#!/usr/bin/env python3
"""
Enhanced LLM ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ìƒˆë¡œ ì—…ë°ì´íŠ¸ëœ --enhanced ì˜µì…˜ì˜ LLM ì¢…í•© ë¶„ì„ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.agent.market_sensor import MarketSensor
from src.agent.enhancements import LLMConfig


def test_enhanced_llm_analysis():
    """Enhanced LLM ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ Enhanced LLM ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # LLM ì„¤ì • (ì¢…í•© ë¶„ì„ ëª¨ë“œ)
    llm_config = {
        'provider': 'hybrid',
        'model_name': 'anthropic.claude-3-sonnet-20240229-v1:0',
        'fallback_to_rules': True,
        'max_tokens': 2000,
        'temperature': 0.1
    }

    try:
        # Market Sensor ì´ˆê¸°í™” (LLM API í™œì„±í™”)
        sensor = MarketSensor(
            enable_llm_api=True,
            llm_config=llm_config,
            use_cached_data=True,  # ìºì‹œëœ ë°ì´í„° ì‚¬ìš©
            use_random_forest=True
        )
        
        print("âœ… Market Sensor ì´ˆê¸°í™” ì„±ê³µ")
        print(f"ğŸ¤– LLM API ì„¤ì •: {llm_config['provider']} - {llm_config['model_name']}")
        
        # Enhanced ë¶„ì„ ìˆ˜í–‰
        print("\nğŸš€ Enhanced ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        result = sensor.run_enhanced_analysis(
            output_dir="results/macro/enhanced_test",
            verbose=True
        )
        
        if result:
            print("\nâœ… Enhanced ë¶„ì„ ì™„ë£Œ!")
            print(f"ì„¸ì…˜ UUID: {result.session_uuid}")
            
            # LLM API ë¶„ì„ ê²°ê³¼ í™•ì¸
            if hasattr(result, 'llm_api_insights') and result.llm_api_insights:
                llm_insights = result.llm_api_insights
                print("\nğŸ¤– LLM ì¢…í•© ë¶„ì„ ê²°ê³¼:")
                
                # ì¢…í•© ë¶„ì„ ê²°ê³¼
                if 'comprehensive_analysis' in llm_insights:
                    comp = llm_insights['comprehensive_analysis']
                    print(f"  ğŸ“Š ì‹œì¥ ì—­í•™:")
                    if 'market_dynamics' in comp:
                        dynamics = comp['market_dynamics']
                        print(f"    - ì£¼ìš” ë™ì¸: {dynamics.get('primary_drivers', [])}")
                        print(f"    - ì¶”ì„¸ ê°•ë„: {dynamics.get('trend_strength', 'N/A')}")
                        print(f"    - ëª¨ë©˜í…€ í’ˆì§ˆ: {dynamics.get('momentum_quality', 'N/A')}")
                
                # ìœ„í—˜ í‰ê°€
                if 'risk_assessment' in llm_insights:
                    risk = llm_insights['risk_assessment']
                    print(f"  âš ï¸ ìœ„í—˜ í‰ê°€:")
                    print(f"    - ë‹¨ê¸° ìœ„í—˜: {risk.get('short_term_risks', [])}")
                    print(f"    - ì¤‘ê¸° ìœ„í—˜: {risk.get('medium_term_risks', [])}")
                    print(f"    - ì¥ê¸° ìœ„í—˜: {risk.get('long_term_risks', [])}")
                
                # ì „ëµì  ì¶”ì²œ
                if 'strategic_recommendations' in llm_insights:
                    strategy = llm_insights['strategic_recommendations']
                    print(f"  ğŸ“ˆ ì „ëµì  ì¶”ì²œ:")
                    if 'portfolio_allocation' in strategy:
                        alloc = strategy['portfolio_allocation']
                        print(f"    - í¬íŠ¸í´ë¦¬ì˜¤ ë°°ë¶„:")
                        print(f"      * ì£¼ì‹: {alloc.get('equity_allocation', 'N/A')}")
                        print(f"      * ì±„ê¶Œ: {alloc.get('bond_allocation', 'N/A')}")
                        print(f"      * í˜„ê¸ˆ: {alloc.get('cash_allocation', 'N/A')}")
                    
                    if 'sector_focus' in strategy:
                        sector = strategy['sector_focus']
                        print(f"    - ì„¹í„° í¬ì»¤ìŠ¤:")
                        print(f"      * ê³¼ì¤‘ ë°°ì¹˜: {sector.get('overweight_sectors', [])}")
                        print(f"      * ê³¼ì†Œ ë°°ì¹˜: {sector.get('underweight_sectors', [])}")
                
                # ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
                if 'scenario_analysis' in llm_insights:
                    scenario = llm_insights['scenario_analysis']
                    print(f"  ğŸ”® ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„:")
                    for scenario_type, details in scenario.items():
                        if isinstance(details, dict):
                            prob = details.get('probability', 0)
                            triggers = details.get('triggers', [])
                            print(f"    - {scenario_type}: {prob:.1%} í™•ë¥ ")
                            if triggers:
                                print(f"      íŠ¸ë¦¬ê±°: {triggers[:2]}")  # ì²˜ìŒ 2ê°œë§Œ
                
                # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
                if 'key_insights' in llm_insights:
                    insights = llm_insights['key_insights']
                    print(f"  ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸:")
                    for i, insight in enumerate(insights[:5], 1):  # ì²˜ìŒ 5ê°œë§Œ
                        print(f"    {i}. {insight}")
                
                # API í†µê³„
                if 'api_stats' in llm_insights:
                    stats = llm_insights['api_stats']
                    print(f"\nğŸ“Š LLM API í†µê³„:")
                    print(f"  - ì´ í˜¸ì¶œ: {stats.get('total_calls', 0)}")
                    print(f"  - ì„±ê³µë¥ : {stats.get('success_rate', 0):.2%}")
                    print(f"  - í‰ê·  ì‘ë‹µì‹œê°„: {stats.get('avg_response_time', 0):.3f}ì´ˆ")
            else:
                print("âš ï¸ LLM API ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"results/macro/enhanced_test/enhanced_llm_test_{timestamp}.json"
            
            # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì¤€ë¹„
            result_dict = {
                "session_uuid": result.session_uuid,
                "current_regime": result.current_regime.value if hasattr(result.current_regime, 'value') else str(result.current_regime),
                "confidence": result.confidence,
                "probabilities": result.probabilities,
                "llm_api_insights": result.llm_api_insights,
                "timestamp": result.timestamp.isoformat() if result.timestamp else datetime.now().isoformat(),
                "analysis_type": "enhanced_llm_test"
            }
            
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result_dict, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
            
        else:
            print("âŒ Enhanced ë¶„ì„ ì‹¤íŒ¨!")
            return False
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\nğŸ‰ Enhanced LLM ë¶„ì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return True


def test_llm_config_parsing():
    """LLM ì„¤ì • íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”§ LLM ì„¤ì • íŒŒì‹± í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    from src.agent.enhancements.llm_api_integration import LLMAPIIntegration
    
    # ë”•ì…”ë„ˆë¦¬ ì„¤ì • í…ŒìŠ¤íŠ¸
    config_dict = {
        'provider': 'hybrid',
        'model_name': 'test-model',
        'max_tokens': 2000,
        'temperature': 0.1
    }
    
    try:
        llm_system = LLMAPIIntegration(config_dict)
        print(f"âœ… ë”•ì…”ë„ˆë¦¬ ì„¤ì • íŒŒì‹± ì„±ê³µ")
        print(f"  - Provider: {llm_system.config.provider}")
        print(f"  - Model: {llm_system.config.model_name}")
        print(f"  - Max Tokens: {llm_system.config.max_tokens}")
        print(f"  - Temperature: {llm_system.config.temperature}")
        
    except Exception as e:
        print(f"âŒ ë”•ì…”ë„ˆë¦¬ ì„¤ì • íŒŒì‹± ì‹¤íŒ¨: {e}")
        return False
    
    return True


if __name__ == "__main__":
    print("ğŸš€ Enhanced LLM ë¶„ì„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # LLM ì„¤ì • íŒŒì‹± í…ŒìŠ¤íŠ¸
    if not test_llm_config_parsing():
        print("âŒ LLM ì„¤ì • íŒŒì‹± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        sys.exit(1)
    
    # Enhanced LLM ë¶„ì„ í…ŒìŠ¤íŠ¸
    if test_enhanced_llm_analysis():
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    else:
        print("\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        sys.exit(1) 