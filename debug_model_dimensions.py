#!/usr/bin/env python3
"""
ëª¨ë¸ ì°¨ì› í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
import pickle
import json
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

def check_model_dimensions():
    """ì €ì¥ëœ ëª¨ë¸ì˜ ì°¨ì› ì •ë³´ í™•ì¸"""
    
    # ë©”íƒ€ ë°ì´í„° ë¡œë“œ
    meta_path = "models/trader/neural_predictor_meta.pkl"
    if os.path.exists(meta_path):
        with open(meta_path, "rb") as f:
            meta_data = pickle.load(f)
            
        print("=" * 80)
        print("ğŸ“Š ëª¨ë¸ ë©”íƒ€ ë°ì´í„°")
        print("=" * 80)
        
        # í”¼ì²˜ ì •ë³´ í™•ì¸
        if "feature_info" in meta_data:
            feature_info = meta_data["feature_info"]
            print("\nâœ… í”¼ì²˜ ì •ë³´:")
            
            # ê°œë³„ ëª¨ë¸ í”¼ì²˜
            if "individual_features" in feature_info:
                print("\nğŸ“Œ ê°œë³„ ëª¨ë¸ í”¼ì²˜:")
                for symbol, info in feature_info["individual_features"].items():
                    feature_names = info.get("feature_names", [])
                    print(f"   {symbol}: {len(feature_names)}ê°œ í”¼ì²˜")
                    if len(feature_names) > 0:
                        print(f"      ì˜ˆì‹œ: {feature_names[:5]}")
                        
            # í†µí•© ëª¨ë¸ í”¼ì²˜
            if "universal_features" in feature_info:
                universal_info = feature_info["universal_features"]
                feature_names = universal_info.get("feature_names", [])
                print(f"\nğŸ“Œ í†µí•© ëª¨ë¸ í”¼ì²˜: {len(feature_names)}ê°œ")
                if len(feature_names) > 0:
                    print(f"   ì˜ˆì‹œ: {feature_names[:5]}")
                    
        # ëª¨ë¸ ì°¨ì› í™•ì¸
        if "model_config" in meta_data:
            model_config = meta_data["model_config"]
            print(f"\nâœ… ëª¨ë¸ ì„¤ì •:")
            print(f"   ì…ë ¥ ì°¨ì›: {model_config.get('input_dim', 'N/A')}")
            print(f"   ì¶œë ¥ ì°¨ì›: {model_config.get('output_size', 'N/A')}")
            
        # í•™ìŠµì‹œ ì‚¬ìš©ëœ í”¼ì²˜ ì´ë¦„ í™•ì¸
        if "feature_names" in meta_data:
            feature_names = meta_data["feature_names"]
            print(f"\nâœ… í†µí•© ëª¨ë¸ í•™ìŠµì‹œ ì‚¬ìš©ëœ í”¼ì²˜: {len(feature_names)}ê°œ")
            print(f"   ì˜ˆì‹œ: {feature_names[:10]}")
            
        # ê°œë³„ ëª¨ë¸ ì°¨ì› í™•ì¸
        print("\nâœ… ê°œë³„ ëª¨ë¸ íŒŒì¼ í™•ì¸:")
        model_dir = Path("models/trader/")
        individual_models = list(model_dir.glob("neural_predictor_pytorch_individual_*.pth"))
        for model_path in individual_models:
            symbol = model_path.stem.split("_")[-1]
            print(f"   {symbol}: {model_path.name}")
            
    else:
        print(f"âŒ ë©”íƒ€ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {meta_path}")
        
    # í”¼ì²˜ ì •ë³´ JSON í™•ì¸
    feature_info_path = "models/trader/neural_predictor_feature_info.json"
    if os.path.exists(feature_info_path):
        print("\n" + "=" * 80)
        print("ğŸ“Š í”¼ì²˜ ì •ë³´ JSON")
        print("=" * 80)
        
        with open(feature_info_path, "r") as f:
            feature_info = json.load(f)
            
        if "individual_features" in feature_info:
            print("\nâœ… ê°œë³„ ëª¨ë¸ í”¼ì²˜ (JSON):")
            for symbol, info in feature_info["individual_features"].items():
                feature_names = info.get("feature_names", [])
                print(f"   {symbol}: {len(feature_names)}ê°œ í”¼ì²˜")
                print(f"      ì°¨ì›: {info.get('input_dim', 'N/A')}")
                print(f"      Lookback: {info.get('lookback_days', 'N/A')}ì¼")
                print(f"      ì´ ì…ë ¥ í¬ê¸°: {len(feature_names)} x {info.get('lookback_days', 'N/A')} = {len(feature_names) * info.get('lookback_days', 0)}")

if __name__ == "__main__":
    check_model_dimensions()