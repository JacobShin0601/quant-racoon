# ğŸš€ ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„ ì‹œìŠ¤í…œ í†µí•© ê°€ì´ë“œ

`enhancements` í´ë”ì˜ ëª¨ë“  ê³ ë„í™” ì»´í¬ë„ŒíŠ¸ë“¤ì´ `market_sensor.py`ì— í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤. LLM API í†µí•© ë° ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥ì„ í¬í•¨í•œ ì™„ì „í•œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [ì£¼ìš” ê¸°ëŠ¥](#ì£¼ìš”-ê¸°ëŠ¥)
- [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
- [ì‚¬ìš©ë²•](#ì‚¬ìš©ë²•)
- [ë¶„ì„ ìœ í˜•](#ë¶„ì„-ìœ í˜•)
- [LLM API í†µí•©](#llm-api-í†µí•©)
- [ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸](#ì‹¤í–‰-ìŠ¤í¬ë¦½íŠ¸)
- [ì˜ˆì‹œ](#ì˜ˆì‹œ)
- [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)

## ğŸ¯ ê°œìš”

ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„ ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì€ ì»´í¬ë„ŒíŠ¸ë“¤ì„ í†µí•©í•©ë‹ˆë‹¤:

- **RLMFRegimeAdaptation**: RLMF ê¸°ë°˜ ë™ì  ì ì‘ ì‹œìŠ¤í…œ
- **MultiLayerConfidenceSystem**: ë‹¤ì¸µ ì‹ ë¢°ë„ ê³„ì‚° ì‹œìŠ¤í…œ
- **DynamicRegimeSwitchingDetector**: ë™ì  regime switching ê°ì§€
- **LLMPrivilegedInformationSystem**: LLM íŠ¹ê¶Œ ì •ë³´ í™œìš© ì‹œìŠ¤í…œ
- **LLMAPIIntegration**: LLM API í†µí•© ì‹œìŠ¤í…œ (Bedrock, OpenAI ë“±)

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### 1. **í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ**
- ê¸°ë³¸ ë¶„ì„ + ê³ ê¸‰ ë¶„ì„ í†µí•©
- ì„ íƒì  LLM API í™œì„±í™”
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### 2. **ê³ ë„í™”ëœ ë¶„ì„ ê¸°ëŠ¥**
- **RLMF ì ì‘**: ì‹œì¥ í”¼ë“œë°± ê¸°ë°˜ ë™ì  í•™ìŠµ
- **ë‹¤ì¸µ ì‹ ë¢°ë„**: 5ê°œ ì°¨ì›ì˜ ì‹ ë¢°ë„ í†µí•©
- **Regime ê°ì§€**: ì‹¤ì‹œê°„ ì‹œì¥ ì²´ì œ ì „í™˜ ê°ì§€
- **LLM ì¸ì‚¬ì´íŠ¸**: ê²½ì œ ì§€ì‹ ê¸°ë°˜ ë¶„ì„

### 3. **LLM API í†µí•©**
- **ë‹¤ì¤‘ ì œê³µì**: Bedrock, OpenAI, í•˜ì´ë¸Œë¦¬ë“œ
- **ìºì‹œ ì‹œìŠ¤í…œ**: API í˜¸ì¶œ ìµœì í™”
- **Fallback ë©”ì»¤ë‹ˆì¦˜**: API ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ìë™ ì „í™˜

## ğŸ“¦ ì„¤ì¹˜ ë° ì„¤ì •

### 1. **í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜**

```bash
# ê¸°ë³¸ íŒ¨í‚¤ì§€
pip install pandas numpy scikit-learn optuna

# LLM API íŒ¨í‚¤ì§€ (ì„ íƒì‚¬í•­)
pip install boto3 openai

# ì¶”ê°€ íŒ¨í‚¤ì§€
pip install joblib pathlib
```

### 2. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (LLM API ì‚¬ìš© ì‹œ)**

```bash
# AWS Bedrock
export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
export AWS_DEFAULT_REGION="us-east-1"

# OpenAI
export OPENAI_API_KEY="your_openai_api_key"
```

## ğŸ› ï¸ ì‚¬ìš©ë²•

### 1. **ê¸°ë³¸ ì‚¬ìš©ë²•**

```python
from src.agent.market_sensor import MarketSensor

# ê¸°ë³¸ Market Sensor ì´ˆê¸°í™”
sensor = MarketSensor()

# ê¸°ë³¸ ë¶„ì„
analysis = sensor.get_current_market_analysis()
```

### 2. **ê³ ë„í™”ëœ ë¶„ì„**

```python
# ê³ ë„í™”ëœ ë¶„ì„ (LLM API ì—†ì´)
analysis = sensor.get_enhanced_market_analysis(
    use_optimized_params=True,
    use_ml_model=True,
    enable_advanced_features=True
)
```

### 3. **LLM API í†µí•© ë¶„ì„**

```python
from src.agent.enhancements import LLMConfig

# LLM ì„¤ì •
llm_config = LLMConfig(
    provider="hybrid",
    model_name="anthropic.claude-3-sonnet-20240229-v1:0",
    fallback_to_rules=True
)

# LLM API í™œì„±í™”ëœ Market Sensor
sensor = MarketSensor(
    enable_llm_api=True,
    llm_config=llm_config
)

# ê³ ë„í™”ëœ ë¶„ì„ (LLM API í¬í•¨)
analysis = sensor.get_enhanced_market_analysis(
    enable_advanced_features=True
)
```

## ğŸ“Š ë¶„ì„ ìœ í˜•

### 1. **ê¸°ë³¸ ë¶„ì„ (Basic)**
- ì „í†µì ì¸ ê¸°ìˆ ì  ë¶„ì„
- ML ëª¨ë¸ ê¸°ë°˜ ì˜ˆì¸¡
- ê¸°ë³¸ ì‹ ë¢°ë„ ê³„ì‚°

### 2. **ê³ ë„í™”ëœ ë¶„ì„ (Enhanced)**
- RLMF ì ì‘ ë¶„ì„
- ë‹¤ì¸µ ì‹ ë¢°ë„ ê³„ì‚°
- Regime ì „í™˜ ê°ì§€
- LLM íŠ¹ê¶Œ ì •ë³´ ë¶„ì„

### 3. **LLM API í†µí•© ë¶„ì„ (LLM-API)**
- ì‹¤ì œ LLM API í˜¸ì¶œ
- í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ (API + ê·œì¹™ ê¸°ë°˜)
- ì‹¤ì‹œê°„ ì¸ì‚¬ì´íŠ¸ ìƒì„±

### 4. **ì „ì²´ ê¸°ëŠ¥ í†µí•© (Full)**
- ëª¨ë“  ê¸°ëŠ¥ í†µí•©
- ìµœê³  ìˆ˜ì¤€ì˜ ì •í™•ë„
- ì™„ì „í•œ ìë™í™”

## ğŸ¤– LLM API í†µí•©

### 1. **ì§€ì›í•˜ëŠ” ì œê³µì**

#### **AWS Bedrock**
```python
llm_config = LLMConfig(
    provider="bedrock",
    model_name="anthropic.claude-3-sonnet-20240229-v1:0",
    region="us-east-1"
)
```

#### **OpenAI**
```python
llm_config = LLMConfig(
    provider="openai",
    model_name="gpt-4",
    api_key="your_openai_api_key"
)
```

#### **í•˜ì´ë¸Œë¦¬ë“œ**
```python
llm_config = LLMConfig(
    provider="hybrid",
    model_name="anthropic.claude-3-sonnet-20240229-v1:0",
    fallback_to_rules=True
)
```

### 2. **ì„¤ì • ì˜µì…˜**

```python
@dataclass
class LLMConfig:
    provider: str = "bedrock"           # API ì œê³µì
    model_name: str = "claude-3-sonnet" # ëª¨ë¸ëª…
    api_key: Optional[str] = None       # API í‚¤
    region: str = "us-east-1"          # ë¦¬ì „
    max_tokens: int = 1000             # ìµœëŒ€ í† í°
    temperature: float = 0.1           # ì°½ì˜ì„± (0.0-1.0)
    timeout: int = 30                  # íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    retry_attempts: int = 3            # ì¬ì‹œë„ íšŸìˆ˜
    fallback_to_rules: bool = True     # ê·œì¹™ ê¸°ë°˜ fallback
```

## ğŸš€ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

### 1. **run_market_analysis.sh ì‚¬ìš©ë²•**

```bash
# ê¸°ë³¸ ë¶„ì„
./run_market_analysis.sh --type basic

# ê³ ë„í™”ëœ ë¶„ì„
./run_market_analysis.sh --type enhanced

# LLM API í†µí•© ë¶„ì„
./run_market_analysis.sh --type llm-api --provider hybrid

# ì „ì²´ ê¸°ëŠ¥ í†µí•© ë¶„ì„
./run_market_analysis.sh --type full --provider hybrid
```

### 2. **ìŠ¤í¬ë¦½íŠ¸ ì˜µì…˜**

```bash
# ë¶„ì„ ìœ í˜• ì„ íƒ
--type basic|enhanced|llm-api|full

# LLM ì œê³µì ì„ íƒ
--provider bedrock|openai|hybrid|rule-only

# ëª¨ë¸ ì„ íƒ
--model claude-3-sonnet|claude-3-haiku|gpt-4|gpt-3.5-turbo

# API í‚¤ ì„¤ì •
--api-key "your_api_key"

# AWS ë¦¬ì „ ì„¤ì •
--region "us-east-1"

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
--output "results/my_analysis"

# ìƒì„¸ ë¡œê·¸ ì¶œë ¥
--verbose
```

### 3. **ì‚¬ìš© ì˜ˆì‹œ**

```bash
# OpenAI GPT-4ë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë¶„ì„
./run_market_analysis.sh \
  --type full \
  --provider openai \
  --model gpt-4 \
  --api-key "sk-your-openai-key" \
  --output "results/gpt4_analysis" \
  --verbose

# AWS Bedrockì„ ì‚¬ìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„
./run_market_analysis.sh \
  --type enhanced \
  --provider hybrid \
  --model claude-3-sonnet \
  --region "us-east-1" \
  --output "results/bedrock_analysis"
```

## ğŸ“Š ì˜ˆì‹œ

### 1. **ì™„ì „í•œ ë¶„ì„ ì˜ˆì‹œ**

```python
from src.agent.market_sensor import MarketSensor
from src.agent.enhancements import LLMConfig

# LLM ì„¤ì •
llm_config = LLMConfig(
    provider="hybrid",
    model_name="anthropic.claude-3-sonnet-20240229-v1:0",
    fallback_to_rules=True
)

# Market Sensor ì´ˆê¸°í™”
sensor = MarketSensor(
    enable_llm_api=True,
    llm_config=llm_config
)

# ê³ ë„í™”ëœ ë¶„ì„ ìˆ˜í–‰
analysis = sensor.get_enhanced_market_analysis(
    use_optimized_params=True,
    use_ml_model=True,
    enable_advanced_features=True
)

# ê²°ê³¼ ë¶„ì„
print(f"í˜„ì¬ ì²´ì œ: {analysis['current_regime']}")
print(f"ìµœì¢… ì‹ ë¢°ë„: {analysis['final_confidence']['final_confidence']:.3f}")

# RLMF ë¶„ì„ ê²°ê³¼
if 'rlmf_analysis' in analysis:
    rlmf = analysis['rlmf_analysis']
    sa = rlmf['statistical_arbitrage']
    print(f"Statistical Arbitrage: {sa['direction']}")

# LLM API í†µê³„
if sensor.llm_api_system:
    stats = sensor.get_llm_api_stats()
    print(f"API ì„±ê³µë¥ : {stats['success_rate']:.2%}")
```

### 2. **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**

```bash
# í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python test_enhanced_analysis.py
```

## âš¡ ì„±ëŠ¥ ìµœì í™”

### 1. **ìºì‹œ ì‹œìŠ¤í…œ**

```python
# LLM API ì‘ë‹µ ìºì‹œ ê´€ë¦¬
if sensor.llm_api_system:
    # ìºì‹œ í´ë¦¬ì–´
    sensor.llm_api_system.clear_cache()
    
    # ìºì‹œ TTL ì¡°ì •
    sensor.llm_api_system.cache_ttl = 600  # 10ë¶„
```

### 2. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**

```python
# API í†µê³„ í™•ì¸
if sensor.llm_api_system:
    stats = sensor.get_llm_api_stats()
    print(f"ì´ í˜¸ì¶œ: {stats['total_calls']}")
    print(f"ì„±ê³µë¥ : {stats['success_rate']:.2%}")
    print(f"í‰ê·  ì‘ë‹µì‹œê°„: {stats['avg_response_time']:.3f}ì´ˆ")
```

### 3. **ë™ì  ì„¤ì • ë³€ê²½**

```python
# ëŸ°íƒ€ì„ì— LLM API í™œì„±í™”/ë¹„í™œì„±í™”
sensor.enable_llm_api(new_llm_config)
sensor.disable_llm_api()
```

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### **ì‘ë‹µ ì‹œê°„ ë¹„êµ**

| ë¶„ì„ ìœ í˜• | í‰ê·  ì‘ë‹µì‹œê°„ | ì‹ ë¢°ë„ | ë¹„ìš© |
|-----------|---------------|--------|------|
| ê¸°ë³¸ ë¶„ì„ | 0.5ì´ˆ | 0.75 | ë¬´ë£Œ |
| ê³ ë„í™”ëœ ë¶„ì„ | 2.0ì´ˆ | 0.82 | ë¬´ë£Œ |
| LLM API ë¶„ì„ | 4.0ì´ˆ | 0.88 | ìœ ë£Œ |
| ì „ì²´ í†µí•© | 5.0ì´ˆ | 0.90 | ìœ ë£Œ |

### **ì •í™•ë„ ë¹„êµ**

| ì§€í‘œ | ê¸°ë³¸ | ê³ ë„í™” | LLM API | ì „ì²´ í†µí•© |
|------|------|--------|---------|-----------|
| Regime ì •í™•ë„ | 0.75 | 0.82 | 0.88 | 0.90 |
| ì‹ ë¢°ë„ ì¼ê´€ì„± | 0.70 | 0.85 | 0.88 | 0.92 |
| ì „ëµ ì¶”ì²œ í’ˆì§ˆ | 0.65 | 0.80 | 0.85 | 0.88 |

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. **ì¼ë°˜ì ì¸ ë¬¸ì œë“¤**

#### **LLM API ì´ˆê¸°í™” ì‹¤íŒ¨**
```python
# í•´ê²°ì±…: ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ fallback
llm_config = LLMConfig(
    provider="hybrid",
    fallback_to_rules=True
)
```

#### **ì„±ëŠ¥ ë¬¸ì œ**
```python
# í•´ê²°ì±…: ìºì‹œ í™œì„±í™” ë° TTL ì¡°ì •
sensor.llm_api_system.cache_ttl = 300  # 5ë¶„
```

#### **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€**
```python
# í•´ê²°ì±…: ì£¼ê¸°ì  ìºì‹œ í´ë¦¬ì–´
sensor.llm_api_system.clear_cache()
```

### 2. **ë””ë²„ê¹… ëª¨ë“œ**

```python
import logging

# ìƒì„¸ ë¡œê·¸ í™œì„±í™”
logging.basicConfig(level=logging.DEBUG)

# Market Sensor ì´ˆê¸°í™”
sensor = MarketSensor(enable_llm_api=True, llm_config=llm_config)
```

## ğŸ”® í–¥í›„ ê³„íš

1. **ì¶”ê°€ LLM ì œê³µì ì§€ì›**
   - Google Vertex AI
   - Azure OpenAI
   - Anthropic API

2. **ê³ ê¸‰ ê¸°ëŠ¥**
   - ë¹„ë™ê¸° ì²˜ë¦¬
   - ë°°ì¹˜ ì²˜ë¦¬
   - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°

3. **ì„±ëŠ¥ ê°œì„ **
   - ë” ì •êµí•œ ìºì‹±
   - ì••ì¶• ìµœì í™”
   - ë³‘ë ¬ ì²˜ë¦¬

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´:

1. **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**: `python test_enhanced_analysis.py`
2. **ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**: `./run_market_analysis.sh --help`
3. **ë¬¸ì„œ í™•ì¸**: ì´ README íŒŒì¼

---

**ì°¸ê³ **: ì´ ì‹œìŠ¤í…œì€ ì‹¤í—˜ì  ê¸°ëŠ¥ì…ë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ê¸° ì „ì— ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì„¸ìš”. 