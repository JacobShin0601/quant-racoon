#!/usr/bin/env python3
"""
ì‹œì¥ ì„¼ì„œ - í†µí•© ì‹œì¥ ë¶„ì„ ì‹œìŠ¤í…œ
ê¸°ë³¸ ë¶„ì„, ê³ ë„í™”ëœ ë¶„ì„, LLM ë¶„ì„ì„ í†µí•©í•˜ì—¬ ì œê³µ
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
import logging
import json
import os
import optuna
from dataclasses import dataclass
from enum import Enum
import uuid
import joblib
from pathlib import Path
import warnings

# yfinance ë””ë²„ê·¸ ë¡œê·¸ ì–µì œ
logging.getLogger("yfinance").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("requests").setLevel(logging.WARNING)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
import sys

sys.path.append(str(Path(__file__).resolve().parent.parent))

from actions.global_macro import (
    GlobalMacroDataCollector,
    MacroSectorAnalyzer,
    HyperparamTuner,
    MarketRegimeValidator,
    MarketRegime,
    MarketCondition,
    MacroAnalysis,
    SectorStrength,
)
from actions.random_forest import MarketRegimeRF  # Random Forest ëª¨ë¸ ì¶”ê°€
from .enhancements import (
    RLMFRegimeAdaptation,
    MultiLayerConfidenceSystem,
    DynamicRegimeSwitchingDetector,
    LLMPrivilegedInformationSystem,
    LLMAPIIntegration,
)


@dataclass
class MarketAnalysisResult:
    """ì‹œì¥ ë¶„ì„ ê²°ê³¼ í†µí•© ë°ì´í„° í´ë˜ìŠ¤"""

    # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼
    current_regime: MarketRegime
    confidence: float
    probabilities: Dict[str, float]

    # ë§¤í¬ë¡œ ë¶„ì„ ê²°ê³¼
    macro_analysis: MacroAnalysis

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼
    optimal_params: Dict[str, Any]
    optimization_performance: Dict[str, float]

    # ê²€ì¦ ê²°ê³¼
    validation_results: Dict[str, Any]

    # ê³ ê¸‰ ë¶„ì„ ê²°ê³¼
    rlmf_analysis: Dict[str, Any]
    confidence_analysis: Dict[str, Any]
    regime_detection: Dict[str, Any]
    llm_insights: Dict[str, Any]
    llm_api_insights: Dict[str, Any]

    # ìµœì¢… ì‹ ë¢°ë„ ë° ì¶”ì²œ
    final_confidence: Dict[str, Any]
    enhanced_recommendations: Dict[str, Any]

    # ë©”íƒ€ë°ì´í„°
    session_uuid: str
    timestamp: datetime
    data_period: str
    analysis_type: str

    # ì›ë³¸ ë¶„ë¥˜ ê²°ê³¼ (ê³ ê¸‰ ë¶„ì„ í¬í•¨)
    classification_result: Dict[str, Any] = None


class MarketSensor:
    """í†µí•© ì‹œì¥ ë¶„ì„ ì‹œìŠ¤í…œ - ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤ (ê³ ë„í™”ëœ ë²„ì „)"""

    def __init__(
        self,
        data_dir: str = "data/macro",
        config_path: str = "config/config_macro.json",
        enable_llm_api: bool = False,
        llm_config: Dict[str, Any] = None,
        use_cached_data: bool = False,
        use_cached_optimization: bool = False,
        cache_days: int = 1,
        use_random_forest: bool = True,  # Random Forest ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
        retrain_rf_model: bool = False,  # Random Forest ëª¨ë¸ ì¬í•™ìŠµ ì—¬ë¶€
    ):
        self.logger = logging.getLogger(__name__)
        self.data_dir = data_dir
        self.config_path = config_path

        # ì„¸ì…˜ UUID ìƒì„±
        self.session_uuid = str(uuid.uuid4())
        self.logger.info(f"MarketSensor ì´ˆê¸°í™” - Session UUID: {self.session_uuid}")

        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™” (UUID ì „ë‹¬)
        self.macro_collector = GlobalMacroDataCollector(self.session_uuid, config_path)
        self.hyperparam_tuner = HyperparamTuner(config_path, self.session_uuid)
        self.macro_analyzer = MacroSectorAnalyzer(data_dir, self.session_uuid)
        self.regime_validator = MarketRegimeValidator(self.session_uuid)

        # ê³ ë„í™”ëœ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
        self.rlmf_adaptation = RLMFRegimeAdaptation()
        self.confidence_system = MultiLayerConfidenceSystem()
        self.regime_detector = DynamicRegimeSwitchingDetector()
        self.llm_privileged_system = LLMPrivilegedInformationSystem()

        # LLM API í†µí•© ì‹œìŠ¤í…œ (ì„ íƒì  í™œì„±í™”)
        self.llm_api_system = None
        self.llm_config = llm_config
        if enable_llm_api and llm_config:
            try:
                self.llm_api_system = LLMAPIIntegration(llm_config)
            except Exception as e:
                pass

        # Random Forest ëª¨ë¸ ì´ˆê¸°í™”
        self.rf_model = None
        self.use_random_forest = use_random_forest
        self.retrain_rf_model = retrain_rf_model

        if use_random_forest:
            try:
                self.rf_model = MarketRegimeRF(verbose=True, config_path=config_path)
            except Exception as e:
                self.use_random_forest = False

        # ìºì‹œ ì„¤ì •
        self.use_cached_data = use_cached_data
        self.use_cached_optimization = use_cached_optimization
        self.cache_days = cache_days

        # ìµœì í™” íŒŒë¼ë¯¸í„° ì €ì¥ ë³€ìˆ˜
        self.optimal_params = None
        self.optimization_performance = None

        # ê²½ê³  ë¬´ì‹œ ì„¤ì •
        warnings.filterwarnings("ignore", category=UserWarning)
        warnings.filterwarnings("ignore", category=pd.errors.SettingWithCopyWarning)

        # ì´ˆê¸°í™” ì™„ë£Œ
        pass

    def _load_cached_data(
        self,
    ) -> Tuple[pd.DataFrame, Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]:
        """ìºì‹œëœ ë§¤í¬ë¡œ ë°ì´í„° ë¡œë“œ"""
        try:
            # ê°€ì¥ ìµœê·¼ ìºì‹œ íŒŒì¼ ì°¾ê¸°
            cache_dir = self.data_dir
            if not os.path.exists(cache_dir):
                return pd.DataFrame(), {}, {}

            # ì„¸ì…˜ë³„ ìºì‹œ ë””ë ‰í† ë¦¬ ì°¾ê¸°
            session_dirs = [
                d
                for d in os.listdir(cache_dir)
                if os.path.isdir(os.path.join(cache_dir, d))
            ]
            if not session_dirs:
                return pd.DataFrame(), {}, {}

            # ê°€ì¥ ìµœê·¼ ì„¸ì…˜ ì°¾ê¸°
            latest_session = max(
                session_dirs, key=lambda x: os.path.getctime(os.path.join(cache_dir, x))
            )
            session_path = os.path.join(cache_dir, latest_session)

            # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬
            cache_time = datetime.fromtimestamp(os.path.getctime(session_path))
            if (datetime.now() - cache_time).days > self.cache_days:
                return pd.DataFrame(), {}, {}

            # ë°ì´í„° íŒŒì¼ë“¤ ë¡œë“œ
            spy_data = pd.DataFrame()
            macro_data = {}
            sector_data = {}

            # SPY ë°ì´í„° ë¡œë“œ
            spy_file = os.path.join(session_path, "spy_data.csv")
            if os.path.exists(spy_file):
                spy_data = pd.read_csv(spy_file, index_col=0, parse_dates=True)

            # ë§¤í¬ë¡œ ë°ì´í„° ë¡œë“œ
            for file in os.listdir(session_path):
                if (
                    file.endswith(".csv")
                    and not file.startswith("spy_")
                    and not file.endswith("_sector.csv")
                ):
                    symbol = file.replace(".csv", "")
                    file_path = os.path.join(session_path, file)
                    macro_data[symbol] = pd.read_csv(
                        file_path, index_col=0, parse_dates=True
                    )

            # ì„¹í„° ë°ì´í„° ë¡œë“œ
            for file in os.listdir(session_path):
                if file.endswith("_sector.csv"):
                    sector = file.replace("_sector.csv", "")
                    file_path = os.path.join(session_path, file)
                    sector_data[sector] = pd.read_csv(
                        file_path, index_col=0, parse_dates=True
                    )

            return spy_data, macro_data, sector_data

        except Exception as e:
            return pd.DataFrame(), {}, {}

    def _load_cached_optimization(self) -> Tuple[Dict[str, Any], Dict[str, float]]:
        """ìºì‹œëœ ìµœì í™” ê²°ê³¼ ë¡œë“œ"""
        try:
            # ìµœì í™” ê²°ê³¼ ë””ë ‰í† ë¦¬ë“¤ í™•ì¸
            optimization_dirs = [
                "results/macro_optimization",
                "results/macro/basic",
                "results/macro/enhanced",
            ]

            best_params = {}
            test_performance = {}
            latest_time = 0
            latest_file = None

            for optimization_dir in optimization_dirs:
                if not os.path.exists(optimization_dir):
                    continue

                # UUID ê¸°ë°˜ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
                for item in os.listdir(optimization_dir):
                    item_path = os.path.join(optimization_dir, item)
                    if os.path.isdir(item_path):
                        # best_params.json íŒŒì¼ ì°¾ê¸°
                        best_params_file = os.path.join(item_path, "best_params.json")
                        performance_file = os.path.join(
                            item_path, "performance_summary.json"
                        )

                        if os.path.exists(best_params_file):
                            file_time = os.path.getctime(best_params_file)

                            # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬
                            if (
                                datetime.now() - datetime.fromtimestamp(file_time)
                            ).days <= self.cache_days:
                                # JSON íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ ë° ë¡œë“œ
                                try:
                                    with open(
                                        best_params_file, "r", encoding="utf-8"
                                    ) as f:
                                        temp_best_params = json.load(f)

                                    # performance_summary.jsonë„ í™•ì¸
                                    if os.path.exists(performance_file):
                                        with open(
                                            performance_file, "r", encoding="utf-8"
                                        ) as f:
                                            performance_data = json.load(f)
                                        temp_test_performance = performance_data.get(
                                            "test_performance", {}
                                        )

                                        # ìœ íš¨í•œ íŒŒì¼ì¸ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
                                        if (
                                            temp_best_params
                                            and temp_test_performance
                                            and file_time > latest_time
                                        ):
                                            latest_time = file_time
                                            latest_file = best_params_file
                                            best_params = temp_best_params
                                            test_performance = temp_test_performance
                                            self.logger.info(
                                                f"best_params.json ë¡œë“œ ì„±ê³µ: {len(best_params)}ê°œ íŒŒë¼ë¯¸í„°"
                                            )
                                            self.logger.info(
                                                f"performance_summary.json ë¡œë“œ ì„±ê³µ: {len(test_performance)}ê°œ ì§€í‘œ"
                                            )
                                            self.logger.info(
                                                f"Sharpe Ratio: {test_performance.get('sharpe_ratio', 'N/A')}"
                                            )
                                    else:
                                        self.logger.warning(
                                            f"performance_summary.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {performance_file}"
                                        )
                                except Exception as e:
                                    self.logger.error(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                                    self.logger.error(f"íŒŒì¼ ê²½ë¡œ: {best_params_file}")
                                    continue

                # ì¼ë°˜ JSON íŒŒì¼ì—ì„œë„ ì°¾ê¸° (ì´ì „ ë²„ì „ í˜¸í™˜ì„± + í´ë°± ì €ì¥ íŒŒì¼)
                optimization_files = [
                    f
                    for f in os.listdir(optimization_dir)
                    if f.endswith(".json")
                    and ("optimization_results" in f or "hyperparam_optimization" in f)
                ]
                for file in optimization_files:
                    file_path = os.path.join(optimization_dir, file)
                    file_time = os.path.getctime(file_path)

                    # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬
                    if (
                        datetime.now() - datetime.fromtimestamp(file_time)
                    ).days <= self.cache_days:
                        try:
                            with open(file_path, "r", encoding="utf-8") as f:
                                optimization_data = json.load(f)

                            # best_paramsê°€ ìˆëŠ” ìœ íš¨í•œ íŒŒì¼ì¸ì§€ í™•ì¸
                            if (
                                "best_params" in optimization_data
                                and optimization_data["best_params"]
                            ):
                                temp_best_params = optimization_data.get(
                                    "best_params", {}
                                )
                                temp_test_performance = optimization_data.get(
                                    "test_performance", {}
                                )

                                # ë” ìµœì‹  íŒŒì¼ì¸ ê²½ìš° ì—…ë°ì´íŠ¸
                                if file_time > latest_time and temp_best_params:
                                    latest_time = file_time
                                    latest_file = file_path
                                    best_params = temp_best_params
                                    test_performance = temp_test_performance
                                    self.logger.info(
                                        f"í´ë°± ìµœì í™” ê²°ê³¼ íŒŒì¼ ë¡œë“œ: {file}"
                                    )
                                    self.logger.info(f"íŒŒë¼ë¯¸í„° ìˆ˜: {len(best_params)}")
                                    self.logger.info(
                                        f"ìµœê³  ì ìˆ˜: {optimization_data.get('best_value', 'N/A')}"
                                    )
                                    self.logger.info(
                                        f"Trial ìˆ˜: {optimization_data.get('n_trials', 'N/A')}"
                                    )
                                    if test_performance:
                                        self.logger.info(
                                            f"Test ì„±ê³¼: {list(test_performance.keys())}"
                                        )
                        except Exception as e:
                            self.logger.warning(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file} - {e}")
                            continue

            if best_params and test_performance:
                self.logger.info(f"ìºì‹œëœ ìµœì í™” ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {latest_file}")
                self.logger.info(f"ë¡œë“œëœ ì„±ê³¼ ì§€í‘œ: {list(test_performance.keys())}")
                return best_params, test_performance
            else:
                self.logger.info("ìœ íš¨í•œ ìºì‹œëœ ìµœì í™” ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {}, {}

        except Exception as e:
            self.logger.warning(f"ìºì‹œëœ ìµœì í™” ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}, {}

    def _copy_data_to_macro_dir(self):
        """UUID ë””ë ‰í† ë¦¬ì˜ ë°ì´í„°ë¥¼ data/macroë¡œ ë³µì‚¬"""
        try:
            import shutil

            # ì„¸ì…˜ UUID ë””ë ‰í† ë¦¬ ê²½ë¡œ
            session_dir = f"data/macro/{self.session_uuid}"
            if not os.path.exists(session_dir):
                self.logger.warning(f"ì„¸ì…˜ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {session_dir}")
                return

            # CSV íŒŒì¼ë“¤ ë³µì‚¬
            csv_count = 0
            for file in os.listdir(session_dir):
                if file.endswith(".csv"):
                    src_path = os.path.join(session_dir, file)
                    dst_path = os.path.join("data/macro", file)
                    shutil.copy2(src_path, dst_path)
                    csv_count += 1
                    self.logger.info(f"ğŸ“„ ë³µì‚¬ë¨: {file}")

            # JSON ë©”íƒ€ë°ì´í„° íŒŒì¼ ë³µì‚¬
            metadata_src = os.path.join(session_dir, "metadata.json")
            metadata_dst = os.path.join("data/macro", "metadata.json")
            if os.path.exists(metadata_src):
                shutil.copy2(metadata_src, metadata_dst)
                self.logger.info("ğŸ“„ ë³µì‚¬ë¨: metadata.json")

            self.logger.info(
                f"âœ… ë§¤í¬ë¡œ ë°ì´í„° ë³µì‚¬ ì™„ë£Œ ({csv_count}ê°œ CSV íŒŒì¼ + ë©”íƒ€ë°ì´í„°)"
            )

        except Exception as e:
            self.logger.error(f"ë§¤í¬ë¡œ ë°ì´í„° ë³µì‚¬ ì¤‘ ì˜¤ë¥˜: {e}")

    def run_basic_analysis(
        self, output_dir: str = "results/macro/basic", verbose: bool = True
    ) -> MarketAnalysisResult:
        """
        ê¸°ë³¸ ì‹œì¥ ë¶„ì„ ì‹¤í–‰ (GlobalMacroDataCollector ê¸°ë°˜)
        - ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
        - ë§¤í¬ë¡œ & ì„¹í„° ë¶„ì„
        - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        - ì‹œì¥ ì²´ì œ ë¶„ë¥˜
        - ê²€ì¦
        """
        if verbose:
            print("ğŸ“Š ê¸°ë³¸ ì‹œì¥ ë¶„ì„ ì‹œì‘ (GlobalMacroDataCollector ê¸°ë°˜)")

        try:
            # 1. ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘ ë˜ëŠ” ìºì‹œ ë¡œë“œ
            if self.use_cached_data:
                spy_data, macro_data, sector_data = self._load_cached_data()

                if spy_data.empty or not macro_data:
                    spy_data, macro_data, sector_data = (
                        self.macro_collector.collect_all_data()
                    )
            else:
                spy_data, macro_data, sector_data = (
                    self.macro_collector.collect_all_data()
                )

                # ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì§í›„ ì¦‰ì‹œ data/macroë¡œ íŒŒì¼ ë³µì‚¬
                if not spy_data.empty and macro_data:
                    self._copy_data_to_macro_dir()

            if spy_data.empty or not macro_data:
                raise ValueError("ë§¤í¬ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")

            # 2. ë§¤í¬ë¡œ & ì„¹í„° ì¢…í•© ë¶„ì„
            macro_analysis = self.macro_analyzer.get_comprehensive_analysis(
                spy_data=spy_data, macro_data=macro_data, sector_data=sector_data
            )

            # 2-1. ìƒì„¸ ë§¤í¬ë¡œ í™˜ê²½ ë¶„ì„
            detailed_macro_analysis = self.macro_analyzer.analyze_macro_environment(
                macro_data
            )

            # 2-2. ì„¹í„° ë¡œí…Œì´ì…˜ ë¶„ì„
            sector_analysis = self.macro_analyzer.analyze_sector_rotation(sector_data)

            # 2-3. ì„¹í„° ì¶”ì²œ ìƒì„±
            sector_recommendations = (
                self.macro_analyzer.generate_sector_recommendations(
                    macro_analysis.market_condition, sector_analysis
                )
            )

            # ë§¤í¬ë¡œ ë¶„ì„ì— ìƒì„¸ ì •ë³´ ì¶”ê°€
            macro_analysis.key_indicators.update(detailed_macro_analysis)
            macro_analysis.sector_rotation.update(sector_analysis)
            macro_analysis.recommendations.update(sector_recommendations)

            # 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë˜ëŠ” ìºì‹œ ë¡œë“œ
            if self.use_cached_optimization:
                self.optimal_params, self.optimization_performance = (
                    self._load_cached_optimization()
                )

                if not self.optimal_params:
                    raise ValueError(
                        "ìºì‹œëœ ìµœì í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìµœì í™”í•˜ë ¤ë©´ --use-cached-optimization ì˜µì…˜ì„ ì œê±°í•˜ì„¸ìš”."
                    )
            else:
                optimization_results = self.hyperparam_tuner.optimize_hyperparameters(
                    spy_data=spy_data, macro_data=macro_data
                )
                self.optimal_params = optimization_results["best_params"]
                self.optimization_performance = optimization_results["test_performance"]

                # Buy & Hold ì„±ê³¼ ê³„ì‚° ì¶”ê°€
                buyhold_performance = self._calculate_buyhold_performance(spy_data)
                self.optimization_performance.update(buyhold_performance)

            # 4. ì‹œì¥ ì²´ì œ ë¶„ë¥˜ (ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
            regime_classification = self._classify_market_regime_with_optimal_params(
                spy_data, macro_data, self.optimal_params
            )

            current_regime = regime_classification["current_regime"]
            base_confidence = regime_classification["confidence"]
            probabilities = regime_classification["probabilities"]

            # 4-1. RLMF ë¶„ì„ (Reinforcement Learning Market Feedback)
            rlmf_analysis = self._perform_rlmf_analysis(macro_analysis, current_regime)

            # 4-2. ë‹¤ì¸µ ì‹ ë¢°ë„ ê³„ì‚° (confidence_system.py ì‚¬ìš©)
            technical_confidence = base_confidence
            macro_confidence = macro_analysis.confidence
            stat_arb_confidence = rlmf_analysis.get("statistical_arbitrage", {}).get(
                "confidence", 0.5
            )
            rlmf_confidence = (
                np.mean(list(rlmf_analysis.get("market_feedback", {}).values()))
                if rlmf_analysis.get("market_feedback")
                else 0.5
            )
            cross_val_confidence = self._calculate_cross_validation_confidence(
                spy_data, regime_classification
            )

            comprehensive_confidence = (
                self.confidence_system.calculate_comprehensive_confidence(
                    technical_confidence,
                    macro_confidence,
                    stat_arb_confidence,
                    rlmf_confidence,
                    cross_val_confidence,
                )
            )

            # ìµœì¢… ì‹ ë¢°ë„ëŠ” ë‹¤ì¸µ ì‹ ë¢°ë„ ì‹œìŠ¤í…œì˜ ê²°ê³¼ ì‚¬ìš©
            confidence = comprehensive_confidence.get(
                "adjusted_confidence", base_confidence
            )

            # 5. ê²€ì¦ ìˆ˜í–‰
            validation_results = self._perform_validation(
                spy_data, macro_data, regime_classification
            )

            # 6. ê²°ê³¼ ìƒì„±
            result = MarketAnalysisResult(
                current_regime=current_regime,
                confidence=confidence,
                probabilities=probabilities,
                macro_analysis=macro_analysis,
                optimal_params=self.optimal_params,
                optimization_performance=self.optimization_performance,
                validation_results=validation_results,
                rlmf_analysis=rlmf_analysis,
                confidence_analysis=comprehensive_confidence,
                regime_detection={},
                llm_insights={},
                llm_api_insights={},
                final_confidence={"final_confidence": confidence},
                enhanced_recommendations=self._generate_basic_recommendations(
                    macro_analysis, current_regime
                ),
                session_uuid=self.session_uuid,
                timestamp=datetime.now(),
                data_period="2_years",
                classification_result=regime_classification,
                analysis_type="basic",
            )

            # 7. ê²°ê³¼ ì €ì¥
            self._save_analysis_result(result, output_dir, verbose)

            if verbose:
                self._print_basic_summary(result)

            return result

        except Exception as e:
            self.logger.error(f"ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            if verbose:
                print(f"âŒ ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    def run_enhanced_analysis(
        self, output_dir: str = "results/macro/enhanced", verbose: bool = True
    ) -> MarketAnalysisResult:
        """
        ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„ ì‹¤í–‰ (ê¸°ë³¸ ë¶„ì„ + LLM + ê³ ê¸‰ ê¸°ëŠ¥)
        """
        if verbose:
            print("ğŸš€ ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„ ì‹œì‘")

        try:
            # 1. ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
            basic_result = self.run_basic_analysis(output_dir, verbose=False)
            if basic_result is None:
                raise ValueError("ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨")

            # 2. ê³ ê¸‰ ë¶„ì„ ìˆ˜í–‰
            if verbose:
                print("ğŸ§  ê³ ê¸‰ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")

            # RLMF ì ì‘ ë¶„ì„ (ë§¤í¬ë¡œ ë°ì´í„° ì „ë‹¬)
            rlmf_analysis = self._perform_rlmf_analysis(
                basic_result.macro_analysis, basic_result.current_regime
            )

            # ë‹¤ì¸µ ì‹ ë¢°ë„ ë¶„ì„
            confidence_analysis = self._perform_confidence_analysis(
                basic_result, rlmf_analysis
            )

            # Regime ì „í™˜ ê°ì§€
            regime_detection = self._perform_regime_detection(
                basic_result.macro_analysis
            )

            # LLM íŠ¹ê¶Œ ì •ë³´ ë¶„ì„
            llm_insights = self._perform_llm_analysis(
                basic_result.macro_analysis, basic_result.current_regime
            )

            # LLM API í†µí•© ë¶„ì„ (í™œì„±í™”ëœ ê²½ìš°)
            llm_api_insights = {}
            if self.llm_api_system:
                # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                analysis_results = {
                    "current_regime": basic_result.current_regime.value,
                    "confidence": basic_result.confidence,
                    "probabilities": basic_result.probabilities,
                    "macro_analysis": basic_result.macro_analysis,
                    "optimal_params": basic_result.optimal_params,
                    "optimization_performance": basic_result.optimization_performance,
                    "validation_results": basic_result.validation_results,
                    "rlmf_analysis": rlmf_analysis,
                    "confidence_analysis": confidence_analysis,
                    "regime_detection": regime_detection,
                    "llm_insights": llm_insights,
                }

                llm_api_insights = self._perform_llm_api_analysis(
                    basic_result.macro_analysis,
                    basic_result.current_regime,
                    analysis_results,
                )

            # 3. ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°
            final_confidence = self._calculate_final_confidence(
                basic_result, rlmf_analysis, confidence_analysis, regime_detection
            )

            # 4. ê³ ë„í™”ëœ ì¶”ì²œ ìƒì„±
            enhanced_recommendations = self._generate_enhanced_recommendations(
                basic_result, rlmf_analysis, regime_detection, llm_insights
            )

            # 5. ê³ ë„í™”ëœ ê²°ê³¼ ìƒì„±
            enhanced_result = MarketAnalysisResult(
                current_regime=basic_result.current_regime,
                confidence=basic_result.confidence,
                probabilities=basic_result.probabilities,
                macro_analysis=basic_result.macro_analysis,
                optimal_params=basic_result.optimal_params,
                optimization_performance=basic_result.optimization_performance,
                validation_results=basic_result.validation_results,
                rlmf_analysis=rlmf_analysis,
                confidence_analysis=confidence_analysis,
                regime_detection=regime_detection,
                llm_insights=llm_insights,
                llm_api_insights=llm_api_insights,
                final_confidence=final_confidence,
                enhanced_recommendations=enhanced_recommendations,
                session_uuid=self.session_uuid,
                timestamp=datetime.now(),
                data_period="2_years",
                analysis_type="enhanced",
            )

            # 6. ê²°ê³¼ ì €ì¥
            self._save_analysis_result(enhanced_result, output_dir, verbose)

            if verbose:
                print("âœ… ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„ ì™„ë£Œ!")
                self._print_enhanced_summary(enhanced_result)

            return enhanced_result

        except Exception as e:
            self.logger.error(f"ê³ ë„í™”ëœ ë¶„ì„ ì‹¤íŒ¨: {e}")
            if verbose:
                print(f"âŒ ê³ ë„í™”ëœ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    def _print_detailed_regime_analysis(self, classification_result: Dict[str, Any]):
        """ì‹œì¥ ì²´ì œ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„¸íˆ ì¶œë ¥ (ë¶„ë¦¬ëœ ì ìˆ˜ì™€ í™•ë¥ )"""
        print("\n" + "=" * 80)
        print("ğŸ” ìƒì„¸ ì‹œì¥ ì²´ì œ ë¶„ì„ ê²°ê³¼")
        print("=" * 80)

        # 1. ê¸°ìˆ ì  ì§€í‘œ ì ìˆ˜ ë¶„ì„
        print("\nğŸ“Š 1. ê¸°ìˆ ì  ì§€í‘œ ì ìˆ˜ ë¶„ì„")
        print("-" * 50)

        if "scores" in classification_result:
            scores = classification_result["scores"]
            total_score = classification_result.get("total_score", scores.sum(axis=1))

            # ìµœê·¼ 5ì¼ê°„ì˜ ì ìˆ˜ ì¶”ì´
            recent_scores = scores.tail(5)
            recent_total = total_score.tail(5)

            print("ğŸ“ˆ ìµœê·¼ 5ì¼ê°„ ì ìˆ˜ ì¶”ì´:")
            for i, (date, row) in enumerate(recent_scores.iterrows()):
                date_str = (
                    date.strftime("%Y-%m-%d")
                    if hasattr(date, "strftime")
                    else str(date)
                )
                total = recent_total.iloc[i] if i < len(recent_total) else 0
                print(f"  {date_str}:")
                print(f"    â€¢ íŠ¸ë Œë“œ ì ìˆ˜: {row.get('trend_score', 0):.3f}")
                print(f"    â€¢ ëª¨ë©˜í…€ ì ìˆ˜: {row.get('momentum_score', 0):.3f}")
                print(f"    â€¢ ë³€ë™ì„± ì ìˆ˜: {row.get('volatility_score', 0):.3f}")
                print(f"    â€¢ ë§¤í¬ë¡œ ì ìˆ˜: {row.get('macro_score', 0):.3f}")
                print(f"    â€¢ ê±°ë˜ëŸ‰ ì ìˆ˜: {row.get('volume_score', 0):.3f}")
                print(f"    â€¢ ì§€ì§€/ì €í•­ ì ìˆ˜: {row.get('sr_score', 0):.3f}")
                print(f"    â€¢ ì´ì : {total:.3f}")
                print()

            # ì ìˆ˜ í†µê³„
            print("ğŸ“Š ì ìˆ˜ í†µê³„ (ì „ì²´ ê¸°ê°„):")
            for col in scores.columns:
                if col in scores:
                    mean_score = scores[col].mean()
                    std_score = scores[col].std()
                    min_score = scores[col].min()
                    max_score = scores[col].max()
                    print(
                        f"  â€¢ {col}: í‰ê· ={mean_score:.3f}, í‘œì¤€í¸ì°¨={std_score:.3f}, ë²”ìœ„=[{min_score:.3f}, {max_score:.3f}]"
                    )

        # 2. Random Forest í™•ë¥  ë¶„ì„
        print("\nğŸ¯ 2. Random Forest í™•ë¥  ë¶„ì„")
        print("-" * 50)

        if "probabilities_series" in classification_result:
            prob_series = classification_result["probabilities_series"]

            # ìµœê·¼ 5ì¼ê°„ì˜ í™•ë¥  ì¶”ì´
            print("ğŸ“ˆ ìµœê·¼ 5ì¼ê°„ í™•ë¥  ì¶”ì´:")
            for i in range(min(5, len(prob_series["trending_up"]))):
                idx = -(i + 1)  # ìµœê·¼ë¶€í„° ì—­ìˆœ
                print(f"  {i+1}ì¼ ì „:")
                print(f"    â€¢ TRENDING_UP: {prob_series['trending_up'][idx]:.1%}")
                print(f"    â€¢ TRENDING_DOWN: {prob_series['trending_down'][idx]:.1%}")
                print(f"    â€¢ VOLATILE: {prob_series['volatile'][idx]:.1%}")
                print(f"    â€¢ SIDEWAYS: {prob_series['sideways'][idx]:.1%}")
                print()

            # í™•ë¥  í†µê³„
            print("ğŸ“Š í™•ë¥  í†µê³„ (ì „ì²´ ê¸°ê°„):")
            for regime, probs in prob_series.items():
                mean_prob = np.mean(probs)
                std_prob = np.std(probs)
                max_prob = np.max(probs)
                min_prob = np.min(probs)
                print(
                    f"  â€¢ {regime.upper()}: í‰ê· ={mean_prob:.1%}, í‘œì¤€í¸ì°¨={std_prob:.1%}, ë²”ìœ„=[{min_prob:.1%}, {max_prob:.1%}]"
                )

        # 3. í˜„ì¬ ìƒíƒœ ë¶„ì„
        print("\nğŸ¯ 3. í˜„ì¬ ì‹œì¥ ìƒíƒœ ë¶„ì„")
        print("-" * 50)

        current_regime = classification_result.get("current_regime", "UNKNOWN")
        confidence = classification_result.get("confidence", 0)
        probabilities = classification_result.get("probabilities", {})

        print(f"í˜„ì¬ ì²´ì œ: {current_regime}")
        print(f"ì‹ ë¢°ë„: {confidence:.3f}")
        print("\nì²´ì œë³„ í™•ë¥ :")
        for regime, prob in probabilities.items():
            print(f"  â€¢ {regime}: {prob:.1%}")

        # 4. ì‹ ë¢°ë„ ë¶„ì„
        print("\nğŸ” 4. ì‹ ë¢°ë„ ë¶„ì„")
        print("-" * 50)

        if confidence < 0.3:
            confidence_level = "ë§¤ìš° ë‚®ìŒ"
            recommendation = "ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì‹ ì¤‘í•˜ê²Œ í•´ì„í•˜ì„¸ìš”"
        elif confidence < 0.5:
            confidence_level = "ë‚®ìŒ"
            recommendation = "ì¶”ê°€ ì§€í‘œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
        elif confidence < 0.7:
            confidence_level = "ë³´í†µ"
            recommendation = "ì¼ë°˜ì ì¸ ì‹ ë¢°ë„ì…ë‹ˆë‹¤"
        elif confidence < 0.9:
            confidence_level = "ë†’ìŒ"
            recommendation = "ì‹ ë¢°í•  ë§Œí•œ ë¶„ë¥˜ì…ë‹ˆë‹¤"
        else:
            confidence_level = "ë§¤ìš° ë†’ìŒ"
            recommendation = "ë§¤ìš° ì‹ ë¢°í•  ë§Œí•œ ë¶„ë¥˜ì…ë‹ˆë‹¤"

        print(f"ì‹ ë¢°ë„ ìˆ˜ì¤€: {confidence_level}")
        print(f"ê¶Œì¥ì‚¬í•­: {recommendation}")

        # 5. ê°œì„  ì œì•ˆ
        print("\nğŸ’¡ 5. ê°œì„  ì œì•ˆ")
        print("-" * 50)

        if "scores" in classification_result:
            scores = classification_result["scores"]

            # ê°€ì¥ ë‚®ì€ ì ìˆ˜ ì§€í‘œ ì°¾ê¸°
            if not scores.empty:
                recent_scores = scores.tail(1).iloc[0]
                min_score_key = recent_scores.idxmin()
                min_score_value = recent_scores[min_score_key]

                print(f"ê°€ì¥ ë‚®ì€ ì ìˆ˜ ì§€í‘œ: {min_score_key} ({min_score_value:.3f})")

                if min_score_value < -0.5:
                    print("â†’ í•´ë‹¹ ì§€í‘œì˜ ë°ì´í„° í’ˆì§ˆì´ë‚˜ íŒŒë¼ë¯¸í„° ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤")
                elif min_score_value < 0:
                    print("â†’ í•´ë‹¹ ì§€í‘œì˜ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")
                else:
                    print("â†’ ëª¨ë“  ì§€í‘œê°€ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤")

        print("\n" + "=" * 80)

    def _classify_market_regime_with_optimal_params(
        self,
        spy_data: pd.DataFrame,
        macro_data: Dict[str, pd.DataFrame],
        optimal_params: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ìµœì í™”ëœ íŒŒë¼ë¯¸í„°ë¡œ ì‹œì¥ ì²´ì œ ë¶„ë¥˜ (ê³ ê¸‰ Quant ë¶„ì„ í†µí•©)"""
        try:
            # Random Forest ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
            if self.use_random_forest and self.rf_model:
                return self._classify_with_random_forest(spy_data, macro_data)
            else:
                # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë„ˆì˜ ë¶„ë¥˜ ë©”ì„œë“œ ì‚¬ìš©
                classification_result = (
                    self.hyperparam_tuner._classify_market_regime_with_probabilities(
                        spy_data, optimal_params
                    )
                )

            # ê³ ê¸‰ Quant ë¶„ì„ ìˆ˜í–‰
            enhanced_quant_analysis = self._perform_enhanced_quant_analysis(
                spy_data, macro_data, classification_result, optimal_params
            )

            # SPY ì§„ì…/ë§¤ë„ í¬ì¸íŠ¸ ê³„ì‚°
            spy_entry_exit_points = self._calculate_spy_entry_exit_points(
                spy_data, current_regime
            )

            # ê¸°ì¡´ ê²°ê³¼ì™€ ê³ ê¸‰ ë¶„ì„ ê²°ê³¼ í†µí•©
            classification_result.update(enhanced_quant_analysis)
            classification_result["spy_entry_exit_points"] = spy_entry_exit_points

            # ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì¶œë ¥
            self._print_detailed_regime_analysis(classification_result)

            # í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if "current_regime" not in classification_result:
                raise KeyError("'current_regime' í‚¤ê°€ ë¶„ë¥˜ ê²°ê³¼ì— ì—†ìŠµë‹ˆë‹¤")

            if "confidence" not in classification_result:
                classification_result["confidence"] = 0.5

            if "probabilities" not in classification_result:
                classification_result["probabilities"] = {
                    "TRENDING_UP": 0.25,
                    "TRENDING_DOWN": 0.25,
                    "SIDEWAYS": 0.25,
                    "VOLATILE": 0.25,
                }

            return {
                "current_regime": MarketRegime(classification_result["current_regime"]),
                "confidence": classification_result["confidence"],
                "probabilities": classification_result["probabilities"],
                "enhanced_quant_analysis": enhanced_quant_analysis,
            }

        except Exception as e:
            return {
                "current_regime": MarketRegime.UNCERTAIN,
                "confidence": 0.5,
                "probabilities": {
                    "TRENDING_UP": 0.25,
                    "TRENDING_DOWN": 0.25,
                    "SIDEWAYS": 0.25,
                    "VOLATILE": 0.25,
                },
            }

    def _classify_with_random_forest(
        self, spy_data: pd.DataFrame, macro_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, Any]:
        """Random Forest ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹œì¥ ì²´ì œ ë¶„ë¥˜"""
        try:
            # ëª¨ë¸ í•™ìŠµ/ë¡œë“œ ìƒíƒœ í™•ì¸
            if self.retrain_rf_model:
                # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
                training_data = self.rf_model.collect_training_data()
                # ëª¨ë¸ í•™ìŠµ
                training_results = self.rf_model.train_model(
                    training_data, save_model=True
                )
                self.logger.info(
                    f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ - í…ŒìŠ¤íŠ¸ ì •í™•ë„: {training_results['test_score']:.4f}"
                )
            else:
                # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì‹œë„
                try:
                    self.rf_model.load_model()
                    self.logger.info("ì €ì¥ëœ Random Forest ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                except FileNotFoundError:
                    self.logger.info("ì €ì¥ëœ ëª¨ë¸ì´ ì—†ì–´ ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤")
                    training_data = self.rf_model.collect_training_data()
                    training_results = self.rf_model.train_model(
                        training_data, save_model=True
                    )
                    self.logger.info(
                        f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ - í…ŒìŠ¤íŠ¸ ì •í™•ë„: {training_results['test_score']:.4f}"
                    )

            # í˜„ì¬ ì‹œì¥ ìƒíƒœ í™•ë¥  ì˜ˆì¸¡
            probabilities = self.rf_model.get_current_market_probabilities(
                self.data_dir
            )
            self.logger.info(f"Random Forest ì˜ˆì¸¡ í™•ë¥ : {probabilities}")

            # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ì²´ì œ ì„ íƒ
            current_regime = max(probabilities.items(), key=lambda x: x[1])[0].upper()

            # ì‹ ë¢°ë„ ê³„ì‚° (ìµœê³  í™•ë¥  ê°’)
            confidence = max(probabilities.values())

            # MarketRegime ì—´ê±°í˜•ìœ¼ë¡œ ë³€í™˜
            regime_mapping = {
                "TRENDING_UP": MarketRegime.TRENDING_UP,
                "TRENDING_DOWN": MarketRegime.TRENDING_DOWN,
                "VOLATILE": MarketRegime.VOLATILE,
                "SIDEWAYS": MarketRegime.SIDEWAYS,
            }

            current_regime_enum = regime_mapping.get(
                current_regime, MarketRegime.UNCERTAIN
            )

            # í™•ë¥ ì„ ëŒ€ë¬¸ì í‚¤ë¡œ ë³€í™˜
            probabilities_upper = {k.upper(): v for k, v in probabilities.items()}

            result = {
                "current_regime": current_regime_enum,
                "confidence": confidence,
                "probabilities": probabilities_upper,
            }

            # SPY ì§„ì…/ë§¤ë„ í¬ì¸íŠ¸ ê³„ì‚°
            spy_entry_exit_points = self._calculate_spy_entry_exit_points(
                spy_data, current_regime_enum
            )
            result["spy_entry_exit_points"] = spy_entry_exit_points

            # ê³ ê¸‰ Quant ë¶„ì„ ìˆ˜í–‰ ë° í†µí•©
            enhanced_quant_analysis = self._perform_enhanced_quant_analysis(
                spy_data, macro_data, result, {}
            )

            # ê²°ê³¼ í†µí•©
            result.update(enhanced_quant_analysis)

            return result

        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í´ë°±
            return {
                "current_regime": MarketRegime.UNCERTAIN,
                "confidence": 0.5,
                "probabilities": {
                    "TRENDING_UP": 0.25,
                    "TRENDING_DOWN": 0.25,
                    "SIDEWAYS": 0.25,
                    "VOLATILE": 0.25,
                },
            }

    def _perform_enhanced_quant_analysis(
        self,
        spy_data: pd.DataFrame,
        macro_data: Dict[str, pd.DataFrame],
        classification_result: Dict[str, Any],
        optimal_params: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ê³ ê¸‰ Quant ë¶„ì„ ìˆ˜í–‰ (RLMF, ì‹ ë¢°ë„ ì‹œìŠ¤í…œ, Regime ê°ì§€ í†µí•©)"""
        try:

            # 1. ë™ì  Regime Switching ê°ì§€
            regime_detection = self.regime_detector.detect_regime_shifts(
                spy_data, macro_data
            )
            regime_stability = self.regime_detector.analyze_regime_stability(spy_data)
            regime_persistence = self.regime_detector.calculate_regime_persistence(
                spy_data
            )

            # 2. RLMF (Reinforcement Learning from Market Feedback) ë¶„ì„
            current_regime = classification_result.get("current_regime", "SIDEWAYS")
            spy_returns = spy_data["close"].pct_change().dropna()

            # RF ëª¨ë¸ ì˜ˆì¸¡ ê¸°ë¡
            rf_probabilities = classification_result.get("probabilities", {})
            confidence = classification_result.get("confidence", 0.5)
            self.rlmf_adaptation.record_prediction(
                current_regime.value, rf_probabilities, confidence
            )

            # Market feedback ê³„ì‚° (ê°œì„ ëœ ë²„ì „)
            if hasattr(self, "last_prediction") and hasattr(self, "last_returns"):
                # ì´ì „ ì˜ˆì¸¡ì´ ìˆìœ¼ë©´ ì‹¤ì œ í”¼ë“œë°± ê³„ì‚°
                market_feedback = self.rlmf_adaptation.calculate_market_feedback(
                    self.last_prediction,
                    spy_returns.tail(len(self.last_returns)),
                    spy_data,
                    macro_data,
                )

                # RF ëª¨ë¸ ë¹„êµ í”¼ë“œë°± ì¶”ê°€
                rf_comparison_feedback = (
                    self.rlmf_adaptation.calculate_rf_comparison_feedback(
                        spy_returns.tail(5)  # ìµœê·¼ 5ì¼ ìˆ˜ìµë¥ 
                    )
                )
                market_feedback.update(rf_comparison_feedback)

                # ì ì‘ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
                self.rlmf_adaptation.update_adaptation_weights(market_feedback)
            else:
                # ì²« ë²ˆì§¸ ì‹¤í–‰ì´ê±°ë‚˜ ì´ì „ ì˜ˆì¸¡ì´ ì—†ëŠ” ê²½ìš°
                # í˜„ì¬ ì‹œì¥ ìƒí™© ê¸°ë°˜ ê¸°ë³¸ í”¼ë“œë°± ê³„ì‚°
                market_feedback = self.rlmf_adaptation.calculate_market_feedback(
                    (
                        current_regime.value
                        if hasattr(current_regime, "value")
                        else str(current_regime)
                    ),
                    spy_returns.tail(20) if len(spy_returns) >= 20 else spy_returns,
                    spy_data,
                    macro_data,
                )

                # RF ëª¨ë¸ ë¹„êµ í”¼ë“œë°± ì¶”ê°€ (í˜„ì¬ ë°ì´í„° ê¸°ë°˜)
                rf_comparison_feedback = (
                    self.rlmf_adaptation.calculate_rf_comparison_feedback(
                        spy_returns.tail(5) if len(spy_returns) >= 5 else spy_returns
                    )
                )
                market_feedback.update(rf_comparison_feedback)

                # ì ì‘ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
                self.rlmf_adaptation.update_adaptation_weights(market_feedback)

            # 3. Statistical Arbitrage ì‹ í˜¸ ê³„ì‚°
            stat_arb_signals = (
                self.rlmf_adaptation.calculate_statistical_arbitrage_signal(macro_data)
            )

            # 4. ë‹¤ì¸µ ì‹ ë¢°ë„ ê³„ì‚° (confidence_system.py ì‚¬ìš©)
            technical_confidence = classification_result.get("confidence", 0.5)
            macro_confidence = self._calculate_macro_confidence(macro_data)
            stat_arb_confidence = stat_arb_signals.get("confidence", 0.5)
            rlmf_confidence = (
                np.mean(list(market_feedback.values())) if market_feedback else 0.5
            )
            cross_val_confidence = self._calculate_cross_validation_confidence(
                spy_data, classification_result
            )

            comprehensive_confidence = (
                self.confidence_system.calculate_comprehensive_confidence(
                    technical_confidence,
                    macro_confidence,
                    stat_arb_confidence,
                    rlmf_confidence,
                    cross_val_confidence,
                )
            )

            # 5. ê³ ê¸‰ Quant ì§€í‘œ ê³„ì‚°
            advanced_indicators = self._calculate_advanced_quant_indicators(
                spy_data, macro_data, optimal_params
            )

            # 6. ê²°ê³¼ í†µí•©
            enhanced_analysis = {
                # Regime ê°ì§€ ê²°ê³¼
                "regime_detection": {
                    "shift_detected": regime_detection.get(
                        "regime_shift_detected", False
                    ),
                    "shift_score": regime_detection.get("shift_score", 0.0),
                    "stability_score": regime_stability.get("stability_score", 0.5),
                    "persistence_score": regime_persistence.get(
                        "persistence_score", 0.5
                    ),
                    "expected_duration": regime_persistence.get(
                        "expected_duration", "unknown"
                    ),
                },
                # RLMF ë¶„ì„ ê²°ê³¼
                "rlmf_analysis": {
                    "market_feedback": market_feedback,
                    "adaptation_status": self.rlmf_adaptation.get_adaptation_status(),
                    "statistical_arbitrage": stat_arb_signals,
                },
                # ì‹ ë¢°ë„ ë¶„ì„ ê²°ê³¼
                "confidence_analysis": comprehensive_confidence,
                # ê³ ê¸‰ ì§€í‘œ
                "advanced_indicators": advanced_indicators,
                # ì¢…í•© í‰ê°€
                "quant_score": self._calculate_quant_score(
                    classification_result,
                    regime_detection,
                    market_feedback,
                    stat_arb_signals,
                    comprehensive_confidence,
                ),
            }

            # í˜„ì¬ ì˜ˆì¸¡ ì €ì¥ (ë‹¤ìŒ ë¶„ì„ì—ì„œ feedback ê³„ì‚°ìš©)
            self.last_prediction = current_regime
            self.last_returns = spy_returns.tail(20).copy()

            self.logger.info("âœ… ê³ ê¸‰ Quant ë¶„ì„ ì™„ë£Œ")
            return enhanced_analysis

        except Exception as e:
            self.logger.error(f"ê³ ê¸‰ Quant ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "regime_detection": {"shift_detected": False, "shift_score": 0.0},
                "rlmf_analysis": {"market_feedback": {}, "adaptation_status": {}},
                "confidence_analysis": {"adjusted_confidence": 0.5},
                "advanced_indicators": {},
                "quant_score": 0.5,
            }

    def _calculate_macro_confidence(self, macro_data: Dict[str, pd.DataFrame]) -> float:
        """ë§¤í¬ë¡œ ë°ì´í„° ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            confidence_scores = []

            # VIX ê¸°ë°˜ ì‹ ë¢°ë„
            if "^VIX" in macro_data and not macro_data["^VIX"].empty:
                vix_data = macro_data["^VIX"]
                close_col = "close" if "close" in vix_data.columns else "Close"
                current_vix = vix_data[close_col].iloc[-1]

                # VIXê°€ 15-25 ë²”ìœ„ì¼ ë•Œ ì‹ ë¢°ë„ ë†’ìŒ
                if 15 <= current_vix <= 25:
                    confidence_scores.append(0.8)
                elif 10 <= current_vix <= 30:
                    confidence_scores.append(0.6)
                else:
                    confidence_scores.append(0.4)

            # ê¸ˆë¦¬ ê¸°ë°˜ ì‹ ë¢°ë„
            if "^TNX" in macro_data and not macro_data["^TNX"].empty:
                tnx_data = macro_data["^TNX"]
                close_col = "close" if "close" in tnx_data.columns else "Close"
                if len(tnx_data) > 5:
                    rate_volatility = tnx_data[close_col].pct_change().std()
                    # ê¸ˆë¦¬ ë³€ë™ì„±ì´ ë‚®ì„ ë•Œ ì‹ ë¢°ë„ ë†’ìŒ
                    if rate_volatility < 0.02:
                        confidence_scores.append(0.7)
                    elif rate_volatility < 0.05:
                        confidence_scores.append(0.5)
                    else:
                        confidence_scores.append(0.3)

            return np.mean(confidence_scores) if confidence_scores else 0.5

        except Exception as e:
            self.logger.warning(f"ë§¤í¬ë¡œ ì‹ ë¢°ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.5

    def _calculate_cross_validation_confidence(
        self, spy_data: pd.DataFrame, classification_result: Dict[str, Any]
    ) -> float:
        """êµì°¨ ê²€ì¦ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            if len(spy_data) < 60:
                return 0.5

            # ìµœê·¼ 60ì¼ ë°ì´í„°ë¡œ ê°„ë‹¨í•œ êµì°¨ ê²€ì¦
            recent_data = spy_data.tail(60)
            returns = recent_data["close"].pct_change().dropna()

            # ë³€ë™ì„± ì¼ê´€ì„±
            volatility_consistency = (
                1.0 - (returns.std() / returns.mean()) if returns.mean() != 0 else 0.5
            )
            volatility_consistency = max(0.0, min(1.0, volatility_consistency))

            # íŠ¸ë Œë“œ ì¼ê´€ì„±
            positive_ratio = np.mean(returns > 0)
            trend_consistency = (
                abs(positive_ratio - 0.5) * 2
            )  # 0.5ì—ì„œ ë©€ìˆ˜ë¡ ì¼ê´€ëœ íŠ¸ë Œë“œ

            # ì˜ˆì¸¡ê³¼ ì‹¤ì œì˜ ì¼ê´€ì„± (ê°„ë‹¨í•œ ê²€ì¦)
            predicted_regime = classification_result.get("current_regime", "SIDEWAYS")
            actual_trend = returns.mean()

            if predicted_regime == "TRENDING_UP" and actual_trend > 0.001:
                prediction_consistency = 0.8
            elif predicted_regime == "TRENDING_DOWN" and actual_trend < -0.001:
                prediction_consistency = 0.8
            elif predicted_regime == "SIDEWAYS" and abs(actual_trend) < 0.001:
                prediction_consistency = 0.8
            else:
                prediction_consistency = 0.4

            # ì¢…í•© ì‹ ë¢°ë„
            cross_val_confidence = (
                volatility_consistency + trend_consistency + prediction_consistency
            ) / 3
            return cross_val_confidence

        except Exception as e:
            self.logger.warning(f"êµì°¨ ê²€ì¦ ì‹ ë¢°ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.5

    def _calculate_buyhold_performance(
        self, spy_data: pd.DataFrame
    ) -> Dict[str, float]:
        """Buy & Hold ì„±ê³¼ ê³„ì‚°"""
        try:
            if spy_data.empty or len(spy_data) < 2:
                return {
                    "buyhold_return": 0.0,
                    "buyhold_sharpe": 0.0,
                    "buyhold_drawdown": 0.0,
                }

            # ì»¬ëŸ¼ëª… í™•ì¸
            close_col = "close" if "close" in spy_data.columns else "Close"

            # Buy & Hold ìˆ˜ìµë¥  ê³„ì‚°
            initial_price = spy_data[close_col].iloc[0]
            final_price = spy_data[close_col].iloc[-1]
            buyhold_return = (final_price - initial_price) / initial_price

            # ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚°
            daily_returns = spy_data[close_col].pct_change().dropna()

            # ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚° (ì—°ê°„í™”)
            mean_return = daily_returns.mean()
            std_return = daily_returns.std()
            risk_free_rate = 0.02 / 252  # ì¼ê°„ ë¬´ìœ„í—˜ ìˆ˜ìµë¥ 
            excess_return = mean_return - risk_free_rate
            buyhold_sharpe = (
                (excess_return * 252) / (std_return * np.sqrt(252))
                if std_return > 0
                else 0.0
            )

            # ìµœëŒ€ ë‚™í­ ê³„ì‚°
            cumulative_returns = (1 + daily_returns).cumprod()
            running_max = cumulative_returns.expanding().max()
            drawdown = (cumulative_returns - running_max) / running_max
            buyhold_drawdown = abs(drawdown.min())

            return {
                "buyhold_return": buyhold_return,
                "buyhold_sharpe": buyhold_sharpe,
                "buyhold_drawdown": buyhold_drawdown,
            }

        except Exception as e:
            self.logger.warning(f"Buy & Hold ì„±ê³¼ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "buyhold_return": 0.0,
                "buyhold_sharpe": 0.0,
                "buyhold_drawdown": 0.0,
            }

    def _calculate_spy_entry_exit_points(
        self, spy_data: pd.DataFrame, current_regime: MarketRegime
    ) -> Dict[str, Any]:
        """SPY ê¸°ë°˜ êµ¬ì²´ì ì¸ ì§„ì…/ë§¤ë„ í¬ì¸íŠ¸ ê³„ì‚°"""
        try:
            if spy_data.empty:
                return {}

            current_price = spy_data["Close"].iloc[-1]
            current_volume = spy_data["Volume"].iloc[-1]

            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
            spy_data = spy_data.copy()

            # ì´ë™í‰ê· 
            spy_data["SMA_20"] = spy_data["Close"].rolling(window=20).mean()
            spy_data["SMA_50"] = spy_data["Close"].rolling(window=50).mean()
            spy_data["EMA_12"] = spy_data["Close"].ewm(span=12).mean()
            spy_data["EMA_26"] = spy_data["Close"].ewm(span=26).mean()

            # RSI
            delta = spy_data["Close"].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            spy_data["RSI"] = 100 - (100 / (1 + rs))

            # MACD
            spy_data["MACD"] = spy_data["EMA_12"] - spy_data["EMA_26"]
            spy_data["MACD_Signal"] = spy_data["MACD"].ewm(span=9).mean()
            spy_data["MACD_Histogram"] = spy_data["MACD"] - spy_data["MACD_Signal"]

            # ë³¼ë¦°ì € ë°´ë“œ
            spy_data["BB_Middle"] = spy_data["Close"].rolling(window=20).mean()
            bb_std = spy_data["Close"].rolling(window=20).std()
            spy_data["BB_Upper"] = spy_data["BB_Middle"] + (bb_std * 2)
            spy_data["BB_Lower"] = spy_data["BB_Middle"] - (bb_std * 2)

            # ì§€ì§€/ì €í•­ì„  ê³„ì‚°
            recent_highs = spy_data["High"].rolling(window=20).max()
            recent_lows = spy_data["Low"].rolling(window=20).min()

            # í˜„ì¬ ê°’ë“¤
            current_sma_20 = spy_data["SMA_20"].iloc[-1]
            current_sma_50 = spy_data["SMA_50"].iloc[-1]
            current_rsi = spy_data["RSI"].iloc[-1]
            current_macd = spy_data["MACD"].iloc[-1]
            current_macd_signal = spy_data["MACD_Signal"].iloc[-1]
            current_bb_upper = spy_data["BB_Upper"].iloc[-1]
            current_bb_lower = spy_data["BB_Lower"].iloc[-1]
            current_bb_middle = spy_data["BB_Middle"].iloc[-1]

            # ì²´ì œë³„ ì§„ì…/ë§¤ë„ ì „ëµ
            entry_exit_points = {
                "current_price": current_price,
                "support_levels": [],
                "resistance_levels": [],
                "entry_signals": [],
                "exit_signals": [],
                "stop_loss_levels": [],
                "take_profit_levels": [],
                "technical_indicators": {
                    "rsi": current_rsi,
                    "macd": current_macd,
                    "macd_signal": current_macd_signal,
                    "sma_20": current_sma_20,
                    "sma_50": current_sma_50,
                    "bb_upper": current_bb_upper,
                    "bb_lower": current_bb_lower,
                    "bb_middle": current_bb_middle,
                },
            }

            # ì²´ì œë³„ ì „ëµ ì„¤ì •
            if current_regime == MarketRegime.TRENDING_UP:
                # ê°•ì„¸ì¥: ëª¨ë©˜í…€ íŒ”ë¡œì‰
                entry_exit_points["support_levels"] = [
                    current_sma_20,
                    current_sma_50,
                    current_bb_middle,
                ]
                entry_exit_points["resistance_levels"] = [
                    current_bb_upper,
                    current_price * 1.02,  # 2% ìƒìŠ¹
                    current_price * 1.05,  # 5% ìƒìŠ¹
                ]
                entry_exit_points["entry_signals"] = [
                    f"RSI < 70 (í˜„ì¬: {current_rsi:.1f})",
                    f"MACD > Signal (í˜„ì¬: {current_macd:.2f} > {current_macd_signal:.2f})",
                    f"ê°€ê²© > SMA20 (í˜„ì¬: {current_price:.2f} > {current_sma_20:.2f})",
                ]
                entry_exit_points["exit_signals"] = [
                    f"RSI > 80 (í˜„ì¬: {current_rsi:.1f})",
                    f"ê°€ê²© < SMA20 (í˜„ì¬: {current_price:.2f} < {current_sma_20:.2f})",
                    f"ë³¼ë¦°ì € ìƒë‹¨ ëŒíŒŒ í›„ í•˜ë½",
                ]
                entry_exit_points["stop_loss_levels"] = [
                    current_sma_50,
                    current_price * 0.95,  # 5% ì†ì ˆ
                    current_bb_lower,
                ]
                entry_exit_points["take_profit_levels"] = [
                    current_price * 1.05,  # 5% ìµì ˆ
                    current_price * 1.10,  # 10% ìµì ˆ
                    current_bb_upper,
                ]

            elif current_regime == MarketRegime.TRENDING_DOWN:
                # ì•½ì„¸ì¥: ë°©ì–´ì  ì „ëµ
                entry_exit_points["support_levels"] = [
                    current_bb_lower,
                    current_price * 0.95,  # 5% í•˜ë½
                    current_price * 0.90,  # 10% í•˜ë½
                ]
                entry_exit_points["resistance_levels"] = [
                    current_sma_20,
                    current_sma_50,
                    current_bb_middle,
                ]
                entry_exit_points["entry_signals"] = [
                    f"RSI < 30 (í˜„ì¬: {current_rsi:.1f})",
                    f"ê°€ê²© < ë³¼ë¦°ì € í•˜ë‹¨ (í˜„ì¬: {current_price:.2f} < {current_bb_lower:.2f})",
                    f"ë°˜ë“± ì‹ í˜¸ í™•ì¸",
                ]
                entry_exit_points["exit_signals"] = [
                    f"RSI > 50 (í˜„ì¬: {current_rsi:.1f})",
                    f"ê°€ê²© > SMA20 (í˜„ì¬: {current_price:.2f} > {current_sma_20:.2f})",
                    f"ì €í•­ì„  ëŒíŒŒ ì‹¤íŒ¨",
                ]
                entry_exit_points["stop_loss_levels"] = [
                    current_price * 0.97,  # 3% ì†ì ˆ
                    current_price * 0.95,  # 5% ì†ì ˆ
                    current_bb_lower * 0.98,
                ]
                entry_exit_points["take_profit_levels"] = [
                    current_price * 1.03,  # 3% ìµì ˆ
                    current_price * 1.05,  # 5% ìµì ˆ
                    current_sma_20,
                ]

            elif current_regime == MarketRegime.VOLATILE:
                # ë³€ë™ì„± ë†’ì€ ì‹œì¥: ë²”ìœ„ ê±°ë˜
                entry_exit_points["support_levels"] = [
                    current_bb_lower,
                    current_sma_50,
                    current_price * 0.98,
                ]
                entry_exit_points["resistance_levels"] = [
                    current_bb_upper,
                    current_sma_20,
                    current_price * 1.02,
                ]
                entry_exit_points["entry_signals"] = [
                    f"RSI < 40 (í˜„ì¬: {current_rsi:.1f})",
                    f"ê°€ê²© < ë³¼ë¦°ì € í•˜ë‹¨ (í˜„ì¬: {current_price:.2f} < {current_bb_lower:.2f})",
                    f"ë³€ë™ì„± ìˆ˜ì¶• ì‹œì ",
                ]
                entry_exit_points["exit_signals"] = [
                    f"RSI > 60 (í˜„ì¬: {current_rsi:.1f})",
                    f"ê°€ê²© > ë³¼ë¦°ì € ìƒë‹¨ (í˜„ì¬: {current_price:.2f} > {current_bb_upper:.2f})",
                    f"ë³€ë™ì„± í™•ëŒ€ ì‹œì ",
                ]
                entry_exit_points["stop_loss_levels"] = [
                    current_price * 0.96,  # 4% ì†ì ˆ
                    current_bb_lower * 0.99,
                    current_sma_50 * 0.98,
                ]
                entry_exit_points["take_profit_levels"] = [
                    current_price * 1.04,  # 4% ìµì ˆ
                    current_bb_upper * 1.01,
                    current_sma_20 * 1.02,
                ]

            elif current_regime == MarketRegime.SIDEWAYS:
                # íš¡ë³´ì¥: ë²”ìœ„ ë‚´ ê±°ë˜
                entry_exit_points["support_levels"] = [
                    current_bb_lower,
                    current_sma_50,
                    current_price * 0.985,
                ]
                entry_exit_points["resistance_levels"] = [
                    current_bb_upper,
                    current_sma_20,
                    current_price * 1.015,
                ]
                entry_exit_points["entry_signals"] = [
                    f"RSI < 35 (í˜„ì¬: {current_rsi:.1f})",
                    f"ì§€ì§€ì„  ê·¼ì²˜ ë§¤ìˆ˜ (í˜„ì¬: {current_price:.2f})",
                    f"ë³¼ë¦°ì € í•˜ë‹¨ ì§€ì§€",
                ]
                entry_exit_points["exit_signals"] = [
                    f"RSI > 65 (í˜„ì¬: {current_rsi:.1f})",
                    f"ì €í•­ì„  ê·¼ì²˜ ë§¤ë„ (í˜„ì¬: {current_price:.2f})",
                    f"ë³¼ë¦°ì € ìƒë‹¨ ì €í•­",
                ]
                entry_exit_points["stop_loss_levels"] = [
                    current_price * 0.965,  # 3.5% ì†ì ˆ
                    current_bb_lower * 0.995,
                    current_sma_50 * 0.985,
                ]
                entry_exit_points["take_profit_levels"] = [
                    current_price * 1.035,  # 3.5% ìµì ˆ
                    current_bb_upper * 1.005,
                    current_sma_20 * 1.015,
                ]

            return entry_exit_points

        except Exception as e:
            self.logger.warning(f"SPY ì§„ì…/ë§¤ë„ í¬ì¸íŠ¸ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}

    def _calculate_advanced_quant_indicators(
        self,
        spy_data: pd.DataFrame,
        macro_data: Dict[str, pd.DataFrame],
        optimal_params: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ê³ ê¸‰ Quant ì§€í‘œ ê³„ì‚°"""
        try:
            indicators = {}

            # 1. ë³€ë™ì„± êµ¬ì¡° ë¶„ì„
            returns = spy_data["close"].pct_change().dropna()
            indicators["volatility_structure"] = {
                "realized_vol": returns.std() * np.sqrt(252),
                "vol_of_vol": returns.rolling(20).std().std(),
                "vol_regime": (
                    "high"
                    if returns.std() > returns.rolling(60).std().mean()
                    else "normal"
                ),
            }

            # 2. ìƒê´€ê´€ê³„ ë¶„ì„
            if "^VIX" in macro_data and not macro_data["^VIX"].empty:
                vix_data = macro_data["^VIX"]
                close_col = "close" if "close" in vix_data.columns else "Close"
                vix_returns = vix_data[close_col].pct_change().dropna()

                # SPYì™€ VIXì˜ ìƒê´€ê´€ê³„
                correlation = returns.tail(len(vix_returns)).corr(vix_returns)
                indicators["correlation_analysis"] = {
                    "spy_vix_correlation": correlation,
                    "correlation_regime": (
                        "negative"
                        if correlation < -0.3
                        else "positive" if correlation > 0.3 else "neutral"
                    ),
                }

            # 3. ëª¨ë©˜í…€ êµ¬ì¡° ë¶„ì„ (ê³ ë„í™”)
            short_momentum = returns.tail(5).mean()
            medium_momentum = returns.tail(20).mean()
            long_momentum = returns.tail(60).mean()

            # ëª¨ë©˜í…€ ê°€ì†ë„ ê³„ì‚°
            momentum_acceleration = short_momentum - medium_momentum
            momentum_trend = medium_momentum - long_momentum

            # RSI ëª¨ë©˜í…€
            rsi_momentum = 0
            if "rsi" in spy_data.columns:
                rsi = spy_data["rsi"].tail(5)
                rsi_momentum = (rsi.iloc[-1] - rsi.iloc[0]) / 100  # RSI ë³€í™”ìœ¨

            # MACD ëª¨ë©˜í…€
            macd_momentum = 0
            if "macd" in spy_data.columns and "macd_signal" in spy_data.columns:
                macd = spy_data["macd"].tail(5)
                macd_signal = spy_data["macd_signal"].tail(5)
                macd_momentum = (
                    (macd.iloc[-1] - macd_signal.iloc[-1]) / abs(macd_signal.iloc[-1])
                    if abs(macd_signal.iloc[-1]) > 0
                    else 0
                )

            # ì¢…í•© ëª¨ë©˜í…€ ì •ë ¬ íŒë‹¨
            momentum_scores = []
            if short_momentum > medium_momentum > long_momentum:
                momentum_scores.append(1)  # ìƒìŠ¹ ì •ë ¬
            elif short_momentum < medium_momentum < long_momentum:
                momentum_scores.append(-1)  # í•˜ë½ ì •ë ¬
            else:
                momentum_scores.append(0)  # í˜¼ì¬

            if momentum_acceleration > 0:
                momentum_scores.append(1)
            elif momentum_acceleration < 0:
                momentum_scores.append(-1)
            else:
                momentum_scores.append(0)

            if rsi_momentum > 0:
                momentum_scores.append(1)
            elif rsi_momentum < 0:
                momentum_scores.append(-1)
            else:
                momentum_scores.append(0)

            if macd_momentum > 0:
                momentum_scores.append(1)
            elif macd_momentum < 0:
                momentum_scores.append(-1)
            else:
                momentum_scores.append(0)

            # ëª¨ë©˜í…€ ì •ë ¬ ê²°ì •
            avg_momentum_score = np.mean(momentum_scores)
            if avg_momentum_score > 0.3:
                momentum_alignment = "bullish"
            elif avg_momentum_score < -0.3:
                momentum_alignment = "bearish"
            else:
                momentum_alignment = "mixed"

            indicators["momentum_structure"] = {
                "short_momentum": short_momentum,
                "medium_momentum": medium_momentum,
                "long_momentum": long_momentum,
                "momentum_acceleration": momentum_acceleration,
                "momentum_trend": momentum_trend,
                "rsi_momentum": rsi_momentum,
                "macd_momentum": macd_momentum,
                "momentum_alignment": momentum_alignment,
                "momentum_score": avg_momentum_score,
            }

            # 4. ê±°ë˜ëŸ‰ ë¶„ì„
            if "volume" in spy_data.columns:
                volume = spy_data["volume"]
                indicators["volume_analysis"] = {
                    "volume_trend": volume.tail(20).mean() / volume.tail(60).mean(),
                    "volume_regime": (
                        "high"
                        if volume.tail(20).mean() > volume.tail(60).mean() * 1.2
                        else "normal"
                    ),
                }

            # 5. ì‹œì¥ ë¯¸ì„¸êµ¬ì¡° ë¶„ì„
            indicators["market_microstructure"] = {
                "bid_ask_spread_proxy": returns.abs().mean(),  # ê°„ë‹¨í•œ ìŠ¤í”„ë ˆë“œ í”„ë¡ì‹œ
                "price_efficiency": (
                    1.0 - abs(returns.autocorr()) if len(returns) > 1 else 0.5
                ),
                "liquidity_regime": "high" if returns.abs().mean() < 0.01 else "normal",
            }

            return indicators

        except Exception as e:
            self.logger.warning(f"ê³ ê¸‰ Quant ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return {}

    def _calculate_quant_score(
        self,
        classification_result: Dict[str, Any],
        regime_detection: Dict[str, Any],
        market_feedback: Dict[str, float],
        stat_arb_signals: Dict[str, Any],
        comprehensive_confidence: Dict[str, Any],
    ) -> float:
        """ì¢…í•© Quant ì ìˆ˜ ê³„ì‚°"""
        try:
            scores = []

            # 1. ê¸°ë³¸ ë¶„ë¥˜ ì‹ ë¢°ë„
            scores.append(classification_result.get("confidence", 0.5))

            # 2. Regime ì•ˆì •ì„±
            stability_score = regime_detection.get("stability_score", 0.5)
            scores.append(stability_score)

            # 3. Market Feedback ì„±ê³¼
            feedback_score = np.mean(list(market_feedback.values()))
            scores.append(feedback_score)

            # 4. Statistical Arbitrage ì‹ í˜¸ ê°•ë„
            arb_signal_strength = stat_arb_signals.get("signal_strength", 0.0)
            scores.append(min(1.0, arb_signal_strength * 2))  # 0.5ë¥¼ 1.0ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§

            # 5. ì¢…í•© ì‹ ë¢°ë„
            comprehensive_conf = comprehensive_confidence.get(
                "adjusted_confidence", 0.5
            )
            scores.append(comprehensive_conf)

            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            weights = [0.3, 0.2, 0.2, 0.15, 0.15]  # ê¸°ë³¸ ë¶„ë¥˜ì— ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜
            quant_score = np.average(scores, weights=weights)

            return max(0.0, min(1.0, quant_score))

        except Exception as e:
            self.logger.warning(f"Quant ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0.5

    def _perform_validation(
        self,
        spy_data: pd.DataFrame,
        macro_data: Dict[str, pd.DataFrame],
        regime_classification: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦"""
        try:
            # ì‹¤ì œ ìˆ˜ìµë¥ ê³¼ ì˜ˆì¸¡ ë¹„êµ
            actual_returns = spy_data["close"].pct_change().dropna()

            # ê°„ë‹¨í•œ ê²€ì¦ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ê²€ì¦ ë¡œì§ í•„ìš”)
            validation_results = {
                "data_quality": {
                    "spy_data_points": len(spy_data),
                    "macro_indicators": len(macro_data),
                    "data_completeness": 0.95,  # ì˜ˆì‹œ
                },
                "regime_consistency": {
                    "confidence_threshold_met": regime_classification["confidence"]
                    > 0.6,
                    "probability_sum": sum(
                        regime_classification["probabilities"].values()
                    ),
                },
            }

            return validation_results

        except Exception as e:
            self.logger.error(f"ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {}

    def _perform_rlmf_analysis(
        self, macro_analysis: MacroAnalysis, current_regime: MarketRegime
    ) -> Dict[str, Any]:
        """RLMF ì ì‘ ë¶„ì„ ìˆ˜í–‰"""
        try:
            # ë§¤í¬ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ìºì‹œëœ ë°ì´í„° ë¡œë“œ
            spy_data, macro_data, sector_data = self._load_cached_data()

            if spy_data.empty or not macro_data:
                self.logger.warning(
                    "ë§¤í¬ë¡œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ RLMF ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤."
                )
                return {
                    "statistical_arbitrage": {
                        "overall_signal": 0.0,
                        "confidence": 0.0,
                        "individual_signals": {},
                        "signal_strength": 0.0,
                        "direction": "NEUTRAL",
                    },
                    "market_feedback": {
                        "prediction_accuracy": 0.5,
                        "return_alignment": 0.5,
                        "volatility_prediction": 0.5,
                        "regime_persistence": 0.5,
                        "macro_consistency": 0.5,
                    },
                    "adaptation_status": self.rlmf_adaptation.get_adaptation_status(),
                    "learning_rate": self.rlmf_adaptation.learning_rate,
                }

            # Statistical Arbitrage ì‹ í˜¸ ê³„ì‚° (ì‹¤ì œ ë§¤í¬ë¡œ ë°ì´í„° ì‚¬ìš©)
            stat_arb_signal = (
                self.rlmf_adaptation.calculate_statistical_arbitrage_signal(macro_data)
            )

            # Market feedback ê³„ì‚° (ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)
            spy_returns = spy_data["close"].pct_change().dropna()
            market_feedback = self.rlmf_adaptation.calculate_market_feedback(
                current_regime.value,
                spy_returns.tail(20) if len(spy_returns) >= 20 else spy_returns,
                spy_data,
                macro_data,
            )

            return {
                "statistical_arbitrage": stat_arb_signal,
                "market_feedback": market_feedback,
                "adaptation_status": self.rlmf_adaptation.get_adaptation_status(),
                "learning_rate": self.rlmf_adaptation.learning_rate,
            }

        except Exception as e:
            self.logger.warning(f"RLMF ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "statistical_arbitrage": {
                    "overall_signal": 0.0,
                    "confidence": 0.0,
                    "individual_signals": {},
                    "signal_strength": 0.0,
                    "direction": "NEUTRAL",
                },
                "market_feedback": {
                    "prediction_accuracy": 0.5,
                    "return_alignment": 0.5,
                    "volatility_prediction": 0.5,
                    "regime_persistence": 0.5,
                    "macro_consistency": 0.5,
                },
                "adaptation_status": self.rlmf_adaptation.get_adaptation_status(),
                "learning_rate": self.rlmf_adaptation.learning_rate,
            }

    def _perform_confidence_analysis(
        self, basic_result: MarketAnalysisResult, rlmf_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë‹¤ì¸µ ì‹ ë¢°ë„ ë¶„ì„ ìˆ˜í–‰"""
        try:
            # ê¸°ë³¸ ì‹ ë¢°ë„ êµ¬ì„±ìš”ì†Œë“¤
            technical_conf = basic_result.confidence
            macro_conf = basic_result.macro_analysis.confidence

            # RLMF ê¸°ë°˜ ì‹ ë¢°ë„
            rlmf_conf = 0.5
            if rlmf_analysis and "market_feedback" in rlmf_analysis:
                feedback = rlmf_analysis["market_feedback"]
                rlmf_conf = feedback.get("prediction_accuracy", 0.5)

            # ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°
            confidence_result = (
                self.confidence_system.calculate_comprehensive_confidence(
                    technical_conf, macro_conf, 0.5, rlmf_conf, 0.5
                )
            )

            return {
                "confidence_result": confidence_result,
                "component_breakdown": {
                    "technical": technical_conf,
                    "macro": macro_conf,
                    "rlmf_feedback": rlmf_conf,
                },
            }

        except Exception as e:
            self.logger.warning(f"ì‹ ë¢°ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"confidence_result": {"adjusted_confidence": 0.5}}

    def _perform_regime_detection(
        self, macro_analysis: MacroAnalysis
    ) -> Dict[str, Any]:
        """Regime ì „í™˜ ê°ì§€ ìˆ˜í–‰"""
        try:
            # Regime shift ê°ì§€ (ì˜ˆì‹œ ë°ì´í„°)
            regime_shift = {
                "regime_shift_detected": False,
                "confidence": 0.5,
                "last_change_date": None,
            }

            return {
                "regime_shift_detection": regime_shift,
                "stability_analysis": {"stability_score": 0.7},
                "persistence_analysis": {"persistence_score": 0.8},
            }

        except Exception as e:
            self.logger.warning(f"Regime ê°ì§€ ì‹¤íŒ¨: {e}")
            return {}

    def _perform_llm_analysis(
        self, macro_analysis: MacroAnalysis, current_regime: MarketRegime
    ) -> Dict[str, Any]:
        """LLM íŠ¹ê¶Œ ì •ë³´ ë¶„ì„ ìˆ˜í–‰"""
        try:
            # ì‹œì¥ ë©”íŠ¸ë¦­ ì¤€ë¹„
            market_metrics = {
                "current_regime": current_regime.value,
                "market_condition": macro_analysis.market_condition.value,
                "confidence": macro_analysis.confidence,
            }

            # LLM íŠ¹ê¶Œ ì •ë³´ íšë“
            llm_insights = self.llm_privileged_system.get_privileged_insights(
                current_regime.value, {}, market_metrics
            )

            return llm_insights

        except Exception as e:
            self.logger.warning(f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def _perform_llm_api_analysis(
        self,
        macro_analysis: MacroAnalysis,
        current_regime: MarketRegime,
        analysis_results: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """LLM API í†µí•© ë¶„ì„ ìˆ˜í–‰"""
        try:
            # ì‹œì¥ ë©”íŠ¸ë¦­ ì¤€ë¹„
            market_metrics = {
                "current_regime": current_regime.value,
                "market_condition": macro_analysis.market_condition.value,
                "confidence": macro_analysis.confidence,
            }

            # LLM API í†µí•© ì¸ì‚¬ì´íŠ¸ íšë“ (ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í¬í•¨)
            llm_api_insights = self.llm_api_system.get_enhanced_insights(
                current_regime.value, {}, market_metrics, analysis_results
            )

            # API í†µê³„ ì¶”ê°€
            api_stats = self.llm_api_system.get_api_stats()
            llm_api_insights["api_stats"] = api_stats

            return llm_api_insights

        except Exception as e:
            self.logger.warning(f"LLM API ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def _calculate_final_confidence(
        self,
        basic_result: MarketAnalysisResult,
        rlmf_analysis: Dict[str, Any],
        confidence_analysis: Dict[str, Any],
        regime_detection: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ ì‹ ë¢°ë„
            base_confidence = basic_result.confidence

            # ê³ ê¸‰ ë¶„ì„ ì‹ ë¢°ë„ë“¤
            confidence_result = confidence_analysis.get("confidence_result", {})
            adjusted_confidence = confidence_result.get(
                "adjusted_confidence", base_confidence
            )

            # Regime ì „í™˜ ê°ì§€ ì˜í–¥
            regime_shift = regime_detection.get("regime_shift_detection", {})
            shift_confidence = regime_shift.get("confidence", 1.0)

            # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
            final_confidence = adjusted_confidence * shift_confidence
            final_confidence = max(0.0, min(1.0, final_confidence))

            return {
                "final_confidence": final_confidence,
                "base_confidence": base_confidence,
                "adjusted_confidence": adjusted_confidence,
                "regime_shift_impact": shift_confidence,
                "confidence_level": self._get_confidence_level(final_confidence),
            }

        except Exception as e:
            self.logger.warning(f"ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {"final_confidence": 0.5, "confidence_level": "MEDIUM"}

    def _get_confidence_level(self, confidence: float) -> str:
        """ì‹ ë¢°ë„ ìˆ˜ì¤€ ë¶„ë¥˜"""
        if confidence >= 0.8:
            return "VERY_HIGH"
        elif confidence >= 0.6:
            return "HIGH"
        elif confidence >= 0.4:
            return "MEDIUM"
        elif confidence >= 0.2:
            return "LOW"
        else:
            return "VERY_LOW"

    def _generate_basic_recommendations(
        self, macro_analysis: MacroAnalysis, current_regime: MarketRegime
    ) -> Dict[str, Any]:
        """ê¸°ë³¸ ì „ëµì  ì¶”ì²œ ìƒì„±"""
        try:
            self.logger.info(f"ê¸°ë³¸ ì¶”ì²œ ìƒì„± ì‹œì‘ - í˜„ì¬ ì²´ì œ: {current_regime}")
            recommendations = {
                "primary_strategy": "",
                "risk_level": "medium",
                "position_sizing": "MODERATE",
                "time_horizon": "MEDIUM",
                "overweight_sectors": [],
                "underweight_sectors": [],
                "neutral_sectors": [],
                "key_actions": [],
                "risk_warnings": [],
                "sector_rotation": [],
                # êµ¬ì²´ì ì¸ íˆ¬ì ì „ëµ ì¶”ê°€
                "position_size_percentage": 0.0,
                "stop_loss_percentage": 0.0,
                "take_profit_percentage": 0.0,
                "trailing_stop_percentage": 0.0,
                "hedging_strategy": "",
                "entry_points": [],
                "exit_strategy": "",
                "risk_management": {},
                "portfolio_allocation": {},
            }

            # ì²´ì œë³„ ê¸°ë³¸ ì „ëµ
            if current_regime == MarketRegime.TRENDING_UP:
                recommendations["primary_strategy"] = "BULLISH"
                recommendations["risk_level"] = "high"
                recommendations["position_sizing"] = "AGGRESSIVE"
                recommendations["position_size_percentage"] = 80.0
                recommendations["stop_loss_percentage"] = 5.0
                recommendations["take_profit_percentage"] = 15.0
                recommendations["trailing_stop_percentage"] = 3.0
                recommendations["hedging_strategy"] = "PUT ì˜µì…˜ í—¤ì§€ (10% ë¹„ì¤‘)"
                recommendations["entry_points"] = ["ì§€ì§€ì„  ëŒíŒŒ", "ëª¨ë©˜í…€ í™•ì¸"]
                recommendations["exit_strategy"] = "íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ + ìµì ˆ"
                recommendations["risk_management"] = {
                    "max_drawdown": 8.0,
                    "position_limit": 25.0,
                    "correlation_limit": 0.7,
                }
                # ë ˆì´ ë‹¬ë¦¬ì˜¤ ì˜¬ì›¨ë” í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ë°˜ (ê°•ì„¸ì¥ ì¡°ì •)
                recommendations["portfolio_allocation"] = {
                    "equity": 40.0,  # 30% ê¸°ë³¸ + 10% ì¶”ê°€
                    "bonds_short": 5.0,
                    "bonds_intermediate": 15.0,  # 7-10ë…„ êµ­ì±„
                    "bonds_long": 25.0,  # 20-25ë…„ êµ­ì±„
                    "gold": 7.5,
                    "commodities": 7.5,
                    "cash": 0.0,
                }
                recommendations["key_actions"].append("ëª¨ë©˜í…€ íŒ”ë¡œì‰ ì „ëµ")
                recommendations["key_actions"].append("ìˆœí™˜ì  ì„¹í„° ì¤‘ ì„ ë„ ì„¹í„° ì§‘ì¤‘")

            elif current_regime == MarketRegime.TRENDING_DOWN:
                recommendations["primary_strategy"] = "BEARISH"
                recommendations["risk_level"] = "low"
                recommendations["position_sizing"] = "CONSERVATIVE"
                recommendations["position_size_percentage"] = 30.0
                recommendations["stop_loss_percentage"] = 3.0
                recommendations["take_profit_percentage"] = 8.0
                recommendations["trailing_stop_percentage"] = 2.0
                recommendations["hedging_strategy"] = (
                    "SHORT í¬ì§€ì…˜ + PUT ì˜µì…˜ (20% ë¹„ì¤‘)"
                )
                recommendations["entry_points"] = [
                    "ì €í•­ì„  í•˜í–¥ ëŒíŒŒ",
                    "ê¸°ìˆ ì  ì•½ì„¸ í™•ì¸",
                ]
                recommendations["exit_strategy"] = "ë³´ìˆ˜ì  ìµì ˆ + ìŠ¤íƒ‘ë¡œìŠ¤"
                recommendations["risk_management"] = {
                    "max_drawdown": 5.0,
                    "position_limit": 15.0,
                    "correlation_limit": 0.5,
                }
                # ë ˆì´ ë‹¬ë¦¬ì˜¤ ì˜¬ì›¨ë” í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ë°˜ (ì•½ì„¸ì¥ ì¡°ì •)
                recommendations["portfolio_allocation"] = {
                    "equity": 20.0,  # 30% ê¸°ë³¸ - 10% ê°ì†Œ
                    "bonds_short": 10.0,
                    "bonds_intermediate": 20.0,  # 7-10ë…„ êµ­ì±„ ì¦ê°€
                    "bonds_long": 30.0,  # 20-25ë…„ êµ­ì±„ ì¦ê°€
                    "gold": 10.0,  # ì¸í”Œë ˆì´ì…˜ í—¤ì§€ ì¦ê°€
                    "commodities": 10.0,
                    "cash": 0.0,
                }
                recommendations["key_actions"].append("ë°©ì–´ì  í¬ì§€ì…”ë‹")
                recommendations["key_actions"].append("ë°©ì–´ì  ì„¹í„° ì§‘ì¤‘")

            elif current_regime == MarketRegime.VOLATILE:
                recommendations["primary_strategy"] = "VOLATILITY_HEDGE"
                recommendations["risk_level"] = "medium"
                recommendations["position_sizing"] = "CAUTIOUS"
                recommendations["position_size_percentage"] = 50.0
                recommendations["stop_loss_percentage"] = 4.0
                recommendations["take_profit_percentage"] = 10.0
                recommendations["trailing_stop_percentage"] = 2.5
                recommendations["hedging_strategy"] = (
                    "VIX ETF + PUT ìŠ¤í”„ë ˆë“œ (15% ë¹„ì¤‘)"
                )
                recommendations["entry_points"] = ["ë³€ë™ì„± ìˆ˜ì¶• ì‹œì ", "ì§€ì§€ì„  ê·¼ì²˜"]
                recommendations["exit_strategy"] = "ë¹ ë¥¸ ìµì ˆ + ë³€ë™ì„± í—¤ì§€"
                recommendations["risk_management"] = {
                    "max_drawdown": 6.0,
                    "position_limit": 20.0,
                    "correlation_limit": 0.6,
                }
                # ë ˆì´ ë‹¬ë¦¬ì˜¤ ì˜¬ì›¨ë” í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ë°˜ (ë³€ë™ì„± ë†’ì€ ì‹œì¥)
                recommendations["portfolio_allocation"] = {
                    "equity": 25.0,  # 30% ê¸°ë³¸ - 5% ê°ì†Œ
                    "bonds_short": 7.5,
                    "bonds_intermediate": 17.5,  # 7-10ë…„ êµ­ì±„
                    "bonds_long": 27.5,  # 20-25ë…„ êµ­ì±„
                    "gold": 8.75,  # ì¸í”Œë ˆì´ì…˜ í—¤ì§€
                    "commodities": 8.75,
                    "cash": 5.0,  # ìœ ë™ì„± ë³´ìœ 
                }
                recommendations["key_actions"].append("ë³€ë™ì„± í—¤ì§€ ì „ëµ")
                recommendations["key_actions"].append("ì˜µì…˜ ìŠ¤í”„ë ˆë“œ í™œìš©")

            elif current_regime == MarketRegime.SIDEWAYS:
                recommendations["primary_strategy"] = "RANGE_TRADING"
                recommendations["risk_level"] = "medium"
                recommendations["position_sizing"] = "MODERATE"
                recommendations["position_size_percentage"] = 60.0
                recommendations["stop_loss_percentage"] = 3.5
                recommendations["take_profit_percentage"] = 7.0
                recommendations["trailing_stop_percentage"] = 2.0
                recommendations["hedging_strategy"] = "CALL/PUT ìŠ¤í”„ë ˆë“œ (10% ë¹„ì¤‘)"
                recommendations["entry_points"] = [
                    "ì§€ì§€ì„  ê·¼ì²˜ ë§¤ìˆ˜",
                    "ì €í•­ì„  ê·¼ì²˜ ë§¤ë„",
                ]
                recommendations["exit_strategy"] = "ë²”ìœ„ ë‚´ ìµì ˆ + ìŠ¤íƒ‘ë¡œìŠ¤"
                recommendations["risk_management"] = {
                    "max_drawdown": 5.5,
                    "position_limit": 20.0,
                    "correlation_limit": 0.6,
                }
                # ë ˆì´ ë‹¬ë¦¬ì˜¤ ì˜¬ì›¨ë” í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ë°˜ (íš¡ë³´ì¥)
                recommendations["portfolio_allocation"] = {
                    "equity": 30.0,  # ê¸°ë³¸ 30%
                    "bonds_short": 7.5,
                    "bonds_intermediate": 15.0,  # 7-10ë…„ êµ­ì±„
                    "bonds_long": 25.0,  # 20-25ë…„ êµ­ì±„
                    "gold": 7.5,
                    "commodities": 7.5,
                    "cash": 7.5,  # íš¡ë³´ì¥ì—ì„œ í˜„ê¸ˆ ë¹„ì¤‘
                }
                recommendations["key_actions"].append("ë²”ìœ„ ë‚´ ê±°ë˜")
                recommendations["key_actions"].append("ì§€ì§€/ì €í•­ì„  í™œìš©")

            # ë§¤í¬ë¡œ ì¡°ê±´ë³„ ì¶”ê°€ ì „ëµ
            market_condition = macro_analysis.market_condition
            if market_condition == MarketCondition.RECESSION_FEAR:
                recommendations["risk_warnings"].append(
                    "ê²½ê¸°ì¹¨ì²´ ìš°ë ¤ - í˜„ê¸ˆ ë¹„ì¤‘ í™•ëŒ€ ê³ ë ¤"
                )
                recommendations["key_actions"].append("êµ­ì±„ ë¹„ì¤‘ í™•ëŒ€")
            elif market_condition == MarketCondition.INFLATION_FEAR:
                recommendations["risk_warnings"].append(
                    "ì¸í”Œë ˆì´ì…˜ ìš°ë ¤ - ì‹¤ë¬¼ìì‚° ë¹„ì¤‘ í™•ëŒ€"
                )
                recommendations["key_actions"].append("TIPS ë° ì‹¤ë¬¼ìì‚° íˆ¬ì")

            # ì„¹í„° ë¡œí…Œì´ì…˜ ì¶”ì²œ
            for sector, strength in macro_analysis.sector_rotation.items():
                if strength == SectorStrength.LEADING:
                    recommendations["overweight_sectors"].append(sector)
                    recommendations["sector_rotation"].append(f"OVERWEIGHT: {sector}")
                elif strength == SectorStrength.LAGGING:
                    recommendations["underweight_sectors"].append(sector)
                    recommendations["sector_rotation"].append(f"UNDERWEIGHT: {sector}")
                else:
                    recommendations["neutral_sectors"].append(sector)

            # ë§¤í¬ë¡œ ë¶„ì„ì˜ ì¶”ì²œ ì •ë³´ ì¶”ê°€
            if (
                hasattr(macro_analysis, "recommendations")
                and macro_analysis.recommendations
            ):
                recommendations.update(macro_analysis.recommendations)

            return recommendations

        except Exception as e:
            self.logger.warning(f"ê¸°ë³¸ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "primary_strategy": "BALANCED",
                "risk_level": "medium",
                "position_sizing": "MODERATE",
                "time_horizon": "MEDIUM",
                "position_size_percentage": 50.0,
                "stop_loss_percentage": 4.0,
                "take_profit_percentage": 10.0,
                "trailing_stop_percentage": 2.5,
                "hedging_strategy": "ê¸°ë³¸ í—¤ì§€ ì—†ìŒ",
                "entry_points": ["ê¸°ìˆ ì  ì§€ì§€ì„ ", "ëª¨ë©˜í…€ í™•ì¸"],
                "exit_strategy": "ìŠ¤íƒ‘ë¡œìŠ¤ + ìµì ˆ",
                "risk_management": {
                    "max_drawdown": 6.0,
                    "position_limit": 20.0,
                    "correlation_limit": 0.6,
                },
                "portfolio_allocation": {
                    "equity": 30.0,  # ë ˆì´ ë‹¬ë¦¬ì˜¤ ì˜¬ì›¨ë” ê¸°ë³¸
                    "bonds_short": 7.5,
                    "bonds_intermediate": 15.0,  # 7-10ë…„ êµ­ì±„
                    "bonds_long": 25.0,  # 20-25ë…„ êµ­ì±„
                    "gold": 7.5,
                    "commodities": 7.5,
                    "cash": 7.5,
                },
            }

    def _generate_enhanced_recommendations(
        self,
        basic_result: MarketAnalysisResult,
        rlmf_analysis: Dict[str, Any],
        regime_detection: Dict[str, Any],
        llm_insights: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ê³ ë„í™”ëœ ì „ëµì  ì¶”ì²œ ìƒì„±"""
        try:
            recommendations = basic_result.enhanced_recommendations.copy()
            recommendations["advanced_insights"] = []
            recommendations["llm_recommendations"] = []

            # RLMF ë¶„ì„ ê¸°ë°˜ ì¶”ì²œ
            if rlmf_analysis:
                stat_arb = rlmf_analysis.get("statistical_arbitrage", {})
                if stat_arb.get("direction") == "BULLISH":
                    recommendations["key_considerations"].append(
                        "Statistical Arbitrage ì‹ í˜¸: ê°•ì„¸"
                    )
                elif stat_arb.get("direction") == "BEARISH":
                    recommendations["key_considerations"].append(
                        "Statistical Arbitrage ì‹ í˜¸: ì•½ì„¸"
                    )

            # Regime ì „í™˜ ê°ì§€ ê¸°ë°˜ ì¶”ì²œ
            if regime_detection.get("regime_shift_detection", {}).get(
                "regime_shift_detected", False
            ):
                recommendations["key_considerations"].append(
                    "âš ï¸ ì‹œì¥ ì²´ì œ ì „í™˜ ê°ì§€ë¨ - ì‹ ì¤‘í•œ ì ‘ê·¼ í•„ìš”"
                )

            # LLM ì¸ì‚¬ì´íŠ¸ ê¸°ë°˜ ì¶”ì²œ
            if llm_insights:
                strategic_recs = llm_insights.get("strategic_recommendations", [])
                recommendations["llm_recommendations"].extend(strategic_recs[:3])

            # ì‹ ë¢°ë„ ê¸°ë°˜ í¬ì§€ì…˜ ì‚¬ì´ì§• ì¡°ì •
            final_confidence = basic_result.final_confidence.get(
                "final_confidence", 0.5
            )
            if final_confidence >= 0.7:
                recommendations["position_sizing"] = "AGGRESSIVE"
            elif final_confidence <= 0.3:
                recommendations["position_sizing"] = "CONSERVATIVE"

            return recommendations

        except Exception as e:
            self.logger.warning(f"ê³ ë„í™”ëœ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"primary_strategy": "BALANCED", "position_sizing": "MODERATE"}

    def _save_analysis_result(
        self, result: MarketAnalysisResult, output_dir: str, verbose: bool = True
    ):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            os.makedirs(output_dir, exist_ok=True)

            # JSON í˜•íƒœë¡œ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"{output_dir}/analysis_results_{timestamp}.json"

            # Random Forest ëª¨ë¸ ì •ë³´ ì¶”ê°€
            rf_info = {
                "model_used": self.use_random_forest,
                "accuracy": None,
                "trained_at": None,
            }

            if self.use_random_forest and self.rf_model:
                try:
                    # ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    model_file = self.rf_model.model_dir / "market_regime_rf_model.pkl"
                    if model_file.exists():
                        import joblib

                        model_data = joblib.load(model_file)
                        rf_info["trained_at"] = model_data.get("trained_at", "Unknown")
                        # ì •í™•ë„ëŠ” í•™ìŠµ ì‹œì—ë§Œ ê³„ì‚°ë˜ë¯€ë¡œ Noneìœ¼ë¡œ ìœ ì§€
                except Exception as e:
                    self.logger.warning(f"Random Forest ëª¨ë¸ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")

            # ë°ì´í„°í´ë˜ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            result_dict = {
                "session_uuid": result.session_uuid,
                "timestamp": result.timestamp.isoformat(),
                "analysis_type": result.analysis_type,
                "data_period": result.data_period,
                "current_regime": result.current_regime.value,
                "confidence": result.confidence,
                "probabilities": result.probabilities,
                "macro_analysis": {
                    "market_condition": result.macro_analysis.market_condition.value,
                    "confidence": result.macro_analysis.confidence,
                    "key_indicators": result.macro_analysis.key_indicators,
                    "sector_rotation": {
                        k: v.value
                        for k, v in result.macro_analysis.sector_rotation.items()
                    },
                    "recommendations": result.macro_analysis.recommendations,
                },
                "optimal_params": result.optimal_params,
                "optimization_performance": result.optimization_performance,
                "validation_results": result.validation_results,
                "rlmf_analysis": result.rlmf_analysis,
                "confidence_analysis": result.confidence_analysis,
                "regime_detection": result.regime_detection,
                "llm_insights": result.llm_insights,
                "llm_api_insights": result.llm_api_insights,
                "final_confidence": result.final_confidence,
                "enhanced_recommendations": result.enhanced_recommendations,
                "random_forest_info": rf_info,
            }

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(result_dict, f, indent=2, ensure_ascii=False, default=str)

            if verbose:
                print(f"âœ… ê²°ê³¼ ì €ì¥: {output_file}")

        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _print_basic_summary(self, result: MarketAnalysisResult):
        """ê¸°ë³¸ ë¶„ì„ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š ìƒì„¸ ì‹œì¥ ë¶„ì„ ê²°ê³¼")
        print("=" * 80)

        # 1. ì‹œì¥ ì²´ì œ ë¶„ì„ (Quant ê¸°ë°˜ + ML ê¸°ë°˜)
        print("\nğŸ¯ 1. ì‹œì¥ ì²´ì œ ë¶„ì„")
        print("-" * 40)

        # Quant ê¸°ë°˜ ë¶„ì„ (ê³ ê¸‰)
        print("ğŸ“Š Quant ê¸°ë°˜ ë¶„ì„ (ê³ ê¸‰):")
        print(f"  í˜„ì¬ ì²´ì œ: {result.current_regime.value}")

        # ê¸°ë³¸ ì‹ ë¢°ë„ (Random Forest)
        base_confidence = (
            result.classification_result.get("confidence", 0.5)
            if result.classification_result
            else 0.5
        )
        print(f"  ê¸°ë³¸ ì‹ ë¢°ë„: {base_confidence:.3f}")

        # ë‹¤ì¸µ ì‹ ë¢°ë„ ì‹œìŠ¤í…œ ê²°ê³¼
        if result.confidence_analysis:
            confidence_analysis = result.confidence_analysis
            adjusted_confidence = confidence_analysis.get(
                "adjusted_confidence", base_confidence
            )
            consistency_score = confidence_analysis.get("consistency_score", 0.5)

            print(f"  ğŸ¯ ë‹¤ì¸µ ì‹ ë¢°ë„: {adjusted_confidence:.3f}")
            print(f"  ğŸ”— ì¼ê´€ì„± ì ìˆ˜: {consistency_score:.3f}")

            # êµ¬ì„±ìš”ì†Œë³„ ì‹ ë¢°ë„
            component_confidences = confidence_analysis.get("component_confidences", {})
            if component_confidences:
                print(f"  ğŸ“Š êµ¬ì„±ìš”ì†Œë³„ ì‹ ë¢°ë„:")
                component_names = {
                    "technical": "ê¸°ìˆ ì  ë¶„ì„",
                    "macro": "ë§¤í¬ë¡œ í™˜ê²½",
                    "statistical_arb": "í†µê³„ì  ì°¨ìµê±°ë˜",
                    "rlmf_feedback": "RLMF í”¼ë“œë°±",
                    "cross_validation": "êµì°¨ ê²€ì¦",
                }
                for component, value in component_confidences.items():
                    component_name = component_names.get(component, component)
                    print(f"    â€¢ {component_name}: {value:.3f}")
        else:
            print(f"  ğŸ¯ ìµœì¢… ì‹ ë¢°ë„: {result.confidence:.3f}")

        # ê³ ê¸‰ Quant ë¶„ì„ ê²°ê³¼ í‘œì‹œ (classification_resultì—ì„œ ì§ì ‘ ì ‘ê·¼)
        enhanced_keys = [
            "quant_score",
            "regime_detection",
            "rlmf_analysis",
            "confidence_analysis",
            "advanced_indicators",
        ]

        # MarketAnalysisResult ê°ì²´ì—ì„œ classification_result ì ‘ê·¼
        classification_result = (
            result.classification_result if result.classification_result else {}
        )
        has_enhanced = any(
            key in classification_result and classification_result[key]
            for key in enhanced_keys
        )

        if has_enhanced:
            # Quant ì ìˆ˜
            if (
                "quant_score" in classification_result
                and classification_result["quant_score"]
            ):
                print(f"  ğŸ¯ Quant ì ìˆ˜: {classification_result['quant_score']:.3f}")

            # Regime ê°ì§€ ê²°ê³¼
            if (
                "regime_detection" in classification_result
                and classification_result["regime_detection"]
            ):
                regime_det = classification_result["regime_detection"]
                print(f"  ğŸ”„ Regime ì•ˆì •ì„±: {regime_det.get('stability_score', 0):.3f}")
                print(
                    f"  â±ï¸ ì˜ˆìƒ ì§€ì†ê¸°ê°„: {regime_det.get('expected_duration', 'unknown')}"
                )
                if regime_det.get("shift_detected", False):
                    print(
                        f"  âš ï¸ Regime ë³€í™” ê°ì§€! (ì ìˆ˜: {regime_det.get('shift_score', 0):.3f})"
                    )

            # RLMF ë¶„ì„ ê²°ê³¼
            if (
                "rlmf_analysis" in classification_result
                and classification_result["rlmf_analysis"]
            ):
                rlmf = classification_result["rlmf_analysis"]
                if "market_feedback" in rlmf:
                    feedback = rlmf["market_feedback"]
                    avg_feedback = np.mean(list(feedback.values())) if feedback else 0.5
                    print(f"  ğŸ§  RLMF í”¼ë“œë°±: {avg_feedback:.3f}")

                if "statistical_arbitrage" in rlmf:
                    stat_arb = rlmf["statistical_arbitrage"]

                    direction = stat_arb.get("direction", "NEUTRAL")
                    signal_strength = stat_arb.get("signal_strength", 0)
                    confidence = stat_arb.get("confidence", 0)
                    print(
                        f"  ğŸ“ˆ Statistical Arbitrage: {direction} (ê°•ë„: {signal_strength:.3f}, ì‹ ë¢°ë„: {confidence:.3f})"
                    )

                    # ê°œë³„ ì‹ í˜¸ í‘œì‹œ
                    individual_signals = stat_arb.get("individual_signals", {})
                    if individual_signals:
                        print(f"    â””â”€ ê°œë³„ ì‹ í˜¸:")
                        for metric, signal_data in individual_signals.items():
                            signal = signal_data.get("signal", 0)
                            ret = signal_data.get("return", 0)
                            weight = signal_data.get("weight", 0)
                            print(
                                f"      â€¢ {metric}: {signal:+.1f} (ìˆ˜ìµë¥ : {ret:+.1%}, ê°€ì¤‘ì¹˜: {weight:.0%})"
                            )

            # ì‹ ë¢°ë„ ë¶„ì„ ê²°ê³¼
            if (
                "confidence_analysis" in classification_result
                and classification_result["confidence_analysis"]
            ):
                conf_analysis = classification_result["confidence_analysis"]
                adjusted_conf = conf_analysis.get("adjusted_confidence", 0.5)
                consistency = conf_analysis.get("consistency_score", 0.5)
                print(f"  ğŸ¯ ì¡°ì •ëœ ì‹ ë¢°ë„: {adjusted_conf:.3f}")
                print(f"  ğŸ”— ì¼ê´€ì„± ì ìˆ˜: {consistency:.3f}")

            # ê³ ê¸‰ ì§€í‘œ
            if (
                "advanced_indicators" in classification_result
                and classification_result["advanced_indicators"]
            ):
                indicators = classification_result["advanced_indicators"]
                if "volatility_structure" in indicators:
                    vol_struct = indicators["volatility_structure"]
                    vol_regime = vol_struct.get("vol_regime", "normal")
                    print(f"  ğŸ“Š ë³€ë™ì„± ì²´ì œ: {vol_regime}")

                if "momentum_structure" in indicators:
                    mom_struct = indicators["momentum_structure"]
                    mom_alignment = mom_struct.get("momentum_alignment", "mixed")
                    momentum_score = mom_struct.get("momentum_score", 0)
                    print(
                        f"  ğŸš€ ëª¨ë©˜í…€ ì •ë ¬: {mom_alignment} (ì ìˆ˜: {momentum_score:.3f})"
                    )

                    # ìƒì„¸ ëª¨ë©˜í…€ ì •ë³´
                    short_mom = mom_struct.get("short_momentum", 0)
                    medium_mom = mom_struct.get("medium_momentum", 0)
                    long_mom = mom_struct.get("long_momentum", 0)
                    accel = mom_struct.get("momentum_acceleration", 0)
                    print(
                        f"    â””â”€ ë‹¨ê¸°: {short_mom:+.1%}, ì¤‘ê¸°: {medium_mom:+.1%}, ì¥ê¸°: {long_mom:+.1%}, ê°€ì†ë„: {accel:+.1%}"
                    )

        # ML ê¸°ë°˜ ë¶„ì„ (Random Forest)
        if hasattr(self, "use_random_forest") and self.use_random_forest:
            print("\nğŸ¤– ML ê¸°ë°˜ ë¶„ì„ (Random Forest):")
            if result.probabilities:
                # ML í™•ë¥ ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
                sorted_probs = sorted(
                    result.probabilities.items(), key=lambda x: x[1], reverse=True
                )
                for i, (regime, prob) in enumerate(sorted_probs):
                    regime_name = regime.replace("_", " ").title()
                    rank_emoji = (
                        "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else "  "
                    )
                    print(f"  {rank_emoji} {regime_name}: {prob:.1%}")

                # ìµœê³  í™•ë¥  ì²´ì œ í‘œì‹œ
                top_regime, top_prob = sorted_probs[0]
                top_regime_name = top_regime.replace("_", " ").title()
                print(f"  ğŸ¯ ML ì˜ˆì¸¡ ìµœê³  í™•ë¥ : {top_regime_name} ({top_prob:.1%})")

            # Quant vs ML ë¹„êµ
            if result.probabilities:
                quant_regime = result.current_regime.value
                ml_regime = sorted_probs[0][0].replace("_", " ").title()
                if quant_regime.upper() == ml_regime.upper():
                    print(f"  âœ… Quantì™€ ML ì˜ˆì¸¡ ì¼ì¹˜: {quant_regime}")
                else:
                    print(
                        f"  âš ï¸ Quantì™€ ML ì˜ˆì¸¡ ì°¨ì´: Quant={quant_regime}, ML={ml_regime}"
                    )
        else:
            print("\nğŸ“ˆ ì²´ì œë³„ í™•ë¥  (Quant ê¸°ë°˜):")
            if result.probabilities:
                for regime, prob in result.probabilities.items():
                    regime_name = regime.replace("_", " ").title()
                    print(f"  â€¢ {regime_name}: {prob:.1%}")

        # 2. ë§¤í¬ë¡œ í™˜ê²½ ë¶„ì„
        print("\nğŸŒ 2. ë§¤í¬ë¡œ í™˜ê²½ ë¶„ì„")
        print("-" * 40)
        print(f"ì‹œì¥ ì¡°ê±´: {result.macro_analysis.market_condition.value}")

        # ì£¼ìš” ì§€í‘œ ë¶„ì„
        if result.macro_analysis.key_indicators:
            print("\nğŸ“Š ì£¼ìš” ë§¤í¬ë¡œ ì§€í‘œ:")
            for indicator, value in result.macro_analysis.key_indicators.items():
                if isinstance(value, float):
                    print(f"  â€¢ {indicator}: {value:.3f}")
                else:
                    print(f"  â€¢ {indicator}: {value}")

        # 3. ì„¹í„° ë¶„ì„
        print("\nğŸ­ 3. ì„¹í„° ë¶„ì„")
        print("-" * 40)

        # ì„¹í„° ë¡œí…Œì´ì…˜ ë¶„ì„
        if result.macro_analysis.sector_rotation:
            print("ğŸ“Š ì„¹í„°ë³„ ê°•ë„ ë¶„ì„:")
            leading_sectors = []
            lagging_sectors = []
            neutral_sectors = []

            for sector, strength in result.macro_analysis.sector_rotation.items():
                if strength.value == "LEADING":
                    leading_sectors.append(sector)
                elif strength.value == "LAGGING":
                    lagging_sectors.append(sector)
                else:
                    neutral_sectors.append(sector)

            if leading_sectors:
                print(f"  ğŸš€ ì„ ë„ ì„¹í„°: {', '.join(leading_sectors)}")
            if lagging_sectors:
                print(f"  ğŸ“‰ í›„í–‰ ì„¹í„°: {', '.join(lagging_sectors)}")
            if neutral_sectors:
                print(f"  â¡ï¸ ì¤‘ë¦½ ì„¹í„°: {', '.join(neutral_sectors)}")
        else:
            print("  ğŸ“Š ì„¹í„° ë°ì´í„° ì—†ìŒ")
            print("  ğŸ” ì„¹í„° ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

            # ì„¹í„° ë°ì´í„° ìˆ˜ì§‘ ì‹œë„
            try:
                spy_data, macro_data, sector_data = self._load_cached_data()
                if sector_data:
                    print(f"  âœ… ìºì‹œëœ ì„¹í„° ë°ì´í„° ë°œê²¬: {list(sector_data.keys())}")
                    # ì„¹í„° ë¶„ì„ ì¬ìˆ˜í–‰
                    sector_analysis = self.macro_analyzer.analyze_sector_rotation(
                        sector_data
                    )
                    if sector_analysis:
                        print("  ğŸ“ˆ ì„¹í„° ë¶„ì„ ê²°ê³¼:")
                        for sector, strength in sector_analysis.items():
                            strength_emoji = (
                                "ğŸš€"
                                if strength.value == "LEADING"
                                else "ğŸ“‰" if strength.value == "LAGGING" else "â¡ï¸"
                            )
                            print(f"    {strength_emoji} {sector}: {strength.value}")
                    else:
                        print("  âš ï¸ ì„¹í„° ë¶„ì„ ì‹¤íŒ¨")
                else:
                    print("  âš ï¸ ì„¹í„° ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            except Exception as e:
                print(f"  âŒ ì„¹í„° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

        # ì„¹í„°ë³„ ìƒì„¸ ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)
        if (
            hasattr(result.macro_analysis, "sector_performance")
            and result.macro_analysis.sector_performance
        ):
            print("\nğŸ“ˆ ì„¹í„°ë³„ ì„±ê³¼:")
            for sector, perf in result.macro_analysis.sector_performance.items():
                if isinstance(perf, dict):
                    return_val = perf.get("return", 0)
                    volatility = perf.get("volatility", 0)
                    print(
                        f"  â€¢ {sector}: ìˆ˜ìµë¥  {return_val:+.2%}, ë³€ë™ì„± {volatility:.2%}"
                    )

        # ì„¹í„°ë³„ ìƒì„¸ ë¶„ì„ (ì¶”ê°€ ì •ë³´)
        if result.macro_analysis.sector_rotation:
            print("\nğŸ” ì„¹í„°ë³„ ìƒì„¸ ë¶„ì„:")

            # ì„¹í„° ë¶„ë¥˜ ì •ë³´ (ì†Œë¬¸ìë¡œ í†µì¼)
            sector_classification = {
                "xlk": "Technology (ìˆœí™˜ì )",
                "xlf": "Financials (ìˆœí™˜ì )",
                "xle": "Energy (ìˆœí™˜ì )",
                "xlv": "Healthcare (ë°©ì–´ì )",
                "xli": "Industrials (ìˆœí™˜ì )",
                "xlp": "Consumer Staples (ë°©ì–´ì )",
                "xlu": "Utilities (ë°©ì–´ì )",
                "xlb": "Materials (ìˆœí™˜ì )",
                "xlre": "Real Estate (ìˆœí™˜ì )",
            }

            for sector, strength in result.macro_analysis.sector_rotation.items():
                sector_name = sector_classification.get(sector, f"{sector} (ë¯¸ë¶„ë¥˜)")
                strength_emoji = (
                    "ğŸš€"
                    if strength.value == "LEADING"
                    else "ğŸ“‰" if strength.value == "LAGGING" else "â¡ï¸"
                )
                print(f"  {strength_emoji} {sector}: {sector_name} - {strength.value}")

            # ì„¹í„° ë¡œí…Œì´ì…˜ íŒ¨í„´ ë¶„ì„ (ê°œì„ ëœ ë²„ì „)
            leading_count = sum(
                1
                for s in result.macro_analysis.sector_rotation.values()
                if hasattr(s, "value") and s.value == "leading"
            )
            lagging_count = sum(
                1
                for s in result.macro_analysis.sector_rotation.values()
                if hasattr(s, "value") and s.value == "lagging"
            )
            neutral_count = sum(
                1
                for s in result.macro_analysis.sector_rotation.values()
                if hasattr(s, "value")
                and s.value in ["neutral", "cyclical", "defensive"]
            )
            total_sectors = len(result.macro_analysis.sector_rotation)

            if total_sectors > 0:
                leading_ratio = leading_count / total_sectors
                lagging_ratio = lagging_count / total_sectors
                neutral_ratio = neutral_count / total_sectors

                print(f"\nğŸ“Š ì„¹í„° ë¡œí…Œì´ì…˜ íŒ¨í„´:")
                print(
                    f"  â€¢ ì„ ë„ ì„¹í„° ë¹„ìœ¨: {leading_ratio:.1%} ({leading_count}/{total_sectors})"
                )
                print(
                    f"  â€¢ í›„í–‰ ì„¹í„° ë¹„ìœ¨: {lagging_ratio:.1%} ({lagging_count}/{total_sectors})"
                )
                print(
                    f"  â€¢ ì¤‘ë¦½ ì„¹í„° ë¹„ìœ¨: {neutral_ratio:.1%} ({neutral_count}/{total_sectors})"
                )

                # ì„¹í„° ê°•ë„ë³„ ë¶„ë¥˜ ê°œì„ 
                if leading_count > 0:
                    print(
                        f"  ğŸš€ ì„ ë„ ì„¹í„°: {', '.join([s for s, strength in result.macro_analysis.sector_rotation.items() if hasattr(strength, 'value') and strength.value == 'leading'])}"
                    )
                if lagging_count > 0:
                    print(
                        f"  ğŸ“‰ í›„í–‰ ì„¹í„°: {', '.join([s for s, strength in result.macro_analysis.sector_rotation.items() if hasattr(strength, 'value') and strength.value == 'lagging'])}"
                    )
                if neutral_count > 0:
                    print(
                        f"  â¡ï¸ ì¤‘ë¦½ ì„¹í„°: {', '.join([s for s, strength in result.macro_analysis.sector_rotation.items() if hasattr(strength, 'value') and strength.value in ['neutral', 'cyclical', 'defensive']])}"
                    )

                # ì‹œì¥ ì „ë§ íŒë‹¨ ê°œì„ 
                if leading_ratio > 0.4:
                    print(f"  ğŸ¯ ì‹œì¥ ì „ë§: ìˆœí™˜ì  ì„¹í„° ì„ í˜¸ (ê°•ì„¸ì¥ ì‹ í˜¸)")
                elif lagging_ratio > 0.4:
                    print(f"  âš ï¸ ì‹œì¥ ì „ë§: ë°©ì–´ì  ì„¹í„° ì„ í˜¸ (ì•½ì„¸ì¥ ì‹ í˜¸)")
                elif neutral_ratio > 0.6:
                    print(f"  â¡ï¸ ì‹œì¥ ì „ë§: ì¤‘ë¦½ì  ì„¹í„° ìš°ì„¸ (íš¡ë³´ì¥ ì‹ í˜¸)")
                else:
                    print(f"  ğŸ”„ ì‹œì¥ ì „ë§: í˜¼ì¬ëœ ì‹ í˜¸ (ë°©í–¥ì„± ë¶ˆëª…í™•)")

                # ì„¹í„° ë°°ì¹˜ ì¶”ì²œ
                print(f"\nğŸ“ˆ ê³¼ì¤‘ ë°°ì¹˜ ì„¹í„°:")
                leading_sectors = [
                    s
                    for s, strength in result.macro_analysis.sector_rotation.items()
                    if hasattr(strength, "value") and strength.value == "leading"
                ]
                for i, sector in enumerate(leading_sectors, 1):
                    print(f"  {i}. {sector}")

                print(f"\nğŸ“‰ ê³¼ì†Œ ë°°ì¹˜ ì„¹í„°:")
                lagging_sectors = [
                    s
                    for s, strength in result.macro_analysis.sector_rotation.items()
                    if hasattr(strength, "value") and strength.value == "lagging"
                ]
                for i, sector in enumerate(lagging_sectors, 1):
                    print(f"  {i}. {sector}")

                print(f"\nğŸ”„ ì„¹í„° ë¡œí…Œì´ì…˜:")
                rotation_count = 1
                for sector in leading_sectors:
                    print(f"  {rotation_count}. OVERWEIGHT: {sector}")
                    rotation_count += 1
                for sector in lagging_sectors:
                    print(f"  {rotation_count}. UNDERWEIGHT: {sector}")
                    rotation_count += 1
            else:
                print(f"\nğŸ“Š ì„¹í„° ë¡œí…Œì´ì…˜ íŒ¨í„´:")
                print(f"  âš ï¸ ì„¹í„° ë°ì´í„° ì—†ìŒ")

        # 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        print("\nâš™ï¸ 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”")
        print("-" * 40)

        # ìµœì í™” ì„±ê³¼
        opt_perf = result.optimization_performance
        strategy_sharpe = opt_perf.get("sharpe_ratio", 0)
        strategy_return = opt_perf.get("total_return", 0)
        strategy_drawdown = opt_perf.get("max_drawdown", 0)

        print(f"ğŸ“Š ìµœì í™” ì „ëµ ì„±ê³¼:")
        print(f"  â€¢ Sharpe Ratio: {strategy_sharpe:.4f}")
        print(f"  â€¢ Total Return: {strategy_return:.2%}")
        print(f"  â€¢ Max Drawdown: {strategy_drawdown:.2%}")

        # Buy & Hold ë¹„êµ
        buyhold_return = opt_perf.get("buyhold_return", 0)
        buyhold_sharpe = opt_perf.get("buyhold_sharpe", 0)
        buyhold_drawdown = opt_perf.get("buyhold_drawdown", 0)

        if buyhold_return != 0:
            print(f"\nğŸ“ˆ Buy & Hold ë¹„êµ:")
            print(f"  â€¢ Buy & Hold Return: {buyhold_return:.2%}")
            print(f"  â€¢ Buy & Hold Sharpe: {buyhold_sharpe:.4f}")
            print(f"  â€¢ Buy & Hold Max DD: {buyhold_drawdown:.2%}")

            # ì„±ê³¼ ë¹„êµ
            excess_return = strategy_return - buyhold_return
            excess_sharpe = strategy_sharpe - buyhold_sharpe
            print(f"\nğŸ¯ ì„±ê³¼ ë¹„êµ:")
            print(f"  â€¢ ì´ˆê³¼ ìˆ˜ìµë¥ : {excess_return:+.2%}")
            print(f"  â€¢ ì´ˆê³¼ Sharpe: {excess_sharpe:+.4f}")

            if excess_return > 0:
                print(f"  âœ… ìµœì í™” ì „ëµì´ Buy & Hold ëŒ€ë¹„ ìš°ìˆ˜")
            else:
                print(f"  âš ï¸ ìµœì í™” ì „ëµì´ Buy & Hold ëŒ€ë¹„ ì—´ìœ„")

        # 5. ì „ëµ ì¶”ì²œ
        print("\nğŸ’¡ 5. ì „ëµ ì¶”ì²œ")
        print("-" * 40)

        # ì „ëµ ì¶”ì²œ ìƒì„± (enhanced_recommendationsê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì¶”ì²œ ìƒì„±)
        if result.enhanced_recommendations:
            rec = result.enhanced_recommendations
        else:
            # ê¸°ë³¸ ì¶”ì²œ ìƒì„±
            rec = self._generate_basic_recommendations(
                result.macro_analysis, result.current_regime
            )

        # ì£¼ìš” ì „ëµ
        primary_strategy = rec.get("primary_strategy", "N/A")
        risk_level = rec.get("risk_level", "N/A")
        position_sizing = rec.get("position_sizing", "N/A")
        time_horizon = rec.get("time_horizon", "N/A")

        print(f"ğŸ¯ ì£¼ìš” ì „ëµ: {primary_strategy}")
        print(f"âš ï¸ ìœ„í—˜ ìˆ˜ì¤€: {risk_level}")
        print(f"ğŸ’° í¬ì§€ì…˜ ì‚¬ì´ì§•: {position_sizing}")
        print(f"â±ï¸ íˆ¬ì ê¸°ê°„: {time_horizon}")

        # êµ¬ì²´ì ì¸ íˆ¬ì ì „ëµ ì •ë³´
        position_size = rec.get("position_size_percentage", 0.0)
        stop_loss = rec.get("stop_loss_percentage", 0.0)
        take_profit = rec.get("take_profit_percentage", 0.0)
        trailing_stop = rec.get("trailing_stop_percentage", 0.0)
        hedging = rec.get("hedging_strategy", "N/A")
        entry_points = rec.get("entry_points", [])
        exit_strategy = rec.get("exit_strategy", "N/A")

        print(f"\nğŸ“Š êµ¬ì²´ì ì¸ íˆ¬ì ì „ëµ:")
        print(f"  ğŸ’° í¬ì§€ì…˜ í¬ê¸°: {position_size:.1f}%")
        print(f"  ğŸ›‘ ì†ì ˆ: -{stop_loss:.1f}%")
        print(f"  ğŸ¯ ìµì ˆ: +{take_profit:.1f}%")
        print(f"  ğŸ“ˆ íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘: {trailing_stop:.1f}%")
        print(f"  ğŸ›¡ï¸ í—·ì§• ì „ëµ: {hedging}")
        print(f"  ğŸšª ì§„ì… ì „ëµ: {', '.join(entry_points) if entry_points else 'N/A'}")
        print(f"  ğŸšª ì²­ì‚° ì „ëµ: {exit_strategy}")

        # í¬íŠ¸í´ë¦¬ì˜¤ ë°°ë¶„
        portfolio_allocation = rec.get("portfolio_allocation", {})
        if portfolio_allocation:
            print(f"\nğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ë°°ë¶„:")
            for asset, percentage in portfolio_allocation.items():
                asset_name = {
                    "equity": "ì£¼ì‹",
                    "bonds_short": "ë‹¨ê¸°ì±„ê¶Œ",
                    "bonds_intermediate": "ì¤‘ê¸°ì±„ê¶Œ",
                    "bonds_long": "ì¥ê¸°ì±„ê¶Œ",
                    "gold": "ê¸ˆ",
                    "commodities": "ìƒí’ˆ",
                    "cash": "í˜„ê¸ˆ",
                }.get(asset, asset)
                print(f"  â€¢ {asset_name}: {percentage:.1f}%")

        # ë¦¬ìŠ¤í¬ ê´€ë¦¬
        risk_management = rec.get("risk_management", {})
        if risk_management:
            print(f"\nâš ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬:")
            max_dd = risk_management.get("max_drawdown", 0.0)
            pos_limit = risk_management.get("position_limit", 0.0)
            corr_limit = risk_management.get("correlation_limit", 0.0)
            print(f"  â€¢ ìµœëŒ€ ì†ì‹¤: {max_dd:.1f}%")
            print(f"  â€¢ í¬ì§€ì…˜ í•œë„: {pos_limit:.1f}%")
            print(f"  â€¢ ìƒê´€ê´€ê³„ í•œë„: {corr_limit:.1f}")

        # SPY ì§„ì…/ë§¤ë„ í¬ì¸íŠ¸ (classification_resultì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        if (
            result.classification_result
            and "spy_entry_exit_points" in result.classification_result
        ):
            spy_points = result.classification_result["spy_entry_exit_points"]
            if spy_points:
                current_price = spy_points.get("current_price", 0.0)
                tech_indicators = spy_points.get("technical_indicators", {})

                print(f"\nğŸ“Š SPY ì§„ì…/ë§¤ë„ í¬ì¸íŠ¸ (í˜„ì¬ê°€: ${current_price:.2f}):")

                # ê¸°ìˆ ì  ì§€í‘œ
                if tech_indicators:
                    rsi = tech_indicators.get("rsi", 0.0)
                    macd = tech_indicators.get("macd", 0.0)
                    macd_signal = tech_indicators.get("macd_signal", 0.0)
                    sma_20 = tech_indicators.get("sma_20", 0.0)
                    sma_50 = tech_indicators.get("sma_50", 0.0)
                    bb_upper = tech_indicators.get("bb_upper", 0.0)
                    bb_lower = tech_indicators.get("bb_lower", 0.0)

                    print(f"  ğŸ“ˆ ê¸°ìˆ ì  ì§€í‘œ:")
                    print(f"    â€¢ RSI: {rsi:.1f}")
                    print(f"    â€¢ MACD: {macd:.2f} (Signal: {macd_signal:.2f})")
                    print(f"    â€¢ SMA20: ${sma_20:.2f}")
                    print(f"    â€¢ SMA50: ${sma_50:.2f}")
                    print(f"    â€¢ ë³¼ë¦°ì € ìƒë‹¨: ${bb_upper:.2f}")
                    print(f"    â€¢ ë³¼ë¦°ì € í•˜ë‹¨: ${bb_lower:.2f}")

                # ì§€ì§€/ì €í•­ì„ 
                support_levels = spy_points.get("support_levels", [])
                resistance_levels = spy_points.get("resistance_levels", [])

                if support_levels:
                    print(f"  ğŸ›¡ï¸ ì§€ì§€ì„ :")
                    for i, level in enumerate(support_levels[:3], 1):
                        print(f"    {i}. ${level:.2f}")

                if resistance_levels:
                    print(f"  ğŸš§ ì €í•­ì„ :")
                    for i, level in enumerate(resistance_levels[:3], 1):
                        print(f"    {i}. ${level:.2f}")

                # ì§„ì…/ë§¤ë„ ì‹ í˜¸
                entry_signals = spy_points.get("entry_signals", [])
                exit_signals = spy_points.get("exit_signals", [])

                if entry_signals:
                    print(f"  ğŸšª ì§„ì… ì‹ í˜¸:")
                    for signal in entry_signals[:3]:
                        print(f"    â€¢ {signal}")

                if exit_signals:
                    print(f"  ğŸšª ë§¤ë„ ì‹ í˜¸:")
                    for signal in exit_signals[:3]:
                        print(f"    â€¢ {signal}")

                # ì†ì ˆ/ìµì ˆ ë ˆë²¨
                stop_loss_levels = spy_points.get("stop_loss_levels", [])
                take_profit_levels = spy_points.get("take_profit_levels", [])

                if stop_loss_levels:
                    print(f"  ğŸ›‘ ì†ì ˆ ë ˆë²¨:")
                    for i, level in enumerate(stop_loss_levels[:3], 1):
                        print(f"    {i}. ${level:.2f}")

                if take_profit_levels:
                    print(f"  ğŸ¯ ìµì ˆ ë ˆë²¨:")
                    for i, level in enumerate(take_profit_levels[:3], 1):
                        print(f"    {i}. ${level:.2f}")

        # ì „ëµ ìƒì„¸ ì„¤ëª…
        strategy_explanations = {
            "RANGE_TRADING": "ì§€ì§€/ì €í•­ì„ ì„ í™œìš©í•œ ë²”ìœ„ ë‚´ ê±°ë˜ ì „ëµ",
            "MOMENTUM_FOLLOWING": "ìƒìŠ¹ ëª¨ë©˜í…€ì„ ë”°ë¼ê°€ëŠ” ì¶”ì„¸ ì¶”ì¢… ì „ëµ",
            "MEAN_REVERSION": "í‰ê·  íšŒê·€ë¥¼ í™œìš©í•œ ë°˜ëŒ€ í¬ì§€ì…˜ ì „ëµ",
            "DEFENSIVE_POSITIONING": "ìœ„í—˜ íšŒí”¼ë¥¼ ìœ„í•œ ë°©ì–´ì  í¬ì§€ì…˜ ì „ëµ",
            "INFLATION_HEDGE": "ì¸í”Œë ˆì´ì…˜ í—¤ì§€ë¥¼ ìœ„í•œ ì‹¤ë¬¼ìì‚° íˆ¬ì ì „ëµ",
            "RECESSION_HEDGE": "ê²½ê¸°ì¹¨ì²´ í—¤ì§€ë¥¼ ìœ„í•œ ì•ˆì „ìì‚° íˆ¬ì ì „ëµ",
        }

        if primary_strategy in strategy_explanations:
            print(f"ğŸ“– ì „ëµ ì„¤ëª…: {strategy_explanations[primary_strategy]}")

        # ì‹œì¥ ìƒí™©ë³„ ì „ëµ ì í•©ì„±
        current_regime = result.current_regime.value
        regime_strategy_fit = {
            "SIDEWAYS": "RANGE_TRADING",
            "TRENDING_UP": "MOMENTUM_FOLLOWING",
            "TRENDING_DOWN": "DEFENSIVE_POSITIONING",
            "VOLATILE": "DEFENSIVE_POSITIONING",
        }

        if current_regime in regime_strategy_fit:
            recommended_strategy = regime_strategy_fit[current_regime]
            if primary_strategy == recommended_strategy:
                print(f"âœ… ì „ëµ ì í•©ì„±: í˜„ì¬ ì‹œì¥ ì²´ì œ({current_regime})ì™€ ì „ëµì´ ì¼ì¹˜")
            else:
                print(
                    f"âš ï¸ ì „ëµ ì í•©ì„±: í˜„ì¬ ì‹œì¥ ì²´ì œ({current_regime})ì—ëŠ” {recommended_strategy} ì „ëµì´ ë” ì í•©í•  ìˆ˜ ìˆìŒ"
                )

        # í•µì‹¬ ì•¡ì…˜
        if "key_actions" in rec and rec["key_actions"]:
            print(f"\nğŸš€ í•µì‹¬ ì•¡ì…˜:")
            for i, action in enumerate(rec["key_actions"], 1):
                print(f"  {i}. {action}")

        # ìœ„í—˜ ê²½ê³ 
        if "risk_warnings" in rec and rec["risk_warnings"]:
            print(f"\nâš ï¸ ìœ„í—˜ ê²½ê³ :")
            for i, warning in enumerate(rec["risk_warnings"], 1):
                print(f"  {i}. {warning}")

        # ì¶”ê°€ ì „ëµì  ê³ ë ¤ì‚¬í•­
        print(f"\nğŸ” ì¶”ê°€ ì „ëµì  ê³ ë ¤ì‚¬í•­:")

        # ì‹ ë¢°ë„ ê¸°ë°˜ í¬ì§€ì…˜ ì‚¬ì´ì§•
        confidence = result.confidence
        if confidence > 0.7:
            print(f"  â€¢ ë†’ì€ ì‹ ë¢°ë„({confidence:.1%}) - ê³µê²©ì  í¬ì§€ì…˜ ì‚¬ì´ì§• ê³ ë ¤")
        elif confidence < 0.4:
            print(f"  â€¢ ë‚®ì€ ì‹ ë¢°ë„({confidence:.1%}) - ë³´ìˆ˜ì  í¬ì§€ì…˜ ì‚¬ì´ì§• ê¶Œì¥")
        else:
            print(f"  â€¢ ì¤‘ê°„ ì‹ ë¢°ë„({confidence:.1%}) - ì¤‘ë¦½ì  í¬ì§€ì…˜ ì‚¬ì´ì§•")

        # ë³€ë™ì„± ê¸°ë°˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬
        if "volatility_regime" in result.macro_analysis.key_indicators:
            vol_regime = result.macro_analysis.key_indicators["volatility_regime"]
            if vol_regime == "high":
                print(f"  â€¢ ë†’ì€ ë³€ë™ì„± í™˜ê²½ - ìŠ¤íƒ‘ë¡œìŠ¤ ì„¤ì • ë° í¬ì§€ì…˜ í¬ê¸° ì¶•ì†Œ ê¶Œì¥")
            elif vol_regime == "normal":
                print(f"  â€¢ ì •ìƒ ë³€ë™ì„± í™˜ê²½ - í‘œì¤€ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì ìš©")

        # ë§¤í¬ë¡œ í™˜ê²½ ê¸°ë°˜ ì¶”ê°€ ê³ ë ¤ì‚¬í•­
        market_condition = result.macro_analysis.market_condition.value
        if market_condition == "bull_market":
            print(f"  â€¢ ê°•ì„¸ì¥ í™˜ê²½ - ëª¨ë©˜í…€ ì „ëµ ë° ë ˆë²„ë¦¬ì§€ í™œìš© ê³ ë ¤")
        elif market_condition == "recession_fear":
            print(f"  â€¢ ê²½ê¸°ì¹¨ì²´ ìš°ë ¤ - í˜„ê¸ˆ ë¹„ì¤‘ í™•ëŒ€ ë° ì•ˆì „ìì‚° ë¹„ì¤‘ í™•ëŒ€")
        elif market_condition == "inflation_fear":
            print(f"  â€¢ ì¸í”Œë ˆì´ì…˜ ìš°ë ¤ - ì‹¤ë¬¼ìì‚° ë° TIPS ë¹„ì¤‘ í™•ëŒ€")

        else:
            print("  ğŸ“Š ì¶”ì²œ ë°ì´í„° ì—†ìŒ")

        print("\n" + "=" * 80)

    def _print_enhanced_summary(self, result: MarketAnalysisResult):
        """ê³ ë„í™”ëœ ë¶„ì„ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸš€ ê³ ë„í™”ëœ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")

        # Quant vs ML ë¹„êµ
        if (
            hasattr(self, "use_random_forest")
            and self.use_random_forest
            and result.probabilities
        ):
            quant_regime = result.current_regime.value
            sorted_probs = sorted(
                result.probabilities.items(), key=lambda x: x[1], reverse=True
            )
            ml_regime = sorted_probs[0][0].replace("_", " ").title()

            print(f"ğŸ“Š Quant ê¸°ë°˜ ì²´ì œ: {quant_regime}")
            print(f"ğŸ¤– ML ê¸°ë°˜ ì²´ì œ: {ml_regime}")

            if quant_regime.upper() == ml_regime.upper():
                print(f"âœ… Quantì™€ ML ì˜ˆì¸¡ ì¼ì¹˜")
            else:
                print(f"âš ï¸ Quantì™€ ML ì˜ˆì¸¡ ì°¨ì´")
        else:
            print(f"í˜„ì¬ ì²´ì œ: {result.current_regime.value}")

        print(f"ìµœì¢… ì‹ ë¢°ë„: {result.final_confidence.get('final_confidence', 0):.3f}")
        print(f"ë§¤í¬ë¡œ ì¡°ê±´: {result.macro_analysis.market_condition.value}")

        if result.llm_api_insights:
            api_stats = result.llm_api_insights.get("api_stats", {})
            print(f"LLM API ì„±ê³µë¥ : {api_stats.get('success_rate', 0):.2%}")

        print(
            f"ì£¼ìš” ì „ëµ: {result.enhanced_recommendations.get('primary_strategy', 'N/A')}"
        )
        print(
            f"í¬ì§€ì…˜ ì‚¬ì´ì§•: {result.enhanced_recommendations.get('position_sizing', 'N/A')}"
        )

    def enable_llm_api(self, llm_config: Dict[str, Any]):
        """LLM API ì‹œìŠ¤í…œ í™œì„±í™”"""
        try:
            self.llm_api_system = LLMAPIIntegration(llm_config)
            self.llm_config = llm_config
            self.logger.info("LLM API í†µí•© ì‹œìŠ¤í…œ í™œì„±í™”ë¨")
        except Exception as e:
            self.logger.error(f"LLM API ì‹œìŠ¤í…œ í™œì„±í™” ì‹¤íŒ¨: {e}")

    def disable_llm_api(self):
        """LLM API ì‹œìŠ¤í…œ ë¹„í™œì„±í™”"""
        self.llm_api_system = None
        self.llm_config = None
        self.logger.info("LLM API í†µí•© ì‹œìŠ¤í…œ ë¹„í™œì„±í™”ë¨")

    def get_llm_api_stats(self) -> Dict[str, Any]:
        """LLM API í†µê³„ ë°˜í™˜"""
        if self.llm_api_system:
            return self.llm_api_system.get_api_stats()
        return {"status": "disabled"}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description="ê³ ë„í™”ëœ Market Sensor ì‹œìŠ¤í…œ")
    parser.add_argument(
        "--analysis-type",
        choices=["basic", "enhanced"],
        default="enhanced",
        help="ë¶„ì„ ìœ í˜• ì„ íƒ (ê¸°ë³¸ê°’: enhanced)",
    )
    parser.add_argument(
        "--output-dir", default="results/macro/enhanced", help="ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--use-cached-data", action="store_true", help="ì €ì¥ëœ ë§¤í¬ë¡œ ë°ì´í„° ì‚¬ìš©"
    )
    parser.add_argument(
        "--use-cached-optimization", action="store_true", help="ì €ì¥ëœ ìµœì í™” ê²°ê³¼ ì‚¬ìš©"
    )
    parser.add_argument("--cache-days", type=int, default=1, help="ìºì‹œ ìœ íš¨ê¸°ê°„ (ì¼)")
    parser.add_argument("--enable-llm", action="store_true", help="LLM API í™œì„±í™”")
    parser.add_argument(
        "--use-random-forest",
        action="store_true",
        default=True,
        help="Random Forest ëª¨ë¸ ì‚¬ìš© (ê¸°ë³¸ê°’: True)",
    )
    parser.add_argument(
        "--retrain-rf-model", action="store_true", help="Random Forest ëª¨ë¸ ì¬í•™ìŠµ"
    )
    parser.add_argument(
        "--no-random-forest",
        action="store_true",
        help="Random Forest ëª¨ë¸ ì‚¬ìš© ì•ˆí•¨ (ê·œì¹™ ê¸°ë°˜ ì‚¬ìš©)",
    )

    args = parser.parse_args()

    # Random Forest ì˜µì…˜ ì²˜ë¦¬
    use_random_forest = args.use_random_forest and not args.no_random_forest
    retrain_rf_model = args.retrain_rf_model

    print("ğŸš€ ê³ ë„í™”ëœ Market Sensor ì‹œìŠ¤í…œ ì‹œì‘")
    print(f"ë¶„ì„ ìœ í˜•: {args.analysis_type}")
    print(
        f"ìºì‹œ ì„¤ì •: ë°ì´í„°={args.use_cached_data}, ìµœì í™”={args.use_cached_optimization}"
    )
    print(f"Random Forest: {'ì‚¬ìš©' if use_random_forest else 'ì‚¬ìš© ì•ˆí•¨'}")
    if use_random_forest and retrain_rf_model:
        print("Random Forest ëª¨ë¸ ì¬í•™ìŠµ ëª¨ë“œ")

    # LLM API ì„¤ì • (ì„ íƒì‚¬í•­)
    llm_config = None
    if args.enable_llm:
        llm_config = {
            "provider": "hybrid",
            "model_name": "anthropic.claude-3-sonnet-20240229-v1:0",
            "fallback_to_rules": True,
        }

    # Market Sensor ì´ˆê¸°í™”
    sensor = MarketSensor(
        enable_llm_api=args.enable_llm,
        llm_config=llm_config,
        use_cached_data=args.use_cached_data,
        use_cached_optimization=args.use_cached_optimization,
        cache_days=args.cache_days,
        use_random_forest=use_random_forest,
        retrain_rf_model=retrain_rf_model,
    )

    # ë¶„ì„ ìˆ˜í–‰
    if args.analysis_type == "basic":
        result = sensor.run_basic_analysis(output_dir=args.output_dir, verbose=True)
    else:
        result = sensor.run_enhanced_analysis(output_dir=args.output_dir, verbose=True)

    if result:
        print("\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")
    else:
        print("\nâŒ ë¶„ì„ ì‹¤íŒ¨!")


if __name__ == "__main__":
    main()
