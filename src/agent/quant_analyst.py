#!/usr/bin/env python3
"""
ì •ëŸ‰ ë¶„ì„ ì‹œìŠ¤í…œ
ì¢…ê°€ ê¸°ì¤€ ìˆ˜ìµë¥ ì„ ì¢…ì†ë³€ìˆ˜ë¡œ í•˜ì—¬ ë‹¤ì–‘í•œ ìš”ì¸ë“¤ì˜ ì˜í–¥ì„ ë¶„ì„
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
import argparse
import json
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from behavior.correlation import CorrelationAnalyzer
from behavior.linear_regression import LinearRegressionAnalyzer
from behavior.lasso_regression import LassoRegressionAnalyzer
from behavior.random_forest import RandomForestAnalyzer
from behavior.multi_layer_perceptron import MLPAnalyzer
from behavior.bayesian_distribution import BayesianDistributionAnalyzer
from agent.helper import (
    Logger,
    load_config,
    load_and_preprocess_data,
    DEFAULT_CONFIG_PATH,
    DEFAULT_DATA_DIR,
)


class QuantAnalyst:
    """ì •ëŸ‰ ë¶„ì„ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(
        self,
        data_dir: str = DEFAULT_DATA_DIR,
        config_path: str = DEFAULT_CONFIG_PATH,
        return_type: str = "percentage",  # "percentage" or "log"
        top_features: int = 10,
    ):
        self.data_dir = data_dir
        self.config = load_config(config_path)
        self.return_type = return_type
        self.top_features = top_features
        self.logger = Logger()
        self.analysis_start_time = datetime.now()

        # ë¶„ì„ê¸°ë“¤ ì´ˆê¸°í™”
        self.correlation_analyzer = CorrelationAnalyzer()
        self.linear_regression_analyzer = LinearRegressionAnalyzer()
        self.lasso_regression_analyzer = LassoRegressionAnalyzer()
        self.random_forest_analyzer = RandomForestAnalyzer()
        self.mlp_analyzer = MLPAnalyzer()
        self.bayesian_analyzer = BayesianDistributionAnalyzer()

        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.analysis_results = {}
        self.prepared_data = {}

    def prepare_data(
        self, data_dict: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """ë°ì´í„° ì „ì²˜ë¦¬ ë° ìˆ˜ìµë¥  ê³„ì‚°"""
        self.logger.log_info("ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ë° ìˆ˜ìµë¥  ê³„ì‚° ì¤‘...")

        # ì‹œê³„ì—´ ê´€ë ¨ ì»¬ëŸ¼ë“¤ê³¼ ì¤‘ë³µ íŠ¹ì„±ë“¤ ì œì™¸ ë¦¬ìŠ¤íŠ¸
        excluded_columns = {
            "datetime",
            "date",
            "time",
            "timestamp",
            "open",
            "high",
            "low",
            "close",
            "volume",
            "adjusted_close",
            "dividend_amount",
            "split_coefficient",
            "returns",  # ì´ì „ ìˆ˜ìµë¥  - targetê³¼ ì¤‘ë³µë˜ì–´ ì œì™¸
        }

        prepared_data = {}

        for symbol, data in data_dict.items():
            # ë°ì´í„° ë³µì‚¬
            df = data.copy()

            # ìˆ˜ìµë¥  ê³„ì‚° (target ë³€ìˆ˜)
            if self.return_type == "log":
                df["return"] = np.log(df["close"] / df["close"].shift(1))
            else:  # percentage
                df["return"] = df["close"].pct_change() * 100

            # NaN ì œê±°
            df = df.dropna()

            # ì œì™¸ ì»¬ëŸ¼ë“¤ì„ ì œì™¸í•œ íŠ¹ì„± ì»¬ëŸ¼ë“¤ ì„ íƒ
            feature_columns = [
                col
                for col in df.columns
                if col not in excluded_columns and col != "return"
            ]

            # ìˆ«ìí˜• ë°ì´í„°ë§Œ ì„ íƒ
            numeric_columns = []
            for col in feature_columns:
                try:
                    pd.to_numeric(df[col], errors="raise")
                    numeric_columns.append(col)
                except (ValueError, TypeError):
                    self.logger.log_info(f"    {symbol}: {col} ì»¬ëŸ¼ ì œì™¸ (ìˆ«ìê°€ ì•„ë‹˜)")

            # ìˆ˜ìµë¥ ì„ ë§ˆì§€ë§‰ ì»¬ëŸ¼ìœ¼ë¡œ ì´ë™
            columns_order = numeric_columns + ["return"]
            df = df[columns_order]

            # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
            for col in numeric_columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")

            # NaN ì œê±° (ìˆ«ì ë³€í™˜ í›„)
            df = df.dropna()

            prepared_data[symbol] = df
            self.logger.log_info(
                f"  {symbol}: {len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸, {len(numeric_columns)}ê°œ íŠ¹ì„±"
            )

        self.prepared_data = prepared_data
        return prepared_data

    def run_correlation_analysis(self, symbol: str) -> Dict[str, Any]:
        """ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤í–‰"""
        self.logger.log_info(f"ğŸ” {symbol} ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤í–‰...")

        data = self.prepared_data[symbol]
        result = self.correlation_analyzer.analyze(
            data, target_column="return", top_n=self.top_features
        )

        self.analysis_results[symbol] = {"correlation": result}
        return result

    def run_linear_regression_analysis(
        self, symbol: str, top_features: int = 5
    ) -> Dict[str, Any]:
        """ì„ í˜•íšŒê·€ ë¶„ì„ ì‹¤í–‰"""
        self.logger.log_info(f"ğŸ“ˆ {symbol} ì„ í˜•íšŒê·€ ë¶„ì„ ì‹¤í–‰...")

        data = self.prepared_data[symbol]

        # ìƒìœ„ íŠ¹ì„± ì„ íƒ
        if (
            symbol in self.analysis_results
            and "correlation" in self.analysis_results[symbol]
        ):
            top_corr_features = self.analysis_results[symbol]["correlation"][
                "top_features"
            ]
            selected_features = top_corr_features[
                : min(top_features, len(top_corr_features))
            ]
        else:
            # ìƒê´€ê´€ê³„ ë¶„ì„ì´ ì—†ìœ¼ë©´ ëª¨ë“  íŠ¹ì„± ì‚¬ìš©
            feature_columns = [col for col in data.columns if col != "return"]
            selected_features = feature_columns[:top_features]

        result = self.linear_regression_analyzer.analyze(
            data, target_column="return", feature_columns=selected_features
        )

        if symbol not in self.analysis_results:
            self.analysis_results[symbol] = {}
        self.analysis_results[symbol]["linear_regression"] = result
        return result

    def run_lasso_regression_analysis(self, symbol: str) -> Dict[str, Any]:
        """Lasso íšŒê·€ ë¶„ì„ ì‹¤í–‰"""
        self.logger.log_info(f"ğŸ¯ {symbol} Lasso íšŒê·€ ë¶„ì„ ì‹¤í–‰...")

        data = self.prepared_data[symbol]
        feature_columns = [col for col in data.columns if col != "return"]

        result = self.lasso_regression_analyzer.analyze(
            data, target_column="return", feature_columns=feature_columns
        )

        if symbol not in self.analysis_results:
            self.analysis_results[symbol] = {}
        self.analysis_results[symbol]["lasso_regression"] = result
        return result

    def run_random_forest_analysis(self, symbol: str) -> Dict[str, Any]:
        """ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ì„ ì‹¤í–‰"""
        self.logger.log_info(f"ğŸŒ² {symbol} ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ì„ ì‹¤í–‰...")

        data = self.prepared_data[symbol]
        feature_columns = [col for col in data.columns if col != "return"]

        result = self.random_forest_analyzer.analyze(
            data, target_column="return", feature_columns=feature_columns
        )

        if symbol not in self.analysis_results:
            self.analysis_results[symbol] = {}
        self.analysis_results[symbol]["random_forest"] = result
        return result

    def run_mlp_analysis(self, symbol: str) -> Dict[str, Any]:
        """MLP ë¶„ì„ ì‹¤í–‰"""
        self.logger.log_info(f"ğŸ§  {symbol} MLP ë¶„ì„ ì‹¤í–‰...")

        data = self.prepared_data[symbol]
        feature_columns = [col for col in data.columns if col != "return"]

        result = self.mlp_analyzer.analyze(
            data, target_column="return", feature_columns=feature_columns
        )

        if symbol not in self.analysis_results:
            self.analysis_results[symbol] = {}
        self.analysis_results[symbol]["mlp"] = result
        return result

    def run_bayesian_distribution_analysis(self, symbol: str) -> Dict[str, Any]:
        """ë² ì´ì§€ì•ˆ ë¶„í¬ ë¶„ì„ ì‹¤í–‰"""
        self.logger.log_info(f"ğŸ”® {symbol} ë² ì´ì§€ì•ˆ ë¶„í¬ ë¶„ì„ ì‹¤í–‰...")

        data = self.prepared_data[symbol]

        # 1. ìˆ˜ìµë¥  ë¶„í¬ ë¶„ì„
        dist_result = self.bayesian_analyzer.analyze_return_distribution(
            data, target_column="return"
        )

        # 2. ë² ì´ì§€ì•ˆ íšŒê·€ ë¶„ì„
        reg_result = self.bayesian_analyzer.analyze_bayesian_regression(
            data, target_column="return"
        )

        # 3. ë³€ë™ì„± ë¶„ì„
        vol_result = self.bayesian_analyzer.analyze_volatility(
            data, target_column="return", window=20
        )

        if symbol not in self.analysis_results:
            self.analysis_results[symbol] = {}
        self.analysis_results[symbol]["bayesian_distribution"] = dist_result
        self.analysis_results[symbol]["bayesian_regression"] = reg_result
        self.analysis_results[symbol]["volatility"] = vol_result
        return {
            "distribution": dist_result,
            "regression": reg_result,
            "volatility": vol_result,
        }

    def run_full_analysis(self, symbols: List[str] = None) -> Dict[str, Any]:
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        # ë¡œê±° ì„¤ì •
        self.logger.setup_logger(
            strategy="quant_analysis", symbols=symbols or [], mode="analysis"
        )

        # ì¢…í•© ìš”ì•½ ë¡œê±° ì„¤ì •
        self.logger.setup_summary_logger(
            symbols=symbols or [], timestamp=self.analysis_start_time
        )

        self.logger.log_section("ğŸ¯ ì •ëŸ‰ ë¶„ì„ ì‹œìŠ¤í…œ ì‹œì‘")
        self.logger.log_info(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {self.data_dir}")
        self.logger.log_info(f"ğŸ“Š ìˆ˜ìµë¥  íƒ€ì…: {self.return_type}")
        self.logger.log_info(f"ğŸ” ìƒìœ„ íŠ¹ì„± ìˆ˜: {self.top_features}")

        # ë°ì´í„° ë¡œë“œ
        self.logger.log_info("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
        data_dict = load_and_preprocess_data(self.data_dir, symbols)
        self.logger.log_success(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ ({len(data_dict)}ê°œ ì¢…ëª©)")

        # ë°ì´í„° ì „ì²˜ë¦¬
        prepared_data = self.prepare_data(data_dict)

        # ê° ì¢…ëª©ë³„ ë¶„ì„ ì‹¤í–‰
        for symbol in prepared_data.keys():
            self.logger.log_info(f"ğŸ”„ {symbol} ë¶„ì„ ì‹œì‘...")

            try:
                # 1. ìƒê´€ê´€ê³„ ë¶„ì„
                corr_result = self.run_correlation_analysis(symbol)

                # 2. ì„ í˜•íšŒê·€ ë¶„ì„
                lr_result = self.run_linear_regression_analysis(symbol)

                # 3. Lasso íšŒê·€ ë¶„ì„
                lasso_result = self.run_lasso_regression_analysis(symbol)

                # 4. ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ì„
                rf_result = self.run_random_forest_analysis(symbol)

                # 5. MLP ë¶„ì„
                mlp_result = self.run_mlp_analysis(symbol)

                # 6. ë² ì´ì§€ì•ˆ ë¶„í¬ ë¶„ì„
                bayesian_result = self.run_bayesian_distribution_analysis(symbol)

                self.logger.log_success(f"âœ… {symbol} ë¶„ì„ ì™„ë£Œ")

            except Exception as e:
                self.logger.log_error(f"âŒ {symbol} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")

        # ì¢…í•© ìš”ì•½ ìƒì„±
        self.generate_analysis_summary()

        return self.analysis_results

    def generate_analysis_summary(self):
        """ë¶„ì„ ê²°ê³¼ ì¢…í•© ìš”ì•½"""
        if not self.analysis_results:
            return

        self.logger.log_summary_section("ğŸ“Š ì •ëŸ‰ ë¶„ì„ ì¢…í•© ìš”ì•½ ë¦¬í¬íŠ¸")

        # ë¶„ì„ ì„¤ì •
        self.logger.log_summary_subsection("ğŸ“‹ ë¶„ì„ ì„¤ì •")
        self.logger.log_summary_info(f"ìˆ˜ìµë¥  íƒ€ì…: {self.return_type}")
        self.logger.log_summary_info(f"ìƒìœ„ íŠ¹ì„± ìˆ˜: {self.top_features}")
        self.logger.log_summary_info(f"ë¶„ì„ ì¢…ëª© ìˆ˜: {len(self.analysis_results)}")

        # ì¢…ëª©ë³„ ìš”ì•½
        self.logger.log_summary_subsection("ğŸ“ˆ ì¢…ëª©ë³„ ë¶„ì„ ìš”ì•½")

        for symbol, results in self.analysis_results.items():
            self.logger.log_summary_info(f"\n{symbol}:")

            if "correlation" in results:
                top_features = results["correlation"]["top_features"][:3]
                self.logger.log_summary_info(
                    f"  ìƒê´€ê´€ê³„ ìƒìœ„: {', '.join(top_features)}"
                )

            if "linear_regression" in results:
                r2 = results["linear_regression"]["r_squared"]
                self.logger.log_summary_info(f"  ì„ í˜•íšŒê·€ RÂ²: {r2:.4f}")

            if "random_forest" in results:
                rf_r2 = results["random_forest"]["r_squared"]
                self.logger.log_summary_info(f"  ëœë¤í¬ë ˆìŠ¤íŠ¸ RÂ²: {rf_r2:.4f}")

            if "mlp" in results:
                mlp_r2 = results["mlp"]["r_squared"]
                self.logger.log_summary_info(f"  MLP RÂ²: {mlp_r2:.4f}")

            if "bayesian_regression" in results:
                br_r2 = results["bayesian_regression"]["bayesian_ridge"]["metrics"][
                    "br_test_r2"
                ]
                ard_r2 = results["bayesian_regression"]["ard_regression"]["metrics"][
                    "ard_test_r2"
                ]
                self.logger.log_summary_info(f"  ë² ì´ì§€ì•ˆ Ridge RÂ²: {br_r2:.4f}")
                self.logger.log_summary_info(f"  ARD RÂ²: {ard_r2:.4f}")

            if "bayesian_distribution" in results:
                best_dist = results["bayesian_distribution"]["best_distribution"]
                var_95 = results["bayesian_distribution"]["var_95"]
                self.logger.log_summary_info(f"  ìµœì  ë¶„í¬: {best_dist}")
                self.logger.log_summary_info(f"  VaR 95%: {var_95:.4f}")

        # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        self.logger.log_summary_subsection("ğŸ† ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")

        model_performance = {}
        for symbol, results in self.analysis_results.items():
            for model_name, result in results.items():
                if "r_squared" in result:
                    if model_name not in model_performance:
                        model_performance[model_name] = []
                    model_performance[model_name].append(result["r_squared"])

        for model_name, r2_scores in model_performance.items():
            avg_r2 = np.mean(r2_scores)
            max_r2 = np.max(r2_scores)
            self.logger.log_summary_info(
                f"{model_name}: í‰ê·  RÂ² = {avg_r2:.4f}, ìµœê³  RÂ² = {max_r2:.4f}"
            )

        # ì¢…ë£Œ ë©”ì‹œì§€
        self.logger.log_summary_section("ğŸ‰ ë¶„ì„ ì™„ë£Œ")
        self.logger.log_summary_success(
            f"ì´ {len(self.analysis_results)}ê°œ ì¢…ëª© ë¶„ì„ ì™„ë£Œ"
        )
        self.logger.log_summary_info(f"ì¢…í•© ìš”ì•½ ë¡œê·¸: {self.logger.summary_log_file}")

    def save_results(self, output_path: str = None):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"log/quant_analysis_results_{timestamp}.json"

        # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        def make_serializable(obj):
            import numpy as np
            import pandas as pd

            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, (np.integer, np.floating)):
                return float(obj)
            elif isinstance(obj, pd.DataFrame):
                return obj.to_dict()
            elif isinstance(obj, pd.Series):
                return obj.to_dict()
            elif isinstance(obj, dict):
                return {k: make_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [make_serializable(v) for v in obj]
            elif hasattr(obj, "__name__") and not isinstance(obj, str):
                return str(obj.__name__)
            elif hasattr(obj, "__class__") and not isinstance(obj, str):
                return str(obj.__class__.__name__)
            else:
                try:
                    import json

                    json.dumps(obj)
                    return obj
                except Exception:
                    return str(obj)

        # NaN/infë¥¼ ì•ˆì „í•œ ê°’ìœ¼ë¡œ ë³€í™˜
        def clean_nan_inf(obj):
            import numpy as np
            import pandas as pd

            if isinstance(obj, float):
                if np.isnan(obj) or np.isinf(obj):
                    return None
                return obj
            elif isinstance(obj, dict):
                return {k: clean_nan_inf(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [clean_nan_inf(v) for v in obj]
            elif isinstance(obj, pd.DataFrame):
                return clean_nan_inf(obj.to_dict())
            elif isinstance(obj, pd.Series):
                return clean_nan_inf(obj.to_dict())
            else:
                return obj

        serializable_results = {}
        for symbol, results in self.analysis_results.items():
            serializable_results[symbol] = {}
            for model_name, result in results.items():
                serializable_results[symbol][model_name] = clean_nan_inf(
                    make_serializable(result)
                )

        with open(output_path, "w", encoding="utf-8") as f:
            import json

            json.dump(serializable_results, f, indent=2, ensure_ascii=False)

        self.logger.log_success(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")
        return output_path


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì •ëŸ‰ ë¶„ì„ ì‹œìŠ¤í…œ")
    parser.add_argument("--data_dir", default="data", help="ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--symbols", nargs="+", help="ë¶„ì„í•  ì¢…ëª© ëª©ë¡")
    parser.add_argument(
        "--return_type",
        choices=["percentage", "log"],
        default="percentage",
        help="ìˆ˜ìµë¥  ê³„ì‚° ë°©ì‹",
    )
    parser.add_argument("--top_features", type=int, default=10, help="ìƒìœ„ íŠ¹ì„± ìˆ˜")
    parser.add_argument("--output", help="ê²°ê³¼ ì €ì¥ ê²½ë¡œ")

    args = parser.parse_args()

    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyst = QuantAnalyst(
        data_dir=args.data_dir,
        return_type=args.return_type,
        top_features=args.top_features,
    )

    # ë¶„ì„ ì‹¤í–‰
    results = analyst.run_full_analysis(symbols=args.symbols)

    # ê²°ê³¼ ì €ì¥
    analyst.save_results(args.output)

    print(f"\nâœ… ì •ëŸ‰ ë¶„ì„ ì™„ë£Œ! {len(results)}ê°œ ì¢…ëª© ë¶„ì„ë¨")


if __name__ == "__main__":
    main()
