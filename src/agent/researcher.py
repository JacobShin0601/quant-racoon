#!/usr/bin/env python3
"""
ê°œë³„ ì „ëµ ì—°êµ¬ ë° ìµœì í™” ì‹œìŠ¤í…œ
"""

import os
import sys
import json
import logging
import argparse
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import pandas as pd
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
sys.path.insert(0, project_root)

from src.agent.evaluator import TrainTestEvaluator
from src.actions.log_pl import TradingSimulator
from src.actions.strategies import *
from src.agent.helper import (
    load_and_preprocess_data,
    split_data_train_test,
    load_config,
    Logger,
)

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class OptimizationResult:
    """ìµœì í™” ê²°ê³¼ í´ë˜ìŠ¤"""

    def __init__(
        self,
        strategy_name: str,
        symbol: str,
        best_params: Dict[str, Any],
        best_score: float,
        optimization_method: str,
        execution_time: float,
        n_combinations_tested: int,
        all_results: List[Dict[str, Any]],
    ):
        self.strategy_name = strategy_name
        self.symbol = symbol
        self.best_params = best_params
        self.best_score = best_score
        self.optimization_method = optimization_method
        self.execution_time = execution_time
        self.n_combinations_tested = n_combinations_tested
        self.all_results = all_results


class IndividualStrategyResearcher:
    """ê°œë³„ ì¢…ëª©ë³„ ì „ëµ ìµœì í™” ì—°êµ¬ì"""

    def __init__(
        self,
        research_config_path: str = "config/config_research.json",
        source_config_path: str = "config/config_swing.json",  # swing configë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
        data_dir: str = "data",
        results_dir: str = None,  # Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´
        log_dir: str = None,  # Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´
        analysis_dir: Optional[str] = None,
        auto_detect_source_config: bool = False,  # ìë™ ê°ì§€ ë¹„í™œì„±í™”
        uuid: Optional[str] = None,
        verbose: bool = False,  # verbose ëª¨ë“œ ì¶”ê°€
    ):
        self.research_config_path = research_config_path
        self.source_config_path = source_config_path
        self.data_dir = data_dir
        self.uuid = uuid
        self.verbose = verbose  # verbose ëª¨ë“œ ì €ì¥

        # ì„¤ì • ë¡œë“œ
        self.research_config = self._load_research_config(research_config_path)
        self.source_config = load_config(source_config_path)

        # configì—ì„œ output ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        output_config = self.source_config.get("output", {})
        self.results_dir = results_dir or output_config.get("results_folder", "results")
        self.log_dir = log_dir or output_config.get("logs_folder", "log")

        # analysis_dirì´ Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
        if analysis_dir is None:
            results_folder = output_config.get("results_folder", "results")
            # results/swing -> analysis/swingë¡œ ë³€ê²½
            self.analysis_dir = results_folder.replace("results", "analysis")
        else:
            self.analysis_dir = analysis_dir

        # ìë™ ê°ì§€ ë° ì„¤ì • (orchestratorì—ì„œ í˜¸ì¶œí•  ë•ŒëŠ” ë¹„í™œì„±í™”)
        if auto_detect_source_config:
            self._auto_detect_and_set_source_config()

        # ë¡œê±° ì„¤ì •
        self.logger = Logger()
        if self.log_dir:
            self.logger.set_log_dir(self.log_dir)

        # UUID ì„¤ì • - loggerë¥¼ í†µí•´ ì„¤ì •
        if self.uuid:
            self.logger.setup_logger(
                strategy="individual_research", mode="research", uuid=self.uuid
            )
        else:
            # UUIDê°€ ì—†ì–´ë„ ê¸°ë³¸ ë¡œê±° ì„¤ì •
            self.logger.setup_logger(strategy="individual_research", mode="research")

        # í‰ê°€ê¸° ì´ˆê¸°í™” (ë‹¨ì¼ ì¢…ëª© ëª¨ë“œ)
        self.evaluator = TrainTestEvaluator(
            data_dir=self.data_dir,
            log_mode="summary",
            config_path=self.source_config_path,
        )

        # ë¡œê±° ì„¤ì •
        if self.log_dir:
            self.evaluator.logger.set_log_dir(self.log_dir)

        self.strategy_manager = StrategyManager()

        # ì „ëµ ë“±ë¡
        self._register_strategies()

        # ì—°êµ¬ ê²°ê³¼ ì €ì¥
        self.research_results = {}
        self.start_time = datetime.now()

    def _load_research_config(self, config_path: str) -> Dict[str, Any]:
        """ì—°êµ¬ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"ì—°êµ¬ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            return {}
        except json.JSONDecodeError:
            logger.error(f"ì—°êµ¬ ì„¤ì • íŒŒì¼ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤: {config_path}")
            return {}

    def _auto_detect_and_set_source_config(self):
        """ìë™ìœ¼ë¡œ ìµœì ì˜ source config ê°ì§€ ë° ì„¤ì •"""
        if self.verbose:
            logger.info("ğŸ” ìë™ source config ê°ì§€ ì¤‘...")

        # ì‚¬ìš© ê°€ëŠ¥í•œ config íŒŒì¼ë“¤ ì°¾ê¸°
        config_dir = Path("config")
        available_configs = []

        for config_file in config_dir.glob("config_*.json"):
            if config_file.name != "config_research.json":
                try:
                    with open(config_file, "r", encoding="utf-8") as f:
                        config_data = json.load(f)

                    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                    config_info = {
                        "name": config_file.name,
                        "path": str(config_file),
                        "time_horizon": config_data.get("time_horizon", "unknown"),
                        "symbol_count": len(
                            config_data.get("data", {}).get("symbols", [])
                        ),
                        "strategy_count": len(config_data.get("strategies", [])),
                        "portfolio_mode": False,  # ë‹¨ì¼ ì¢…ëª© ëª¨ë“œë¡œ ë³€ê²½
                    }
                    available_configs.append(config_info)

                except Exception as e:
                    if self.verbose:
                        logger.warning(f"Config íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {config_file} - {e}")

        if not available_configs:
            if self.verbose:
                logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ config íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
            return

        # ìµœì ì˜ config ì„ íƒ
        best_config = self._select_best_source_config(available_configs)
        if best_config:
            self.source_config_path = best_config["path"]
            self.source_config = load_config(self.source_config_path)
            if self.verbose:
                logger.info(f"âœ… ì„ íƒëœ source config: {best_config['name']}")
        else:
            if self.verbose:
                logger.warning("ì ì ˆí•œ configë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")

    def _select_best_source_config(
        self, available_configs: List[Dict]
    ) -> Optional[Dict]:
        """ìµœì ì˜ source config ì„ íƒ"""
        if not available_configs:
            return None

        def config_score(config):
            score = 0

            # ì‹¬ë³¼ ìˆ˜ ì ìˆ˜ (ìµœëŒ€ 50ì )
            symbol_score = min(config["symbol_count"] * 10, 50)
            score += symbol_score

            # time_horizon ì ìˆ˜ (ìµœëŒ€ 30ì ) - swingì„ ìš°ì„ ìœ¼ë¡œ ì„¤ì •
            horizon = config["time_horizon"].lower()
            if "swing" in horizon:
                score += 30  # swingì„ ìµœê³  ì ìˆ˜ë¡œ ì„¤ì •
            elif "long" in horizon:
                score += 20
            elif "scalping" in horizon:
                score += 15
            else:
                score += 10

            # ì „ëµ ìˆ˜ ì ìˆ˜ (ìµœëŒ€ 20ì )
            strategy_score = min(config["strategy_count"] * 2, 20)
            score += strategy_score

            return score

        # ì ìˆ˜ë¡œ ì •ë ¬
        sorted_configs = sorted(available_configs, key=config_score, reverse=True)

        if self.verbose:
            logger.info("ğŸ“Š Config íŒŒì¼ ìš°ì„ ìˆœìœ„:")
            for i, config in enumerate(sorted_configs[:3], 1):
                logger.info(
                    f"  {i}. {config['name']} (ì‹¬ë³¼: {config['symbol_count']}, "
                    f"ì „ëµ: {config['strategy_count']}, ì‹œê°„ëŒ€: {config['time_horizon']})"
                )

        return sorted_configs[0] if sorted_configs else None

    def _load_source_config_symbols(self) -> List[str]:
        """source configì—ì„œ ì‹¬ë³¼ ëª©ë¡ ë¡œë“œ"""
        logger.info(f"ğŸ” source_config_path: {self.source_config_path}")
        logger.info(f"ğŸ” source_config keys: {list(self.source_config.keys())}")

        # ë¨¼ì € data ì„¹ì…˜ì—ì„œ ì‹œë„
        data_section = self.source_config.get("data", {})
        symbols = data_section.get("symbols", [])

        # data ì„¹ì…˜ì— ì—†ìœ¼ë©´ scrapper ì„¹ì…˜ì—ì„œ ì‹œë„
        if not symbols:
            scrapper_section = self.source_config.get("scrapper", {})
            symbols = scrapper_section.get("symbols", [])
            logger.info(f"ğŸ” scrapper section keys: {list(scrapper_section.keys())}")

        logger.info(f"ğŸ” ë¡œë“œëœ ì‹¬ë³¼ë“¤: {symbols}")
        logger.info(f"ğŸ” ì‹¬ë³¼ ê°œìˆ˜: {len(symbols)}")

        return symbols

    def _load_source_config_settings(self) -> Dict[str, Any]:
        """source configì—ì„œ ì„¤ì • ë¡œë“œ"""
        return self.source_config.get("data", {})

    def _register_strategies(self):
        """ì „ëµ ë“±ë¡"""
        strategies_to_register = {
            "dual_momentum": DualMomentumStrategy,
            "volatility_breakout": VolatilityAdjustedBreakoutStrategy,
            "swing_ema": SwingEMACrossoverStrategy,
            "swing_rsi": SwingRSIReversalStrategy,
            "swing_donchian": DonchianSwingBreakoutStrategy,
            "stoch_donchian": StochDonchianStrategy,
            "whipsaw_prevention": WhipsawPreventionStrategy,
            "donchian_rsi_whipsaw": DonchianRSIWhipsawStrategy,
            "volatility_filtered_breakout": VolatilityFilteredBreakoutStrategy,
            "multi_timeframe_whipsaw": MultiTimeframeWhipsawStrategy,
            "adaptive_whipsaw": AdaptiveWhipsawStrategy,
            "cci_bollinger": CCIBollingerStrategy,
            "mean_reversion": MeanReversionStrategy,
            "trend_following_ma200": TrendFollowingMA200Strategy,
            "swing_breakout": SwingBreakoutStrategy,
            "swing_pullback_entry": SwingPullbackEntryStrategy,
            "swing_candle_pattern": SwingCandlePatternStrategy,
            "swing_bollinger_band": SwingBollingerBandStrategy,
            "swing_macd": SwingMACDStrategy,
            # íŠ¹ìˆ˜ ì „ëµë“¤ ì¶”ê°€
            "inverse_etf": InverseETFStrategy,
            "largecap_growth": LargeCap_GrowthStrategy,
            # ëˆ„ë½ëœ ì „ëµë“¤ ì¶”ê°€
            "multi_timeframe_ma": MultiTimeframeMAStrategy,
            "pivot_point": PivotPointStrategy,
            "macd_divergence": MACDDivergenceStrategy,
            "rsi_bollinger_advanced": RSIBollingerAdvancedStrategy,
            # AI ë©”ê°€íŠ¸ë Œë“œ ì „ëµ
            "ai_megatrend": AIMegaTrendStrategy,
            # ëˆ„ë½ëœ ì „ëµë“¤ ì¶”ê°€
            "bull_market_momentum": BullMarketMomentumStrategy,
            "ai_tech_mega_trend": AITechMegaTrendStrategy,
        }

        for name, strategy_class in strategies_to_register.items():
            self.strategy_manager.add_strategy(name, strategy_class(StrategyParams()))

        if self.verbose:
            logger.info(f"âœ… {len(strategies_to_register)}ê°œ ì „ëµ ë“±ë¡ ì™„ë£Œ")

    def create_evaluation_function(
        self,
        strategy_name: str,
        data_dict: Dict[str, pd.DataFrame],
        symbol: str,
    ):
        """í‰ê°€ í•¨ìˆ˜ ìƒì„± (ë‹¨ì¼ ì¢…ëª©ìš©)"""

        def evaluation_function(params: Dict[str, Any]) -> float:
            try:
                # ì „ëµ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                strategy = self.strategy_manager.strategies.get(strategy_name)
                if not strategy:
                    logger.error(f"ì „ëµì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {strategy_name}")
                    return -999999.0

                # íŒŒë¼ë¯¸í„° ì„¤ì •
                for param_name, param_value in params.items():
                    if hasattr(strategy, param_name):
                        setattr(strategy, param_name, param_value)

                # ë‹¨ì¼ ì¢…ëª© ë°ì´í„°ë¡œ ì „ëµ ì‹¤í–‰
                symbol_data = data_dict[symbol]
                signals = strategy.generate_signals(symbol_data)

                if signals is None or signals.empty:
                    return -999999.0

                # ì‹œê·¸ë„ì´ ëª¨ë‘ 0ì¸ ê²½ìš° ì²´í¬
                signal_counts = signals["signal"].value_counts()
                if len(signal_counts) == 1 and 0 in signal_counts:
                    return -999999.0

                # ê±°ë˜ ì‹œë®¬ë ˆì´ì…˜
                simulator = TradingSimulator(self.source_config_path)
                simulation_result = simulator.simulate_trading(
                    symbol_data, signals, strategy_name
                )

                if not simulation_result:
                    return -999999.0

                # TradingSimulator ê²°ê³¼ì—ì„œ performance metrics ì¶”ì¶œ
                strategy_result = simulation_result.get("results", {})
                trades = simulation_result.get("trades", [])

                # ê±°ë˜ê°€ ì—†ëŠ” ê²½ìš° ì²´í¬
                if not trades:
                    return -999999.0

                # ì¶”ê°€ ì •ë³´ ì¶”ê°€
                strategy_result["trades"] = trades

                # ë³µí•© ì ìˆ˜ ê³„ì‚°
                composite_score = self._calculate_composite_score(strategy_result)

                return composite_score

            except Exception as e:
                logger.error(f"í‰ê°€ í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                return -999999.0

        return evaluation_function

    def _calculate_composite_score(self, strategy_result) -> float:
        """ë³µí•© ì ìˆ˜ ê³„ì‚° (ë‹¨ì¼ ì¢…ëª©ìš©)"""
        try:
            # ê¸°ë³¸ ì§€í‘œë“¤
            total_return = strategy_result.get("total_return", 0)
            sharpe_ratio = strategy_result.get("sharpe_ratio", 0)
            max_drawdown = strategy_result.get("max_drawdown", 1)
            win_rate = strategy_result.get("win_rate", 0)
            profit_factor = strategy_result.get("profit_factor", 0)
            total_trades = strategy_result.get("total_trades", 0)
            trades = strategy_result.get("trades", [])

            # ê±°ë˜ê°€ ì—†ëŠ” ê²½ìš° ì²´í¬
            if not trades or total_trades == 0:
                return -999999.0

            # ì¶”ê°€ ì§€í‘œë“¤
            sortino_ratio = self._calculate_sortino_ratio(strategy_result)
            calmar_ratio = self._calculate_calmar_ratio(strategy_result)

            # ì„±ê³¼ ê¸°ì¤€ ì²´í¬ (ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ)
            performance_thresholds = self.source_config.get("researcher", {}).get(
                "performance_thresholds", {}
            )
            min_return_threshold = performance_thresholds.get(
                "min_return_threshold", 0.0
            )
            min_sharpe_ratio = performance_thresholds.get("min_sharpe_ratio", -1.0)
            min_profit_factor = performance_thresholds.get("min_profit_factor", 0.0)
            min_win_rate = performance_thresholds.get("min_win_rate", 0.0)
            min_trades = performance_thresholds.get("min_trades", 1)

            # ê±°ë˜ê°€ ì—†ëŠ” ê²½ìš° ì²´í¬ (ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œ)
            if not trades or total_trades < min_trades:
                return -999999.0

            # ìµœì†Œ ê¸°ì¤€ ì²´í¬
            if total_return < min_return_threshold:
                return -999999.0

            if sharpe_ratio < min_sharpe_ratio:
                return -999999.0

            if profit_factor < min_profit_factor:
                return -999999.0

            if win_rate < min_win_rate:
                return -999999.0

            # configì—ì„œ ê°€ì¤‘ì¹˜ ì„¤ì • ë¡œë“œ
            evaluation_metrics = self.source_config.get("researcher", {}).get(
                "evaluation_metrics", {}
            )
            weights = evaluation_metrics.get(
                "weights",
                {
                    "sharpe_ratio": 0.25,
                    "sortino_ratio": 0.20,
                    "calmar_ratio": 0.15,
                    "profit_factor": 0.20,
                    "win_rate": 0.20,
                },
            )

            # total_returnê³¼ max_drawdownì€ ë³„ë„ ì²˜ë¦¬
            weights["total_return"] = 0.30  # ìˆ˜ìµë¥  ê°€ì¤‘ì¹˜ ì¦ê°€
            weights["max_drawdown"] = 0.10  # ë‚™í­ ê°€ì¤‘ì¹˜ ì¦ê°€

            # ì ìˆ˜ ê³„ì‚°
            scores = {}

            # ìˆ˜ìµë¥  ì ìˆ˜ (ìŒìˆ˜ ìˆ˜ìµë¥ ì— í˜ë„í‹° ì ìš©)
            if total_return >= 0:
                # ì–‘ìˆ˜ ìˆ˜ìµë¥ : 0-100ì 
                scores["total_return"] = min(total_return * 100, 100)
            else:
                # ìŒìˆ˜ ìˆ˜ìµë¥ : í˜ë„í‹° ì ìš© (ìµœëŒ€ -50ì )
                penalty_score = max(total_return * 100, -50)
                scores["total_return"] = penalty_score

            # ìƒ¤í”„ ë¹„ìœ¨ ì ìˆ˜ (0-100)
            scores["sharpe_ratio"] = min(max(sharpe_ratio * 20, 0), 100)

            # ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨ ì ìˆ˜ (0-100)
            scores["sortino_ratio"] = min(max(sortino_ratio * 20, 0), 100)

            # ì¹¼ë§ˆ ë¹„ìœ¨ ì ìˆ˜ (0-100)
            scores["calmar_ratio"] = min(max(calmar_ratio * 10, 0), 100)

            # ìˆ˜ìµ íŒ©í„° ì ìˆ˜ (0-100)
            scores["profit_factor"] = min(max(profit_factor * 20, 0), 100)

            # ìŠ¹ë¥  ì ìˆ˜ (0-100)
            scores["win_rate"] = min(max(win_rate * 100, 0), 100)

            # ìµœëŒ€ ë‚™í­ ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            scores["max_drawdown"] = max(0, 100 - (max_drawdown * 100))

            # ë³µí•© ì ìˆ˜ ê³„ì‚°
            composite_score = sum(
                scores[metric] * weight for metric, weight in weights.items()
            )

            # ìœ„í—˜ í˜ë„í‹° ì ìš© (researcher configì—ì„œ ë¡œë“œ)
            risk_penalties = self.source_config.get("researcher", {}).get(
                "risk_penalties", {}
            )
            max_drawdown_threshold = risk_penalties.get("max_drawdown_threshold", 0.20)
            max_drawdown_penalty = risk_penalties.get("max_drawdown_penalty", 0.5)
            volatility_threshold = risk_penalties.get("volatility_threshold", 0.30)
            volatility_penalty = risk_penalties.get("volatility_penalty", 0.3)

            # ìµœëŒ€ ë‚™í­ í˜ë„í‹° (ë” ì—„ê²©í•˜ê²Œ)
            if max_drawdown > max_drawdown_threshold:
                composite_score *= 1 - max_drawdown_penalty

            # ë³€ë™ì„± í˜ë„í‹°
            volatility = strategy_result.get("volatility", 0)
            if volatility > volatility_threshold:
                composite_score *= 1 - volatility_penalty

            # ìˆ˜ìµë¥  í˜ë„í‹° (ìŒìˆ˜ ìˆ˜ìµë¥ ì— ì¶”ê°€ í˜ë„í‹°)
            if total_return < 0:
                return_penalty = abs(total_return) * 0.5  # ìˆ˜ìµë¥  ì ˆëŒ“ê°’ì˜ 50% í˜ë„í‹°
                composite_score *= 1 - return_penalty

            return composite_score

        except Exception as e:
            logger.error(f"ë³µí•© ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return -999999.0

    def _calculate_sortino_ratio(self, strategy_result) -> float:
        """ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            trades = strategy_result.get("trades", [])
            if not trades:
                return 0

            # ê±°ë˜ë³„ ìˆ˜ìµë¥  ê³„ì‚°
            returns = []
            for trade in trades:
                pnl = trade.get("pnl", 0)
                returns.append(pnl)

            if not returns:
                return 0

            returns_array = np.array(returns)
            negative_returns = returns_array[returns_array < 0]

            # ìŒìˆ˜ ìˆ˜ìµë¥ ì´ ì—†ìœ¼ë©´ ë§¤ìš° ë†’ì€ ê°’ ë°˜í™˜ (ë¬´í•œëŒ€ ëŒ€ì‹ )
            if len(negative_returns) == 0:
                return 99.99  # inf ëŒ€ì‹  ë§¤ìš° ë†’ì€ ê°’

            downside_deviation = np.std(negative_returns)
            # í•˜ë°© í¸ì°¨ê°€ 0ì´ë©´ ë§¤ìš° ë†’ì€ ê°’ ë°˜í™˜
            if downside_deviation == 0:
                return 99.99  # inf ëŒ€ì‹  ë§¤ìš° ë†’ì€ ê°’

            mean_return = np.mean(returns_array)
            risk_free_rate = 0.02 / 252  # ì¼ê°„ ë¬´ìœ„í—˜ ìˆ˜ìµë¥ 

            sortino_ratio = (mean_return - risk_free_rate) / downside_deviation
            return sortino_ratio

        except Exception as e:
            logger.error(f"ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0

    def _calculate_calmar_ratio(self, strategy_result) -> float:
        """ì¹¼ë§ˆ ë¹„ìœ¨ ê³„ì‚°"""
        try:
            total_return = strategy_result.get("total_return", 0)
            max_drawdown = strategy_result.get("max_drawdown", 1)

            if max_drawdown == 0:
                return 0

            calmar_ratio = total_return / max_drawdown
            return calmar_ratio

        except Exception as e:
            logger.error(f"ì¹¼ë§ˆ ë¹„ìœ¨ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return 0

    def optimize_single_strategy_for_symbol(
        self,
        strategy_name: str,
        symbol: str,
        optimization_method: str = None,  # Noneì´ë©´ configì—ì„œ ë¡œë“œ
    ) -> Optional[OptimizationResult]:
        """ë‹¨ì¼ ì „ëµì„ ë‹¨ì¼ ì¢…ëª©ì— ëŒ€í•´ ìµœì í™”"""
        start_time = datetime.now()

        try:
            # ìµœì í™” ë°©ë²• ì„¤ì • (configì—ì„œ ë¡œë“œ)
            if optimization_method is None:
                optimization_method = self.source_config.get("researcher", {}).get(
                    "optimization_method", "bayesian_optimization"
                )

            # ë°ì´í„° ë¡œë“œ
            data_dict = load_and_preprocess_data(self.data_dir, [symbol])
            if not data_dict or symbol not in data_dict:
                if self.verbose:
                    logger.error(f"{symbol} ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None

            # í‰ê°€ í•¨ìˆ˜ ìƒì„±
            evaluation_function = self.create_evaluation_function(
                strategy_name, data_dict, symbol
            )

            # íŒŒë¼ë¯¸í„° ë²”ìœ„ ì„¤ì • (research_configì—ì„œ ë¡œë“œ)
            param_ranges = (
                self.research_config.get("strategies", {})
                .get(strategy_name, {})
                .get("param_ranges", {})
            )
            if not param_ranges:
                if self.verbose:
                    logger.error(f"{strategy_name}ì˜ param_rangesê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return None

            # ìµœì í™” ì„¤ì • (source_configì—ì„œ ë¡œë“œ)
            settings = self.source_config.get("researcher", {}).get(
                "optimization_settings", {}
            )

            # ìµœì í™” ì‹¤í–‰
            if optimization_method == "grid_search":
                best_result = self._grid_search_optimization(
                    evaluation_function, param_ranges, settings
                )
            elif optimization_method == "bayesian_optimization":
                best_result = self._bayesian_optimization(
                    evaluation_function, param_ranges, settings
                )
            elif optimization_method == "genetic_algorithm":
                best_result = self._genetic_algorithm_optimization(
                    evaluation_function, param_ranges, settings
                )
            else:
                if self.verbose:
                    logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìµœì í™” ë°©ë²•: {optimization_method}")
                return None

            if not best_result:
                return None

            execution_time = (datetime.now() - start_time).total_seconds()

            # ê²°ê³¼ ìƒì„±
            result = OptimizationResult(
                strategy_name=strategy_name,
                symbol=symbol,
                best_params=best_result["params"],
                best_score=best_result["score"],
                optimization_method=optimization_method,
                execution_time=execution_time,
                n_combinations_tested=best_result.get("n_combinations", 0),
                all_results=best_result.get("all_results", []),
            )

            return result

        except Exception as e:
            if self.verbose:
                logger.error(f"{symbol} - {strategy_name} ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback

                logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None

    def _grid_search_optimization(
        self, evaluation_function, param_ranges: Dict, settings: Dict
    ) -> Optional[Dict]:
        """ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™”"""
        try:
            from itertools import product

            # íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
            param_names = list(param_ranges.keys())
            param_values = list(param_ranges.values())

            all_combinations = list(product(*param_values))
            max_combinations = settings.get("max_combinations", 3000)

            if len(all_combinations) > max_combinations:
                if self.verbose:
                    logger.warning(
                        f"ì¡°í•© ìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤ ({len(all_combinations)}). "
                        f"ì²˜ìŒ {max_combinations}ê°œë§Œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
                    )
                all_combinations = all_combinations[:max_combinations]

            best_score = -999999.0
            best_params = {}
            # all_resultsëŠ” ìƒìœ„ 10ê°œë§Œ ì €ì¥ (ë©”ëª¨ë¦¬ ì ˆì•½)
            top_results = []

            for i, combination in enumerate(all_combinations):
                params = dict(zip(param_names, combination))
                score = evaluation_function(params)

                # ìƒìœ„ 10ê°œ ê²°ê³¼ë§Œ ì €ì¥
                if len(top_results) < 10:
                    top_results.append({"params": params, "score": score})
                    top_results.sort(key=lambda x: x["score"], reverse=True)
                elif score > top_results[-1]["score"]:
                    top_results.append({"params": params, "score": score})
                    top_results.sort(key=lambda x: x["score"], reverse=True)
                    top_results = top_results[:10]  # ìƒìœ„ 10ê°œë§Œ ìœ ì§€

                # ìƒˆë¡œìš´ ìµœê³  ì ìˆ˜ ë°œê²¬ ì‹œì—ë§Œ ì—…ë°ì´íŠ¸ (ë¡œê·¸ ì—†ìŒ)
                if score > best_score and score > -999999.0:
                    best_score = score
                    best_params = params

            # ìµœì í™” ê²°ê³¼ ìš”ì•½ì€ verbose ëª¨ë“œì—ì„œë§Œ ì¶œë ¥

            return {
                "params": best_params,
                "score": best_score,
                "n_combinations": len(all_combinations),
                "all_results": top_results,
            }

        except Exception as e:
            logger.error(f"ê·¸ë¦¬ë“œ ì„œì¹˜ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _bayesian_optimization(
        self, evaluation_function, param_ranges: Dict, settings: Dict
    ) -> Optional[Dict]:
        """Optunaë¥¼ ì‚¬ìš©í•œ ë² ì´ì§€ì•ˆ ìµœì í™”"""
        try:
            import optuna
            import logging

            # Optuna ë¡œê·¸ ë ˆë²¨ì„ ERRORë¡œ ì„¤ì •í•˜ì—¬ ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì–µì œ
            optuna_logger = logging.getLogger("optuna")
            optuna_logger.setLevel(logging.ERROR)

            best_score_so_far = -999999.0
            best_params_so_far = {}

            def objective(trial):
                nonlocal best_score_so_far, best_params_so_far

                # íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
                params = {}
                for param_name, param_range in param_ranges.items():
                    if isinstance(param_range[0], bool):
                        # Boolean íŒŒë¼ë¯¸í„° ì²˜ë¦¬
                        params[param_name] = trial.suggest_categorical(
                            param_name, param_range
                        )
                    elif isinstance(param_range[0], int):
                        params[param_name] = trial.suggest_int(
                            param_name, param_range[0], param_range[-1]
                        )
                    else:
                        params[param_name] = trial.suggest_float(
                            param_name, param_range[0], param_range[-1]
                        )

                # í‰ê°€ í•¨ìˆ˜ ì‹¤í–‰
                score = evaluation_function(params)

                # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸ (ë¡œê·¸ ì—†ìŒ)
                if score > best_score_so_far and score > -999999.0:
                    best_score_so_far = score
                    best_params_so_far = params.copy()

                return score

            # ìµœì í™” ì‹¤í–‰
            bayesian_settings = settings.get("bayesian_optimization", {})
            n_trials = bayesian_settings.get("n_trials", 50)
            n_startup_trials = bayesian_settings.get("n_startup_trials", 5)
            early_stopping_patience = bayesian_settings.get(
                "early_stopping_patience", 10
            )

            study = optuna.create_study(direction="maximize")
            study.optimize(objective, n_trials=n_trials)

            best_params = study.best_params
            best_score = study.best_value

            # all_results ìˆ˜ì§‘ (Optuna trialsì—ì„œ)
            all_results = []
            for trial in study.trials:
                if trial.value is not None and trial.value >= -999999.0:
                    # trial.durationì´ Noneì´ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                    evaluation_time = (
                        trial.duration if trial.duration is not None else 0.0
                    )
                    result = {
                        "params": trial.params,
                        "score": trial.value,
                        "evaluation_time": evaluation_time,
                        "combination_index": trial.number,
                    }
                    all_results.append(result)

            # ì ìˆ˜ë³„ë¡œ ì •ë ¬ (ìƒìœ„ 10ê°œë§Œ ìœ ì§€)
            all_results.sort(key=lambda x: x["score"], reverse=True)
            all_results = all_results[:10]

            return {
                "params": best_params,
                "score": best_score,
                "n_combinations": n_trials,
                "all_results": all_results,
            }

        except ImportError:
            logger.warning("optunaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ë¦¬ë“œ ì„œì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self._grid_search_optimization(
                evaluation_function, param_ranges, settings
            )
        except Exception as e:
            logger.error(f"ë² ì´ì§€ì•ˆ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _genetic_algorithm_optimization(
        self, evaluation_function, param_ranges: Dict, settings: Dict
    ) -> Optional[Dict]:
        """ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ìµœì í™”"""
        try:
            import random

            # ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
            population_size = settings.get("population_size", 50)
            generations = settings.get("generations", 30)
            mutation_rate = settings.get("mutation_rate", 0.1)
            crossover_rate = settings.get("crossover_rate", 0.8)

            def create_individual():
                """ê°œì²´ ìƒì„±"""
                individual = {}
                for param_name, param_range in param_ranges.items():
                    if isinstance(param_range[0], int):
                        individual[param_name] = random.randint(
                            param_range[0], param_range[-1]
                        )
                    else:
                        individual[param_name] = random.uniform(
                            param_range[0], param_range[-1]
                        )
                return individual

            def evaluate(individual):
                """ê°œì²´ í‰ê°€"""
                return evaluation_function(individual)

            def crossover(parent1, parent2):
                """êµì°¨"""
                if random.random() > crossover_rate:
                    return parent1, parent2

                child1, child2 = {}, {}
                for param_name in param_ranges.keys():
                    if random.random() < 0.5:
                        child1[param_name] = parent1[param_name]
                        child2[param_name] = parent2[param_name]
                    else:
                        child1[param_name] = parent2[param_name]
                        child2[param_name] = parent1[param_name]

                return child1, child2

            def mutate(individual):
                """ëŒì—°ë³€ì´"""
                for param_name, param_range in param_ranges.items():
                    if random.random() < mutation_rate:
                        if isinstance(param_range[0], int):
                            individual[param_name] = random.randint(
                                param_range[0], param_range[-1]
                            )
                        else:
                            individual[param_name] = random.uniform(
                                param_range[0], param_range[-1]
                            )
                return individual

            # ì´ˆê¸° ê°œì²´êµ° ìƒì„±
            population = [create_individual() for _ in range(population_size)]

            best_individual = None
            best_score = -999999.0

            # ì§„í™”
            for generation in range(generations):
                # í‰ê°€
                fitness_scores = [
                    (evaluate(individual), individual) for individual in population
                ]
                fitness_scores.sort(reverse=True)

                # ìµœê³  ê°œì²´ ì—…ë°ì´íŠ¸ (ë¡œê·¸ ì—†ìŒ)
                current_best_score = fitness_scores[0][0]
                if current_best_score > best_score and current_best_score > -999999.0:
                    best_score = current_best_score
                    best_individual = fitness_scores[0][1]

                # ìƒˆë¡œìš´ ê°œì²´êµ° ìƒì„±
                new_population = fitness_scores[: population_size // 2]  # ìƒìœ„ 50% ìœ ì§€

                # ë‚˜ë¨¸ì§€ëŠ” êµì°¨ì™€ ëŒì—°ë³€ì´ë¡œ ìƒì„±
                while len(new_population) < population_size:
                    parent1 = random.choice(fitness_scores[: population_size // 2])[1]
                    parent2 = random.choice(fitness_scores[: population_size // 2])[1]

                    child1, child2 = crossover(parent1, parent2)
                    child1 = mutate(child1)
                    child2 = mutate(child2)

                    new_population.extend([child1, child2])

                population = [
                    individual for _, individual in new_population[:population_size]
                ]

            # all_resultsëŠ” ìµœì¢… ìµœê³  ê²°ê³¼ë§Œ í¬í•¨
            all_results = []
            if best_score > -999999.0:
                all_results.append(
                    {
                        "params": best_individual,
                        "score": best_score,
                        "evaluation_time": 0.0,
                        "combination_index": 0,
                    }
                )

            return {
                "params": best_individual,
                "score": best_score,
                "n_combinations": population_size * generations,
                "all_results": all_results,
            }

        except Exception as e:
            logger.error(f"ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def run_comprehensive_research(
        self,
        strategies: Optional[List[str]] = None,
        symbols: Optional[List[str]] = None,
        optimization_method: str = None,  # configì—ì„œ ë¡œë“œ
        use_train_data_only: bool = True,
    ) -> Dict[str, OptimizationResult]:
        """ì¢…í•© ì—°êµ¬ ì‹¤í–‰"""
        logger.info("ğŸš€ ì¢…í•© ì—°êµ¬ ì‹œì‘")

        # ì „ëµê³¼ ì‹¬ë³¼ ì„¤ì •
        if not strategies:
            strategies = list(self.research_config.get("strategies", {}).keys())
        if not symbols:
            symbols = self._load_source_config_symbols()

        # ìµœì í™” ë°©ë²• ì„¤ì • (configì—ì„œ ë¡œë“œ)
        if optimization_method is None:
            optimization_method = self.source_config.get("researcher", {}).get(
                "optimization_method", "bayesian_optimization"
            )

        # ë°ì´í„° ë¡œë“œ ë° Train/Test ë¶„í• 
        data_dict = load_and_preprocess_data(self.data_dir, symbols)
        if not data_dict:
            logger.error(f"ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.data_dir}")
            return {}

        # Train/Test ë¶„í•  (train ë°ì´í„°ë§Œ ì‚¬ìš©)
        if use_train_data_only:
            train_ratio = self.source_config.get("data", {}).get("train_ratio", 0.8)
            train_data_dict, test_data_dict = split_data_train_test(
                data_dict, train_ratio
            )
            data_dict = train_data_dict  # train ë°ì´í„°ë§Œ ì‚¬ìš©

        results = {}
        total_combinations = len(strategies) * len(symbols)
        current_combination = 0
        successful_combinations = 0
        failed_combinations = 0

        logger.info(
            f"ğŸ¯ {len(strategies)}ê°œ ì „ëµ Ã— {len(symbols)}ê°œ ì‹¬ë³¼ = {total_combinations}ê°œ ì¡°í•© ìµœì í™” ì‹œì‘"
        )

        # ì¢…ëª©ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì²˜ë¦¬
        for symbol_idx, symbol in enumerate(symbols):
            # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì§„í–‰ë¥  ê³„ì‚° (ì¢…ëª© ê¸°ì¤€)
            symbol_progress = (symbol_idx / len(symbols)) * 100
            logger.info(f"[{symbol_progress:.1f}%] {symbol} ìµœì í™” ì¤‘...")

            symbol_results = []

            for strategy_name in strategies:
                current_combination += 1

                result = self.optimize_single_strategy_for_symbol(
                    strategy_name, symbol, optimization_method
                )

                if result:
                    key = f"{strategy_name}_{symbol}"
                    results[key] = result
                    symbol_results.append(result)
                    successful_combinations += 1
                else:
                    failed_combinations += 1

            # í•´ë‹¹ ì¢…ëª©ì—ì„œ ìƒìœ„ 1ê°œ ì „ëµë§Œ ë¡œê·¸ ì¶œë ¥
            if symbol_results:
                symbol_results.sort(key=lambda x: x.best_score, reverse=True)
                best_result = symbol_results[0]
                logger.info(
                    f"  â†’ {best_result.strategy_name} (ì ìˆ˜: {best_result.best_score:.2f})"
                )
            else:
                logger.warning(f"  â†’ ëª¨ë“  ì „ëµ ìµœì í™” ì‹¤íŒ¨")

            logger.info("")  # ì¢…ëª© ê°„ êµ¬ë¶„ì„ ìœ„í•œ ë¹ˆ ì¤„

        logger.info(
            f"âœ… ì™„ë£Œ: {successful_combinations}ê°œ ì„±ê³µ, {failed_combinations}ê°œ ì‹¤íŒ¨"
        )
        return results

    def save_research_results(self, results: Dict[str, OptimizationResult]):
        """ì—°êµ¬ ê²°ê³¼ ì €ì¥"""
        try:
            # ì‹¤íŒ¨í•œ ì „ëµ í•„í„°ë§ (-999999 ì ìˆ˜ ì œì™¸)
            filtered_results = {}
            failed_count = 0

            for key, result in results.items():
                if result.best_score > -999999.0:
                    filtered_results[key] = result
                else:
                    failed_count += 1

            if self.verbose:
                logger.info(
                    f"ğŸ” í•„í„°ë§: {len(results)}ê°œ ì¤‘ {len(filtered_results)}ê°œ ì„±ê³µ, {failed_count}ê°œ ì‹¤íŒ¨ ì œì™¸"
                )

            # ë‚ ì§œì™€ UUIDë¡œ íŒŒì¼ëª… ìƒì„±
            current_date = datetime.now().strftime("%Y%m%d")
            if hasattr(self, "uuid") and self.uuid:
                filename = f"hyperparam_optimization_{current_date}_{self.uuid}.json"
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"hyperparam_optimization_{timestamp}.json"

            # ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            serializable_results = {}
            for key, result in filtered_results.items():  # Use filtered_results here
                # execution_timeì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜
                try:
                    if hasattr(result.execution_time, "total_seconds"):
                        execution_time_seconds = result.execution_time.total_seconds()
                    elif isinstance(result.execution_time, (int, float)):
                        execution_time_seconds = float(result.execution_time)
                    else:
                        execution_time_seconds = 0.0
                except (TypeError, ValueError, AttributeError):
                    execution_time_seconds = 0.0

                # all_results ë‚´ë¶€ì˜ evaluation_timeë„ ì•ˆì „í•˜ê²Œ ë³€í™˜
                serializable_all_results = []
                for all_result in result.all_results:
                    serializable_all_result = all_result.copy()
                    if "evaluation_time" in serializable_all_result:
                        try:
                            eval_time = serializable_all_result["evaluation_time"]
                            if hasattr(eval_time, "total_seconds"):
                                serializable_all_result["evaluation_time"] = (
                                    eval_time.total_seconds()
                                )
                            elif isinstance(eval_time, (int, float)):
                                serializable_all_result["evaluation_time"] = float(
                                    eval_time
                                )
                            else:
                                serializable_all_result["evaluation_time"] = 0.0
                        except (TypeError, ValueError, AttributeError):
                            serializable_all_result["evaluation_time"] = 0.0
                    serializable_all_results.append(serializable_all_result)

                serializable_results[key] = {
                    "strategy_name": result.strategy_name,
                    "symbol": result.symbol,
                    "best_params": result.best_params,
                    "best_score": result.best_score,
                    "optimization_method": result.optimization_method,
                    "execution_time": execution_time_seconds,
                    "n_combinations_tested": result.n_combinations_tested,
                    "all_results": serializable_all_results,
                }

            # íŒŒì¼ ì €ì¥
            output_path = os.path.join(self.results_dir, filename)
            os.makedirs(self.results_dir, exist_ok=True)

            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(serializable_results, f, indent=2, ensure_ascii=False)

            if self.verbose:
                logger.info(f"ğŸ’¾ ì—°êµ¬ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")

            # ìµœì‹  íŒŒì¼ ê²½ë¡œ ë°˜í™˜
            return output_path

        except Exception as e:
            logger.error(f"ì—°êµ¬ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def generate_research_report(self, results: Dict[str, OptimizationResult]):
        """ì—°êµ¬ ë³´ê³ ì„œ ìƒì„±"""
        try:
            # UUIDê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ ì‚¬ìš©
            if hasattr(self, "uuid") and self.uuid:
                timestamp = self.uuid
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"research_report_{timestamp}.txt"
            output_path = os.path.join(self.results_dir, filename)

            with open(output_path, "w", encoding="utf-8") as f:
                f.write("=" * 80 + "\n")
                f.write("ê°œë³„ ì¢…ëª©ë³„ ì „ëµ ìµœì í™” ì—°êµ¬ ë³´ê³ ì„œ\n")
                f.write("=" * 80 + "\n\n")

                f.write(f"ì—°êµ¬ ì‹œì‘ ì‹œê°„: {self.start_time}\n")
                f.write(f"ì—°êµ¬ ì™„ë£Œ ì‹œê°„: {datetime.now()}\n")
                f.write(f"ì´ ì¡°í•© ìˆ˜: {len(results)}\n\n")

                # ì „ëµë³„ ìš”ì•½
                strategy_summary = {}
                for key, result in results.items():
                    strategy_name = result.strategy_name
                    if strategy_name not in strategy_summary:
                        strategy_summary[strategy_name] = []
                    strategy_summary[strategy_name].append(result)

                f.write("ì „ëµë³„ ìµœì í™” ê²°ê³¼ ìš”ì•½:\n")
                f.write("-" * 50 + "\n")
                for strategy_name, strategy_results in strategy_summary.items():
                    avg_score = np.mean([r.best_score for r in strategy_results])
                    best_score = max([r.best_score for r in strategy_results])
                    f.write(f"{strategy_name}:\n")
                    f.write(f"  í‰ê·  ì ìˆ˜: {avg_score:.2f}\n")
                    f.write(f"  ìµœê³  ì ìˆ˜: {best_score:.2f}\n")
                    f.write(f"  ìµœì í™”ëœ ì¢…ëª© ìˆ˜: {len(strategy_results)}\n\n")

                # ìƒìœ„ ê²°ê³¼ë“¤
                f.write("ìƒìœ„ 10ê°œ ìµœì í™” ê²°ê³¼:\n")
                f.write("-" * 50 + "\n")
                sorted_results = sorted(
                    results.items(), key=lambda x: x[1].best_score, reverse=True
                )
                for i, (key, result) in enumerate(sorted_results[:10], 1):
                    f.write(
                        f"{i}. {result.strategy_name} - {result.symbol}: "
                        f"ì ìˆ˜ {result.best_score:.2f}\n"
                    )

            if self.verbose:
                logger.info(f"ğŸ“„ ì—°êµ¬ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_path}")

        except Exception as e:
            logger.error(f"ì—°êµ¬ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

    def run_quick_test(
        self, strategy_name: str = "dual_momentum", symbol: str = "AAPL"
    ):
        """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        if self.verbose:
            logger.info(f"ğŸ§ª ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: {strategy_name} - {symbol}")

        # configì—ì„œ ìµœì í™” ë°©ë²• ë¡œë“œ
        optimization_method = self.source_config.get("researcher", {}).get(
            "optimization_method", "bayesian_optimization"
        )
        if self.verbose:
            logger.info(f"ğŸ”§ ì‚¬ìš©í•  ìµœì í™” ë°©ë²•: {optimization_method}")

        result = self.optimize_single_strategy_for_symbol(
            strategy_name, symbol, optimization_method
        )

        if result:
            if self.verbose:
                logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ: ì ìˆ˜ {result.best_score:.2f}")
        else:
            logger.error("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ê°œë³„ ì¢…ëª©ë³„ ì „ëµ ìµœì í™” ì—°êµ¬ì")
    parser.add_argument(
        "--config", default="config/config_research.json", help="ì—°êµ¬ ì„¤ì • íŒŒì¼"
    )
    parser.add_argument(
        "--source-config", default="config/config_swing.json", help="ì†ŒìŠ¤ ì„¤ì • íŒŒì¼"
    )
    parser.add_argument("--data-dir", default="data", help="ë°ì´í„° ë””ë ‰í† ë¦¬")
    parser.add_argument(
        "--results-dir", default=None, help="ê²°ê³¼ ë””ë ‰í† ë¦¬ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)"
    )
    parser.add_argument(
        "--log-dir", default=None, help="ë¡œê·¸ ë””ë ‰í† ë¦¬ (Noneì´ë©´ configì—ì„œ ê°€ì ¸ì˜´)"
    )
    parser.add_argument(
        "--optimization-method",
        choices=["grid_search", "bayesian_optimization", "genetic_algorithm"],
        help="ìµœì í™” ë°©ë²• (ê¸°ë³¸ê°’: configì—ì„œ ë¡œë“œ)",
    )
    parser.add_argument("--quick-test", action="store_true", help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    parser.add_argument("--verbose", action="store_true", help="ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥")

    args = parser.parse_args()

    # ì—°êµ¬ì ì´ˆê¸°í™”
    researcher = IndividualStrategyResearcher(
        research_config_path=args.config,
        source_config_path=args.source_config,
        data_dir=args.data_dir,
        results_dir=args.results_dir,
        log_dir=args.log_dir,
        verbose=args.verbose,  # verbose ì˜µì…˜ ì¶”ê°€
    )

    if args.quick_test:
        researcher.run_quick_test()
    else:
        # ì¢…í•© ì—°êµ¬ ì‹¤í–‰
        results = researcher.run_comprehensive_research(
            optimization_method=(
                args.optimization_method if args.optimization_method else None
            )
        )

        if results:
            # ê²°ê³¼ ì €ì¥
            output_file = researcher.save_research_results(results)
            if output_file:
                logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {output_file}")

            # ë³´ê³ ì„œ ìƒì„±
            researcher.generate_research_report(results)


if __name__ == "__main__":
    main()
