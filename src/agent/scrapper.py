import os
import sys
import json
from pathlib import Path
from datetime import datetime

sys.path.append(str(Path(__file__).resolve().parent.parent))
from actions.y_finance import YahooFinanceDataCollector
from actions.calculate_index import TechnicalIndicators, StrategyParams
from agent.helper import Logger, load_config, print_section_header, print_subsection_header


def main():
    import argparse
    
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description="ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ")
    parser.add_argument("--data-dir", default="data", help="ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--config", default="../../config/config_default.json", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--uuid", help="ì‹¤í–‰ UUID")
    args = parser.parse_args()
    
    # config.json ê²½ë¡œ
    config_path = os.path.abspath(args.config)
    config = load_config(config_path)
    
    # Logger ì´ˆê¸°í™” - configì—ì„œ ë¡œê·¸ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    log_dir = config.get("output", {}).get("logs_folder", "log")
    logger = Logger(log_dir=log_dir)
    
    # UUID ì„¤ì •
    if args.uuid:
        print(f"ğŸ†” ìŠ¤í¬ë˜í¼ UUID ì„¤ì •: {args.uuid}")

    # ê³µí†µ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    data_config = config.get("data", {})
    # data ì„¹ì…˜ì—ì„œ ì§ì ‘ ì„¤ì •ì„ ê°€ì ¸ì˜¤ê±°ë‚˜, common_settingsê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
    common_settings = data_config.get("common_settings", data_config)
    symbols = data_config.get("symbols", [])
    custom_tasks = data_config.get("custom_tasks", [])

    if not symbols and not custom_tasks:
        print("ìˆ˜ì§‘í•  ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë¡œê±° ì„¤ì •
    all_symbols = symbols + [
        task.get("symbol") for task in custom_tasks if task.get("symbol")
    ]
    logger.setup_logger(
        strategy="data_collection", symbols=all_symbols, mode="scrapper"
    )

    logger.log_section("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì‹œì‘")

    collector = YahooFinanceDataCollector()
    params = StrategyParams()

    # 1. ê³µí†µ ì„¤ì •ì„ ì ìš©í•œ symbols ì²˜ë¦¬
    if symbols:
        logger.log_subsection(f"ê³µí†µ ì„¤ì •ìœ¼ë¡œ {len(symbols)}ê°œ ì¢…ëª© ì²˜ë¦¬")
        logger.log_config(common_settings, "ê³µí†µ ì„¤ì •")

        for symbol in symbols:
            logger.log_subsection(f"{symbol} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            try:
                info = collector.get_stock_info(symbol)
                logger.log_info(f"ì£¼ì‹ ì •ë³´: {info['name']} ({info['sector']})")
            except Exception as e:
                logger.log_error(f"{symbol} ì¢…ëª© ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

            try:
                # 1ë‹¨ê³„: ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ (ì¬ë¬´ì§€í‘œ í¬í•¨)
                logger.log_info(f"{symbol} ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                df = collector.get_candle_data(
                    symbol=symbol,
                    interval=common_settings.get("interval", "15m"),
                    start_date=common_settings.get("start_date"),
                    end_date=common_settings.get("end_date"),
                    days_back=common_settings.get("lookback_days", common_settings.get("days_back", 30)),
                )
                logger.log_success(
                    f"{symbol} ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({len(df)}ê°œ í¬ì¸íŠ¸)"
                )
                
                # ìˆ˜ì§‘ëœ ì¬ë¬´ì§€í‘œ ì •ë³´ ë¡œê¹…
                financial_columns = [col for col in df.columns if col not in [
                    "datetime", "date", "time", "timestamp", "open", "high", "low", "close", "volume"
                ]]
                if financial_columns:
                    logger.log_info(f"{symbol} ì¬ë¬´ì§€í‘œ {len(financial_columns)}ê°œ ìˆ˜ì§‘ë¨")
                    # ì£¼ìš” ì¬ë¬´ì§€í‘œë“¤ë§Œ ë¡œê¹…
                    key_indicators = ["pe_ratio", "return_on_equity", "debt_to_equity", "dividend_yield", 
                                    "free_cashflow", "market_cap", "beta"]
                    available_indicators = [ind for ind in key_indicators if ind in df.columns and df[ind].iloc[0] is not None]
                    if available_indicators:
                        indicator_values = {ind: df[ind].iloc[0] for ind in available_indicators}
                        logger.log_info(f"{symbol} ì£¼ìš” ì¬ë¬´ì§€í‘œ: {indicator_values}")

                # 2ë‹¨ê³„: ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                logger.log_info(f"{symbol} ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘...")
                df_with_indicators = TechnicalIndicators.calculate_all_indicators(
                    df, params
                )
                logger.log_success(f"{symbol} ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ")

                # 3ë‹¨ê³„: CSV íŒŒì¼ë¡œ ì €ì¥
                logger.log_info(f"{symbol} CSV íŒŒì¼ ì €ì¥ ì¤‘...")
                filepath = collector.save_to_csv(
                    df=df_with_indicators,
                    symbol=symbol,
                    interval=common_settings.get("interval", "15m"),
                    start_date=common_settings.get("start_date") or "auto",
                    end_date=common_settings.get("end_date") or "auto",
                    output_dir=args.data_dir,
                    uuid=args.uuid,  # UUID ì¶”ê°€
                )
                logger.log_success(f"{symbol} ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")

            except Exception as e:
                logger.log_error(f"{symbol} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    # 2. ê°œë³„ ì„¤ì •ì´ ìˆëŠ” custom_tasks ì²˜ë¦¬
    if custom_tasks:
        logger.log_subsection(f"ê°œë³„ ì„¤ì •ìœ¼ë¡œ {len(custom_tasks)}ê°œ ì¢…ëª© ì²˜ë¦¬")

        for task in custom_tasks:
            symbol = task.get("symbol")
            logger.log_subsection(f"{symbol} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ê°œë³„ ì„¤ì •)")
            logger.log_config(task, f"{symbol} ê°œë³„ ì„¤ì •")

            try:
                info = collector.get_stock_info(symbol)
                logger.log_info(f"ì£¼ì‹ ì •ë³´: {info['name']} ({info['sector']})")
            except Exception as e:
                logger.log_error(f"{symbol} ì¢…ëª© ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

            try:
                # 1ë‹¨ê³„: ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ (ì¬ë¬´ì§€í‘œ í¬í•¨)
                logger.log_info(f"{symbol} ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                df = collector.get_candle_data(
                    symbol=symbol,
                    interval=task.get("interval", "15m"),
                    start_date=task.get("start_date"),
                    end_date=task.get("end_date"),
                    days_back=task.get("days_back", 30),
                )
                logger.log_success(
                    f"{symbol} ê¸°ë³¸ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ({len(df)}ê°œ í¬ì¸íŠ¸)"
                )
                
                # ìˆ˜ì§‘ëœ ì¬ë¬´ì§€í‘œ ì •ë³´ ë¡œê¹…
                financial_columns = [col for col in df.columns if col not in [
                    "datetime", "date", "time", "timestamp", "open", "high", "low", "close", "volume"
                ]]
                if financial_columns:
                    logger.log_info(f"{symbol} ì¬ë¬´ì§€í‘œ {len(financial_columns)}ê°œ ìˆ˜ì§‘ë¨")
                    # ì£¼ìš” ì¬ë¬´ì§€í‘œë“¤ë§Œ ë¡œê¹…
                    key_indicators = ["pe_ratio", "return_on_equity", "debt_to_equity", "dividend_yield", 
                                    "free_cashflow", "market_cap", "beta"]
                    available_indicators = [ind for ind in key_indicators if ind in df.columns and df[ind].iloc[0] is not None]
                    if available_indicators:
                        indicator_values = {ind: df[ind].iloc[0] for ind in available_indicators}
                        logger.log_info(f"{symbol} ì£¼ìš” ì¬ë¬´ì§€í‘œ: {indicator_values}")

                # 2ë‹¨ê³„: ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                logger.log_info(f"{symbol} ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘...")
                df_with_indicators = TechnicalIndicators.calculate_all_indicators(
                    df, params
                )
                logger.log_success(f"{symbol} ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ")

                # 3ë‹¨ê³„: CSV íŒŒì¼ë¡œ ì €ì¥
                logger.log_info(f"{symbol} CSV íŒŒì¼ ì €ì¥ ì¤‘...")
                filepath = collector.save_to_csv(
                    df=df_with_indicators,
                    symbol=symbol,
                    interval=task.get("interval", "15m"),
                    start_date=task.get("start_date") or "auto",
                    end_date=task.get("end_date") or "auto",
                    output_dir=args.data_dir,
                    uuid=args.uuid,  # UUID ì¶”ê°€
                )
                logger.log_success(f"{symbol} ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}")

            except Exception as e:
                logger.log_error(f"{symbol} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    logger.log_success("ğŸ‰ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # JSON ë¡œê·¸ ì €ì¥
    log_data = {
        "timestamp": datetime.now().isoformat(),
        "symbols": all_symbols,
        "common_settings": common_settings,
        "custom_tasks": custom_tasks,
        "total_symbols": len(all_symbols),
        "uuid": args.uuid,
        "financial_analysis": {
            "description": "í¬ê´„ì ì¸ ì¬ë¬´ë¶„ì„ì„ ìœ„í•œ í™•ì¥ëœ ì§€í‘œë“¤ í¬í•¨",
            "categories": [
                "ê¸°ì—… ê°€ì¹˜ ì§€í‘œ (P/E, P/B, EV/EBITDA ë“±)",
                "ìˆ˜ìµì„± ì§€í‘œ (ROE, ROA, ë§ˆì§„ ë“±)",
                "ì„±ì¥ì„± ì§€í‘œ (ë§¤ì¶œì„±ì¥ë¥ , ì´ìµì„±ì¥ë¥  ë“±)",
                "ì¬ë¬´ ê±´ì „ì„± ì§€í‘œ (ë¶€ì±„ë¹„ìœ¨, ìœ ë™ë¹„ìœ¨ ë“±)",
                "í˜„ê¸ˆíë¦„ ì§€í‘œ (ì˜ì—…í˜„ê¸ˆíë¦„, ììœ í˜„ê¸ˆíë¦„ ë“±)",
                "ë°°ë‹¹ ê´€ë ¨ ì§€í‘œ (ë°°ë‹¹ìˆ˜ìµë¥ , ë°°ë‹¹ì„±í–¥ ë“±)",
                "ë¶„ê¸°ë³„ ì¬ë¬´ì œí‘œ ë°ì´í„°",
                "ê³„ì‚°ëœ ì¬ë¬´ë¹„ìœ¨ë“¤"
            ]
        }
    }
    logger.save_json_log(
        log_data, f"data_collection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    )


if __name__ == "__main__":
    main()
