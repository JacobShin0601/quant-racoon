#!/usr/bin/env python3
"""
ê¸°ë³¸ ì‹œì¥ ë¶„ì„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
src/actions í´ë”ì—ì„œ ì‹¤í–‰
"""

import sys
import os
import json
from datetime import datetime
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

from src.agent.market_sensor import MarketSensor
from src.agent.enhancements import LLMConfig


def run_basic_analysis(
    output_dir: str = "results/macro/basic",
    enable_llm_api: bool = False,
    llm_config: LLMConfig = None,
    verbose: bool = True
) -> Dict[str, Any]:
    """
    ê¸°ë³¸ ì‹œì¥ ë¶„ì„ ì‹¤í–‰
    
    Args:
        output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        enable_llm_api: LLM API í™œì„±í™” ì—¬ë¶€
        llm_config: LLM ì„¤ì •
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if verbose:
        print("ğŸš€ ê¸°ë³¸ ì‹œì¥ ë¶„ì„ ì‹œì‘")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # Market Sensor ì´ˆê¸°í™”
        sensor = MarketSensor(
            enable_llm_api=enable_llm_api,
            llm_config=llm_config
        )
        
        if verbose:
            print("âœ… Market Sensor ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
        if verbose:
            print("ğŸ“Š ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        
        analysis = sensor.get_current_market_analysis(
            use_optimized_params=True,
            use_ml_model=True
        )
        
        if verbose:
            print("âœ… ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ")
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"{output_dir}/analysis_results_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False, default=str)
        
        if verbose:
            print(f"âœ… ê²°ê³¼ ì €ì¥: {output_file}")
        
        # ìš”ì•½ ì¶œë ¥
        if verbose:
            print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
            print(f"í˜„ì¬ ì²´ì œ: {analysis.get('current_regime', 'N/A')}")
            
            if 'confidence' in analysis:
                print(f"ì‹ ë¢°ë„: {analysis.get('confidence', 0.5):.3f}")
            
            if 'probabilities' in analysis:
                probs = analysis['probabilities']
                print("ì²´ì œ í™•ë¥ :")
                for regime, prob in probs.items():
                    print(f"  {regime}: {prob:.3f}")
            
            print("ğŸ‰ ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ!")
        
        return analysis
        
    except Exception as e:
        if verbose:
            print(f"âŒ ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±
    import argparse
    
    parser = argparse.ArgumentParser(description="ê¸°ë³¸ ì‹œì¥ ë¶„ì„")
    parser.add_argument("--output", type=str, default="results/macro/basic", 
                       help="ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--enable-llm", action="store_true", 
                       help="LLM API í™œì„±í™”")
    parser.add_argument("--verbose", action="store_true", default=True,
                       help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    
    args = parser.parse_args()
    
    # LLM ì„¤ì • (í™œì„±í™”ëœ ê²½ìš°)
    llm_config = None
    if args.enable_llm:
        llm_config = LLMConfig(
            provider="hybrid",
            model_name="anthropic.claude-3-sonnet-20240229-v1:0",
            fallback_to_rules=True
        )
    
    # ë¶„ì„ ì‹¤í–‰
    result = run_basic_analysis(
        output_dir=args.output,
        enable_llm_api=args.enable_llm,
        llm_config=llm_config,
        verbose=args.verbose
    )
    
    return result


if __name__ == "__main__":
    main() 