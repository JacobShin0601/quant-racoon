#!/usr/bin/env python3
"""
í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ì‚°ì¶œ ì‹œìŠ¤í…œ
"""

import json
import os
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from scipy.optimize import minimize
import logging
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PortfolioWeightCalculator:
    """í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ê³„ì‚° í´ë˜ìŠ¤"""

    def __init__(self, config_path: Optional[str] = None):
        print(f"ğŸ” PortfolioWeightCalculator ì´ˆê¸°í™” ì‹œì‘ - config_path: {config_path}")

        self.config = self._load_config(config_path)
        print(f"ğŸ” ì„¤ì • ë¡œë“œ ì™„ë£Œ: {type(self.config)}")

        self.portfolio_config = self.config["portfolio"]
        print(f"ğŸ” í¬íŠ¸í´ë¦¬ì˜¤ ì„¤ì •: {self.portfolio_config}")

        # ìƒˆë¡œìš´ ì„¤ì • êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
        self.rebalance_period = self.portfolio_config.get("rebalance_period", 20)
        print(f"ğŸ” ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°: {self.rebalance_period}")

        # optimization_method ì‚¬ìš© (ê¸°ì¡´ weight_calculation_method ëŒ€ì‹ )
        self.method = self.portfolio_config.get(
            "optimization_method", "sharpe_maximization"
        )
        print(f"ğŸ” ì„ íƒëœ ìµœì í™” ë°©ë²•: {self.method}")

        # fallback í˜„í™© ê¸°ë¡
        self.fallback_stats = {
            "risk_parity": 0,
            "min_variance": 0,
            "volatility_inverse": 0,
            "equal_weight": 0,
        }
        self.fallback_log = []

        # AdvancedPortfolioManager import (lazy loading)
        self.advanced_manager = None

        print("âœ… PortfolioWeightCalculator ì´ˆê¸°í™” ì™„ë£Œ")

    def _load_config(self, config_path: Optional[str] = None) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            # config_pathê°€ Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if config_path is None:
                config_path = "config/config_swing.json"

            # ë¨¼ì € ì ˆëŒ€ ê²½ë¡œë¡œ ì‹œë„
            if os.path.isabs(config_path):
                config_file = config_path
            else:
                # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ ì‹œë„
                possible_paths = [
                    config_path,  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€
                    os.path.join(
                        os.path.dirname(__file__), "..", "..", config_path
                    ),  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€
                    os.path.join(
                        os.path.dirname(__file__), config_path
                    ),  # actions ë””ë ‰í† ë¦¬ ê¸°ì¤€
                ]

                config_file = None
                for path in possible_paths:
                    if os.path.exists(path):
                        config_file = path
                        break

                if config_file is None:
                    raise FileNotFoundError(
                        f"Config file not found in any of: {possible_paths}"
                    )

            with open(config_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            return {
                "portfolio": {
                    "initial_capital": 100000,
                    "rebalance_period": 20,
                    "optimization_method": "sharpe_maximization",
                    "risk_free_rate": 0.02,
                    "target_volatility": 0.20,
                    "min_weight": 0.0,
                    "max_weight": 0.8,
                }
            }

    def calculate_optimal_weights(
        self, data_dict: Dict[str, pd.DataFrame]
    ) -> pd.DataFrame:
        """ìµœì  ë¹„ì¤‘ ê³„ì‚°"""
        print(f"ğŸ“Š {self.method} ë°©ì‹ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ê³„ì‚° ì¤‘...")

        # ëª¨ë“  ì¢…ëª©ì˜ ê³µí†µ ê¸°ê°„ ì°¾ê¸°
        common_dates = self._get_common_dates(data_dict)
        symbols = list(data_dict.keys())

        # ë¹„ì¤‘ DataFrame ì´ˆê¸°í™”
        weights_df = pd.DataFrame(index=common_dates)
        weights_df.index.name = "datetime"

        # ê° ì‹œì ë³„ë¡œ ë¹„ì¤‘ ê³„ì‚°
        for i, date in enumerate(common_dates):
            # dateê°€ timezone-naiveì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë³€í™˜
            if hasattr(date, "tz") and date.tz is not None:
                date_naive = date.tz_localize(None)
            else:
                date_naive = date

            if i % self.rebalance_period == 0:  # ë¦¬ë°¸ëŸ°ì‹± ì‹œì 
                # í•´ë‹¹ ì‹œì ê¹Œì§€ì˜ ë°ì´í„°ë¡œ ë¹„ì¤‘ ê³„ì‚°
                historical_data = self._get_historical_data(
                    data_dict, date_naive, symbols
                )
                weights = self._calculate_weights_at_date(historical_data, symbols)
            else:
                # ì´ì „ ë¹„ì¤‘ ìœ ì§€ (ì²« ë²ˆì§¸ ì‹œì ì´ ì•„ë‹Œ ê²½ìš°)
                if i > 0:
                    weights = {
                        symbol: weights_df.iloc[i - 1][symbol] for symbol in symbols
                    }
                else:
                    # ì²« ë²ˆì§¸ ì‹œì ì—ì„œëŠ” ë“±ê°€ ë¹„ì¤‘ ì‚¬ìš©
                    weights = self._equal_weight(symbols)

            # ë¹„ì¤‘ì„ DataFrameì— ì €ì¥
            for symbol in symbols:
                weights_df.loc[date, symbol] = float(weights.get(symbol, 0.0))

            # í˜„ê¸ˆ ë¹„ì¤‘ ê³„ì‚° (1 - ëª¨ë“  ì¢…ëª© ë¹„ì¤‘ í•©)
            total_weight = sum(float(weights.get(symbol, 0.0)) for symbol in symbols)
            weights_df.loc[date, "CASH"] = max(0.0, 1.0 - total_weight)

        return weights_df

    def _get_common_dates(self, data_dict: Dict[str, pd.DataFrame]) -> pd.DatetimeIndex:
        """ëª¨ë“  ì¢…ëª©ì˜ ê³µí†µ ë‚ ì§œ ì°¾ê¸°"""
        if not isinstance(data_dict, dict):
            logger.error(
                f"data_dict íƒ€ì… ì˜¤ë¥˜: {type(data_dict)}. dict[str, pd.DataFrame]ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
            )
            return pd.DatetimeIndex([])
        date_sets = []
        for symbol, df in data_dict.items():
            if not isinstance(df, pd.DataFrame) or "datetime" not in df.columns:
                logger.warning(
                    f"{symbol} ë°ì´í„°ê°€ DataFrameì´ ì•„ë‹ˆê±°ë‚˜ datetime ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
                )
                continue
            # datetime ì»¬ëŸ¼ì„ ì•ˆì „í•˜ê²Œ ë³€í™˜ (ë¬¸ìì—´, tz-aware ëª¨ë‘ ì²˜ë¦¬)
            dates = pd.to_datetime(df["datetime"], errors="coerce", utc=True)
            if hasattr(dates, "dt") and dates.dt.tz is not None:
                dates = dates.dt.tz_localize(None)
            date_sets.append(set(dates))

        if not date_sets:
            return pd.DatetimeIndex([])
        common_dates = set.intersection(*date_sets)
        return pd.DatetimeIndex(sorted(common_dates))

    def _get_historical_data(
        self,
        data_dict: Dict[str, pd.DataFrame],
        current_date: pd.Timestamp,
        symbols: List[str],
    ) -> Dict[str, pd.DataFrame]:
        """í˜„ì¬ ì‹œì ê¹Œì§€ì˜ ê³¼ê±° ë°ì´í„° ì¶”ì¶œ"""
        historical_data = {}

        for symbol in symbols:
            df = data_dict[symbol]

            # datetime ì»¬ëŸ¼ì˜ timezone ì²˜ë¦¬ - ë” ê°•ë ¥í•œ ë°©ë²•
            df_dates = pd.to_datetime(df["datetime"], errors="coerce")
            if hasattr(df_dates, "dt") and df_dates.dt.tz is not None:
                # timezone-aware datetimeì„ timezone-naiveë¡œ ë³€í™˜
                df_dates = df_dates.dt.tz_localize(None)

            # current_dateë„ timezone-naiveë¡œ ë³´ì¥
            if hasattr(current_date, "tz") and current_date.tz is not None:
                current_date_naive = current_date.tz_localize(None)
            else:
                current_date_naive = current_date

            # timezone-naive datetimeìœ¼ë¡œ ë¹„êµ
            historical_df = df[df_dates <= current_date_naive].copy()
            if len(historical_df) > 0:
                historical_data[symbol] = historical_df

        return historical_data

    def _calculate_weights_at_date(
        self, historical_data: Dict[str, pd.DataFrame], symbols: List[str]
    ) -> Dict[str, float]:
        """íŠ¹ì • ì‹œì ì—ì„œì˜ ë¹„ì¤‘ ê³„ì‚°"""
        # AdvancedPortfolioManagerê°€ ì§€ì›í•˜ëŠ” ë°©ë²•ë“¤
        advanced_methods = [
            "sharpe_maximization",
            "sortino_maximization",
            "mean_variance",
            "risk_parity",
            "minimum_variance",
            "maximum_diversification",
            "black_litterman",
            "kelly_criterion",
        ]

        if self.method in advanced_methods:
            return self._advanced_optimization_weight(historical_data, symbols)
        elif self.method == "equal_weight":
            return self._equal_weight(symbols)
        elif self.method == "volatility_inverse":
            return self._volatility_inverse_weight(historical_data, symbols)
        elif self.method == "momentum_weight":
            return self._momentum_weight(historical_data, symbols)
        else:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë¹„ì¤‘ ê³„ì‚° ë°©ì‹: {self.method}, ë“±ê°€ ë¹„ì¤‘ ì‚¬ìš©")
            return self._equal_weight(symbols)

    def _equal_weight(self, symbols: List[str]) -> Dict[str, float]:
        """ë“±ê°€ ë¹„ì¤‘"""
        weight_per_symbol = 1.0 / len(symbols)
        return {symbol: weight_per_symbol for symbol in symbols}

    def _advanced_optimization_weight(
        self, historical_data: Dict[str, pd.DataFrame], symbols: List[str]
    ) -> Dict[str, float]:
        """AdvancedPortfolioManagerë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ìµœì í™” ë¹„ì¤‘ ê³„ì‚°"""
        try:
            # Lazy loading of AdvancedPortfolioManager
            if self.advanced_manager is None:
                from agent.portfolio_manager import AdvancedPortfolioManager

                # config_pathë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                config_path = os.path.join(
                    os.path.dirname(__file__), "../../config/config_long.json"
                )
                self.advanced_manager = AdvancedPortfolioManager(config_path)

            # ìˆ˜ìµë¥  ë°ì´í„° ì¤€ë¹„
            returns_data = {}
            for symbol in symbols:
                if symbol in historical_data and len(historical_data[symbol]) > 1:
                    returns = historical_data[symbol]["close"].pct_change().dropna()
                    if len(returns) > 0:
                        returns_data[symbol] = returns

            if len(returns_data) < 2:
                logger.warning(
                    "Advanced optimization requires at least 2 assets with data"
                )
                return self._equal_weight(symbols)

            # ê³µí†µ ê¸°ê°„ìœ¼ë¡œ ì •ë ¬
            returns_df = pd.DataFrame(returns_data)
            returns_df = returns_df.dropna()

            if len(returns_df) < 30:  # ìµœì†Œ ë°ì´í„° í¬ì¸íŠ¸ í•„ìš”
                logger.warning("Advanced optimization requires at least 30 data points")
                return self._equal_weight(symbols)

            # ìµœì í™” ë°©ë²•ì„ ë¬¸ìì—´ë¡œ ì§ì ‘ ì „ë‹¬ (AdvancedPortfolioManagerì—ì„œ ì²˜ë¦¬)
            optimization_method = self.method

            # í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì‹¤í–‰ (AdvancedPortfolioManagerì˜ run_advanced_portfolio_management ì‚¬ìš©)
            try:
                # ì„ì‹œë¡œ AdvancedPortfolioManagerì˜ ìµœì í™” ë¡œì§ì„ ì§ì ‘ í˜¸ì¶œ
                from actions.portfolio_optimization import (
                    PortfolioOptimizer,
                    OptimizationMethod,
                )

                # ìˆ˜ìµë¥  ë°ì´í„° ì¤€ë¹„
                returns_data = {}
                for symbol in symbols:
                    if symbol in historical_data and len(historical_data[symbol]) > 1:
                        returns = historical_data[symbol]["close"].pct_change().dropna()
                        if len(returns) > 0:
                            returns_data[symbol] = returns

                if len(returns_data) < 2:
                    return self._equal_weight(symbols)

                returns_df = pd.DataFrame(returns_data)
                returns_df = returns_df.dropna()

                if len(returns_df) < 30:
                    return self._equal_weight(symbols)

                # PortfolioOptimizer ì§ì ‘ ì‚¬ìš©
                optimizer = PortfolioOptimizer(returns=returns_df, risk_free_rate=0.02)

                # ìµœì í™” ë°©ë²• ë§¤í•‘
                method_mapping = {
                    "sharpe_maximization": OptimizationMethod.SHARPE_MAXIMIZATION,
                    "sortino_maximization": OptimizationMethod.SORTINO_MAXIMIZATION,
                    "mean_variance": OptimizationMethod.MEAN_VARIANCE,
                    "risk_parity": OptimizationMethod.RISK_PARITY,
                    "minimum_variance": OptimizationMethod.MINIMUM_VARIANCE,
                    "maximum_diversification": OptimizationMethod.MAXIMUM_DIVERSIFICATION,
                    "black_litterman": OptimizationMethod.BLACK_LITTERMAN,
                    "kelly_criterion": OptimizationMethod.KELLY_CRITERION,
                }

                method = method_mapping.get(
                    self.method, OptimizationMethod.SHARPE_MAXIMIZATION
                )

                # ê¸°ë³¸ ì œì•½ì¡°ê±´
                from actions.portfolio_optimization import OptimizationConstraints

                constraints = OptimizationConstraints(
                    min_weight=0.0, max_weight=1.0, cash_weight=0.0, leverage=1.0
                )

                result = optimizer.optimize_portfolio(method, constraints)

            except Exception as e:
                logger.warning(f"Direct optimization failed: {e}, using equal weight")
                return self._equal_weight(symbols)

            if result and result.weights is not None:
                # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                weights = {}
                for i, symbol in enumerate(symbols):
                    if i < len(result.weights):
                        weights[symbol] = float(result.weights[i])
                    else:
                        weights[symbol] = 0.0
                return weights
            else:
                logger.warning("Advanced optimization failed, using equal weight")
                return self._equal_weight(symbols)

        except Exception as e:
            logger.warning(f"Advanced optimization error: {e}, using equal weight")
            return self._equal_weight(symbols)

    def _volatility_inverse_weight(
        self, historical_data: Dict[str, pd.DataFrame], symbols: List[str]
    ) -> Dict[str, float]:
        """ë³€ë™ì„± ì—­ë¹„ë¡€ ë¹„ì¤‘"""
        lookback = self.weight_methods["volatility_inverse"]["lookback_period"]
        volatilities = {}

        for symbol in symbols:
            if symbol in historical_data and len(historical_data[symbol]) >= lookback:
                returns = historical_data[symbol]["close"].pct_change().dropna()
                if len(returns) >= lookback:
                    volatility = returns.tail(lookback).std()
                    volatilities[symbol] = volatility

        if not volatilities:
            return self._equal_weight(symbols)

        # ë³€ë™ì„± ì—­ìˆ˜ ê³„ì‚°
        inv_volatilities = {symbol: 1 / vol for symbol, vol in volatilities.items()}
        total_inv_vol = sum(inv_volatilities.values())

        # ë¹„ì¤‘ ê³„ì‚°
        weights = {
            symbol: inv_vol / total_inv_vol
            for symbol, inv_vol in inv_volatilities.items()
        }
        return weights

    def _risk_parity_weight(
        self, historical_data: Dict[str, pd.DataFrame], symbols: List[str]
    ) -> Dict[str, float]:
        """ë¦¬ìŠ¤í¬ íŒ¨ë¦¬í‹° ë¹„ì¤‘ (fallback í¬í•¨)"""
        returns_data = {}
        min_length = float("inf")
        for symbol in symbols:
            if symbol in historical_data:
                returns = historical_data[symbol]["close"].pct_change().dropna()
                if len(returns) > 0:
                    returns_data[symbol] = returns
                    min_length = min(min_length, len(returns))
        if len(returns_data) < 2:
            self.fallback_stats["equal_weight"] += 1
            self.fallback_log.append("risk_parityâ†’equal_weight: insufficient data")
            return self._equal_weight(symbols)
        aligned_returns = {}
        for symbol in symbols:
            if symbol in returns_data:
                aligned_returns[symbol] = returns_data[symbol].tail(int(min_length))
        if len(aligned_returns) < 2:
            self.fallback_stats["equal_weight"] += 1
            self.fallback_log.append("risk_parityâ†’equal_weight: aligned insufficient")
            return self._equal_weight(symbols)
        returns_df = pd.DataFrame(aligned_returns)
        cov_matrix = returns_df.cov()
        # ê³µë¶„ì‚° í–‰ë ¬ ì •ê·œí™”(íŠ¹ì´í–‰ë ¬ ë°©ì§€)
        try:
            if np.linalg.cond(cov_matrix) > 1e8:
                cov_matrix += np.eye(len(cov_matrix)) * 1e-6
        except Exception as e:
            logger.warning(f"ê³µë¶„ì‚° í–‰ë ¬ cond ê³„ì‚° ì‹¤íŒ¨: {e}")
        n_assets = len(aligned_returns)
        initial_weights = np.array([1.0 / n_assets] * n_assets)

        def risk_parity_objective(weights):
            portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
            asset_contributions = (
                weights * (np.dot(cov_matrix, weights)) / portfolio_risk
            )
            return np.sum((asset_contributions - asset_contributions.mean()) ** 2)

        constraints = [{"type": "eq", "fun": lambda x: np.sum(x) - 1.0}]
        bounds = [(0.0, 1.0)] * n_assets
        try:
            result = minimize(
                risk_parity_objective,
                initial_weights,
                method="SLSQP",
                bounds=bounds,
                constraints=constraints,
                options={
                    "maxiter": self.weight_methods["risk_parity"]["max_iterations"]
                },
            )
            if result.success and np.all(result.x >= 0):
                self.fallback_stats["risk_parity"] += 1
                return {
                    symbol: weight
                    for symbol, weight in zip(aligned_returns.keys(), result.x)
                }
            else:
                logger.warning("ë¦¬ìŠ¤í¬ íŒ¨ë¦¬í‹° ìµœì í™” ì‹¤íŒ¨, ìµœì†Œë¶„ì‚° fallback")
                self.fallback_stats["min_variance"] += 1
                self.fallback_log.append("risk_parityâ†’min_variance")
                # ìµœì†Œë¶„ì‚° fallback
                minvar = self._min_variance_weight(historical_data, symbols)
                if sum(minvar.values()) > 0:
                    return minvar
                logger.warning("ìµœì†Œë¶„ì‚°ë„ ì‹¤íŒ¨, ë³€ë™ì„± ì—­ë¹„ë¡€ fallback")
                self.fallback_stats["volatility_inverse"] += 1
                self.fallback_log.append("min_varianceâ†’volatility_inverse")
                # ë³€ë™ì„± ì—­ë¹„ë¡€ fallback
                invvol = self._volatility_inverse_weight(historical_data, symbols)
                if sum(invvol.values()) > 0:
                    return invvol
                logger.warning("ë³€ë™ì„± ì—­ë¹„ë¡€ë„ ì‹¤íŒ¨, ë“±ê°€ fallback")
                self.fallback_stats["equal_weight"] += 1
                self.fallback_log.append("volatility_inverseâ†’equal_weight")
                return self._equal_weight(symbols)
        except Exception as e:
            logger.error(f"ë¦¬ìŠ¤í¬ íŒ¨ë¦¬í‹° ìµœì í™” ì˜ˆì™¸: {e}")
            self.fallback_stats["min_variance"] += 1
            self.fallback_log.append(f"risk_parity_exceptionâ†’min_variance: {e}")
            minvar = self._min_variance_weight(historical_data, symbols)
            if sum(minvar.values()) > 0:
                return minvar
            self.fallback_stats["volatility_inverse"] += 1
            self.fallback_log.append("min_varianceâ†’volatility_inverse")
            invvol = self._volatility_inverse_weight(historical_data, symbols)
            if sum(invvol.values()) > 0:
                return invvol
            self.fallback_stats["equal_weight"] += 1
            self.fallback_log.append("volatility_inverseâ†’equal_weight")
            return self._equal_weight(symbols)

    def _momentum_weight(
        self, historical_data: Dict[str, pd.DataFrame], symbols: List[str]
    ) -> Dict[str, float]:
        """ëª¨ë©˜í…€ ê¸°ë°˜ ë¹„ì¤‘"""
        momentum_period = self.weight_methods["momentum_weight"]["momentum_period"]
        top_n = self.weight_methods["momentum_weight"]["top_n_symbols"]

        momentums = {}

        for symbol in symbols:
            if (
                symbol in historical_data
                and len(historical_data[symbol]) >= momentum_period
            ):
                prices = historical_data[symbol]["close"]
                if len(prices) >= momentum_period:
                    momentum = (prices.iloc[-1] / prices.iloc[-momentum_period]) - 1
                    momentums[symbol] = momentum

        if not momentums:
            return self._equal_weight(symbols)

        # ìƒìœ„ Nê°œ ì¢…ëª© ì„ íƒ
        sorted_momentums = sorted(momentums.items(), key=lambda x: x[1], reverse=True)
        top_symbols = [symbol for symbol, _ in sorted_momentums[:top_n]]

        # ë¹„ì¤‘ ê³„ì‚° (ëª¨ë©˜í…€ì— ë¹„ë¡€)
        total_momentum = sum(momentums[symbol] for symbol in top_symbols)
        if total_momentum > 0:
            weights = {
                symbol: momentums[symbol] / total_momentum for symbol in top_symbols
            }
            # ë‚˜ë¨¸ì§€ ì¢…ëª©ì€ 0
            for symbol in symbols:
                if symbol not in weights:
                    weights[symbol] = 0.0
        else:
            weights = self._equal_weight(symbols)

        return weights

    def _min_variance_weight(
        self, historical_data: Dict[str, pd.DataFrame], symbols: List[str]
    ) -> Dict[str, float]:
        """ìµœì†Œ ë¶„ì‚° í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘"""
        lookback = self.weight_methods["min_variance"]["lookback_period"]

        # ìˆ˜ìµë¥  ë°ì´í„° ì¤€ë¹„
        returns_data = {}
        min_length = float("inf")

        for symbol in symbols:
            if symbol in historical_data:
                returns = historical_data[symbol]["close"].pct_change().dropna()
                if len(returns) >= lookback:
                    returns_data[symbol] = returns.tail(lookback)
                    min_length = min(min_length, len(returns))

        if len(returns_data) < 2:
            return self._equal_weight(symbols)

        # ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°
        returns_df = pd.DataFrame(returns_data)
        cov_matrix = returns_df.cov()

        # ìµœì†Œ ë¶„ì‚° ìµœì í™”
        n_assets = len(returns_data)
        initial_weights = np.array([1.0 / n_assets] * n_assets)

        def portfolio_variance(weights):
            return np.dot(weights.T, np.dot(cov_matrix, weights))

        # ì œì•½ì¡°ê±´: ë¹„ì¤‘ í•© = 1, ë¹„ì¤‘ >= 0
        constraints = [{"type": "eq", "fun": lambda x: np.sum(x) - 1.0}]
        bounds = [(0.0, 1.0)] * n_assets

        # ìµœì í™” ì‹¤í–‰
        result = minimize(
            portfolio_variance,
            initial_weights,
            method="SLSQP",
            bounds=bounds,
            constraints=constraints,
        )

        if result.success:
            weights = result.x
            return {
                symbol: weight for symbol, weight in zip(returns_data.keys(), weights)
            }
        else:
            logger.warning("ìµœì†Œ ë¶„ì‚° ìµœì í™” ì‹¤íŒ¨, ë“±ê°€ ë¹„ì¤‘ ì‚¬ìš©")
            return self._equal_weight(symbols)

    def print_weight_summary(self, weights_df: pd.DataFrame):
        """ë¹„ì¤‘ ìš”ì•½ ì¶œë ¥ ë° fallback í˜„í™© ì¶œë ¥"""
        print(f"\nğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ ìš”ì•½")
        print(f"ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°: {self.rebalance_period}íšŒ ê±°ë˜ë§ˆë‹¤")
        print(f"ë¹„ì¤‘ ê³„ì‚° ë°©ì‹: {self.method}")
        print("-" * 50)
        # í‰ê·  ë¹„ì¤‘
        avg_weights = weights_df.mean()
        print("í‰ê·  ë¹„ì¤‘:")
        if isinstance(avg_weights, pd.Series):
            for symbol, weight in avg_weights.items():
                print(f"  {symbol}: {weight*100:.1f}%")
        else:
            print("  í‰ê·  ë¹„ì¤‘ ê³„ì‚° ë¶ˆê°€")
        # ë¹„ì¤‘ ë³€ë™ì„±
        weight_volatility = weights_df.std()
        print(f"\në¹„ì¤‘ ë³€ë™ì„± (í‘œì¤€í¸ì°¨):")
        if isinstance(weight_volatility, pd.Series):
            for symbol, vol in weight_volatility.items():
                print(f"  {symbol}: {vol*100:.1f}%")
        else:
            print("  ë¹„ì¤‘ ë³€ë™ì„± ê³„ì‚° ë¶ˆê°€")
        # ë¦¬ë°¸ëŸ°ì‹± íšŸìˆ˜
        rebalance_count = len(weights_df) // self.rebalance_period
        print(f"\nì´ ë¦¬ë°¸ëŸ°ì‹± íšŸìˆ˜: {rebalance_count}íšŒ")
        # fallback í˜„í™©
        print(f"\nFallback í˜„í™©:")
        for k, v in self.fallback_stats.items():
            print(f"  {k}: {v}íšŒ")
        if self.fallback_log:
            print("  ìµœê·¼ fallback ë¡œê·¸:")
            for log in self.fallback_log[-5:]:
                print(f"    - {log}")


def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    print("PortfolioWeightCalculator í…ŒìŠ¤íŠ¸")

    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    dates = pd.date_range(start="2024-01-01", end="2024-01-31", freq="D")
    symbols = ["NVDL", "TSLL", "CONL"]

    data_dict = {}
    for symbol in symbols:
        np.random.seed(hash(symbol) % 1000)
        close_prices = [100.0]  # floatë¡œ ì´ˆê¸°í™”
        for i in range(len(dates) - 1):
            change = np.random.normal(0, 0.02)
            close_prices.append(close_prices[-1] * (1 + change))

        df = pd.DataFrame(
            {
                "datetime": dates,
                "close": close_prices,
                "open": [p * (1 + np.random.normal(0, 0.005)) for p in close_prices],
                "high": [
                    p * (1 + abs(np.random.normal(0, 0.01))) for p in close_prices
                ],
                "low": [p * (1 - abs(np.random.normal(0, 0.01))) for p in close_prices],
                "volume": np.random.randint(1000000, 10000000, len(dates)),
            }
        )
        data_dict[symbol] = df

    # ë¹„ì¤‘ ê³„ì‚°
    calculator = PortfolioWeightCalculator()
    weights_df = calculator.calculate_optimal_weights(data_dict)

    # ê²°ê³¼ ì¶œë ¥
    print(f"\në¹„ì¤‘ DataFrame í˜•íƒœ: {weights_df.shape}")
    print(f"ì»¬ëŸ¼: {list(weights_df.columns)}")
    print(f"\nì²˜ìŒ 5ê°œ ì‹œì ì˜ ë¹„ì¤‘:")
    print(weights_df.head())

    # ë¹„ì¤‘ ìš”ì•½
    calculator.print_weight_summary(weights_df)


if __name__ == "__main__":
    main()
