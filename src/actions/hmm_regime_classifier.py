"""
HMM ê¸°ë°˜ ì‹œì¥ ì²´ì œ ë¶„ë¥˜ê¸°
Hidden Markov Modelsë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œì¥ì„ 4ê°€ì§€ ì²´ì œë¡œ ë¶„ë¥˜
- BULLISH: ìƒìŠ¹ ì¶”ì„¸
- BEARISH: í•˜ë½ ì¶”ì„¸
- SIDEWAYS: íš¡ë³´
- VOLATILE: ê³ ë³€ë™ì„±
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from hmmlearn import hmm
import joblib
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import warnings

warnings.filterwarnings("ignore")

logger = logging.getLogger(__name__)


class MarketRegimeHMM:
    """
    Hidden Markov Modelì„ ì‚¬ìš©í•œ ì‹œì¥ ì²´ì œ ë¶„ë¥˜ê¸°

    Features:
    - VIX ìˆ˜ì¤€ (ë³€ë™ì„± ì§€í‘œ)
    - ìˆ˜ìµë¥  ê³¡ì„  ê¸°ìš¸ê¸° (TNX - IRX)
    - ë‹¬ëŸ¬ ê°•ì„¸ ì§€ìˆ˜
    - ì„¹í„° íšŒì „ìœ¨
    - ëª¨ë©˜í…€ ì§€í‘œë“¤
    """

    def __init__(self, config: Dict):
        self.config = config
        self.hmm_config = config.get("hmm_regime", {})

        # ì‹œì¥ ì²´ì œ ì •ì˜
        self.states = ["BULLISH", "BEARISH", "SIDEWAYS", "VOLATILE"]
        self.n_states = len(self.states)

        # HMM ëª¨ë¸ ì´ˆê¸°í™”
        self.model = hmm.GaussianHMM(
            n_components=self.n_states,
            covariance_type=self.hmm_config.get("covariance_type", "diag"),
            n_iter=self.hmm_config.get("n_iter", 100),
            random_state=42,
        )

        # ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”
        self.scaler = StandardScaler()

        # ëª¨ë¸ í•™ìŠµ ìƒíƒœ
        self.is_fitted = False
        self.feature_names = []

        logger.info(f"MarketRegimeHMM ì´ˆê¸°í™” ì™„ë£Œ - States: {self.states}")

    def extract_macro_features(self, macro_data: pd.DataFrame) -> pd.DataFrame:
        """
        ë§¤í¬ë¡œ ë°ì´í„°ì—ì„œ HMM í”¼ì²˜ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)
        
        ìƒˆë¡œìš´ ê¸°ëŠ¥:
        - ë™ì  VIX ì„ê³„ê°’
        - ì‹ ìš© ìŠ¤í”„ë ˆë“œ ì§€í‘œ
        - ê°œì„ ëœ ì²´ì œ ê°ì§€

        Args:
            macro_data: ë§¤í¬ë¡œ ê²½ì œ ë°ì´í„°

        Returns:
            í”¼ì²˜ ë°ì´í„°í”„ë ˆì„
        """
        features = pd.DataFrame(index=macro_data.index)

        try:
            # ë§¤í¬ë¡œ ë°ì´í„° ì»¬ëŸ¼ëª… í™•ì¸ ë° ì •ê·œí™” (ê°„ì†Œí™”)
            unique_symbols = set()
            for col in macro_data.columns:
                symbol = col.split("_")[0]
                unique_symbols.add(symbol)
            logger.info(
                f"ë§¤í¬ë¡œ ë°ì´í„°: {len(macro_data.columns)}ê°œ ì»¬ëŸ¼, ì‹¬ë³¼: {sorted(unique_symbols)}"
            )

            # 1. VIX ìˆ˜ì¤€ (ë³€ë™ì„±) - ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ì‹œë„
            vix_col = None
            for col in ["vix", "vix_close", "^vix", "vix_data"]:
                if col in macro_data.columns:
                    vix_col = col
                    break

            if vix_col is not None:
                # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
                vix_data = pd.to_numeric(macro_data[vix_col], errors="coerce").fillna(
                    20.0
                )
                features["vix_level"] = vix_data
                features["vix_ma_ratio"] = vix_data / vix_data.rolling(
                    20
                ).mean().fillna(1.0)
            else:
                logger.warning("VIX ë°ì´í„° ì—†ìŒ")
                features["vix_level"] = 20.0  # ê¸°ë³¸ê°’
                features["vix_ma_ratio"] = 1.0

            # 2. ìˆ˜ìµë¥  ê³¡ì„  ê¸°ìš¸ê¸° - ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ì‹œë„
            tnx_col = None
            irx_col = None
            for col in ["tnx", "tnx_close", "^tnx", "tnx_data"]:
                if col in macro_data.columns:
                    tnx_col = col
                    break
            for col in ["irx", "irx_close", "^irx", "irx_data"]:
                if col in macro_data.columns:
                    irx_col = col
                    break

            if tnx_col is not None and irx_col is not None:
                # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
                tnx_data = pd.to_numeric(macro_data[tnx_col], errors="coerce").fillna(
                    2.0
                )
                irx_data = pd.to_numeric(macro_data[irx_col], errors="coerce").fillna(
                    0.5
                )
                features["yield_spread"] = tnx_data - irx_data
                features["yield_spread_ma"] = (
                    features["yield_spread"].rolling(10).mean().fillna(1.5)
                )
            else:
                logger.warning("ê¸ˆë¦¬ ë°ì´í„° ì—†ìŒ")
                features["yield_spread"] = 1.5  # ê¸°ë³¸ê°’
                features["yield_spread_ma"] = 1.5

            # 3. ë‹¬ëŸ¬ ê°•ì„¸ (UUP ë˜ëŠ” DXY ëŒ€ìš©) - ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ì‹œë„
            dollar_col = None
            dollar_patterns = ["uup_close", "uup", "dxy_close", "dxy", "uup_data"]
            for pattern in dollar_patterns:
                if pattern in macro_data.columns:
                    dollar_col = pattern
                    break

            if dollar_col is not None:
                # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
                dollar_data = pd.to_numeric(
                    macro_data[dollar_col], errors="coerce"
                ).fillna(25.0)
                features["dollar_strength"] = dollar_data.pct_change(20).fillna(0)
                features["dollar_momentum"] = dollar_data.pct_change(5).fillna(0)
                logger.info(f"ë‹¬ëŸ¬ ê°•ì„¸ ë°ì´í„° ì‚¬ìš©: {dollar_col}")
            else:
                logger.warning("ë‹¬ëŸ¬ ê°•ì„¸ ë°ì´í„° ì—†ìŒ")
                features["dollar_strength"] = 0.0
                features["dollar_momentum"] = 0.0

            # 4. ê°œì„ ëœ ë³€ë™ì„± ì²´ì œ (ë™ì  VIX ì„ê³„ê°’)
            if vix_col is not None:
                vix_data = pd.to_numeric(macro_data[vix_col], errors="coerce").fillna(
                    20.0
                )
                # ë™ì  ì„ê³„ê°’ ê³„ì‚° (60ì¼ ë¡¤ë§ ë°±ë¶„ìœ„ìˆ˜)
                vix_low_threshold = vix_data.rolling(60, min_periods=20).quantile(0.25)
                vix_high_threshold = vix_data.rolling(60, min_periods=20).quantile(0.75)
                
                # ë™ì  ì²´ì œ ë¶„ë¥˜
                features["volatility_regime"] = np.where(
                    vix_data > vix_high_threshold.fillna(25), 1, 
                    np.where(vix_data < vix_low_threshold.fillna(15), -1, 0)
                )
                features["vix_acceleration"] = vix_data.diff(2).fillna(0)
                features["vix_percentile"] = (
                    vix_data.rolling(252, min_periods=60)
                    .rank(pct=True).fillna(0.5)
                )
                logger.info("ë™ì  VIX ì„ê³„ê°’ ì ìš© ì™„ë£Œ")
            else:
                features["volatility_regime"] = 0
                features["vix_acceleration"] = 0
                features["vix_percentile"] = 0.5

            # 5. ëª¨ë©˜í…€ ì§€í‘œ (SPY ê¸°ë°˜) - ê°œì„ ëœ ê²€ìƒ‰
            spy_col = None
            spy_patterns = ["spy_close", "spy", "spy_data"]
            for pattern in spy_patterns:
                if pattern in macro_data.columns:
                    spy_col = pattern
                    break

            if spy_col is not None:
                # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
                spy_data = pd.to_numeric(macro_data[spy_col], errors="coerce").fillna(
                    400.0
                )
                features["market_momentum"] = spy_data.pct_change(20).fillna(0)
                features["market_trend"] = (
                    spy_data / spy_data.rolling(50).mean() - 1
                ).fillna(0)
                logger.info(f"SPY ë°ì´í„° ì‚¬ìš©: {spy_col}")
            else:
                logger.warning("SPY ë°ì´í„° ì—†ìŒ")
                features["market_momentum"] = 0.0
                features["market_trend"] = 0.0

            # 6. ì‹ ìš© ìŠ¤í”„ë ˆë“œ ì§€í‘œ ì¶”ê°€
            self._add_credit_spread_features(features, macro_data)
            
            # 7. ì¶”ê°€ í”¼ì²˜ë“¤
            features["cross_market_stress"] = features["vix_level"] * abs(
                features["yield_spread"]
            )
            features["regime_transition"] = (
                features["volatility_regime"].diff().fillna(0)
            )
            
            # 8. ì²´ì œ ì§€ì†ì„± ì§€í‘œ
            features["regime_persistence"] = self._calculate_regime_persistence(features)
            
            # 9. ì‹œì¥ ìŠ¤íŠ¸ë ˆìŠ¤ ë³µí•© ì§€í‘œ
            features["market_stress_composite"] = self._calculate_market_stress_composite(features)

            # NaN ì²˜ë¦¬
            features = features.fillna(method="ffill").fillna(0)

            self.feature_names = list(features.columns)
            logger.info(f"ì¶”ì¶œëœ í”¼ì²˜ ({len(self.feature_names)}ê°œ): {self.feature_names}")

            return features

        except Exception as e:
            logger.error(f"ë§¤í¬ë¡œ í”¼ì²˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ í”¼ì²˜ ë°˜í™˜
            n_rows = len(macro_data)
            default_features = pd.DataFrame(
                {
                    "vix_level": [20.0] * n_rows,
                    "yield_spread": [1.5] * n_rows,
                    "dollar_strength": [0.0] * n_rows,
                    "volatility_regime": [0] * n_rows,
                    "market_momentum": [0.0] * n_rows,
                },
                index=macro_data.index,
            )

            self.feature_names = list(default_features.columns)
            return default_features

    def _add_credit_spread_features(self, features: pd.DataFrame, macro_data: pd.DataFrame):
        """ì‹ ìš© ìŠ¤í”„ë ˆë“œ ì§€í‘œ ì¶”ê°€"""
        try:
            # HYG (ê³ ìˆ˜ìµ íšŒì‚¬ì±„ ETF) ê²€ìƒ‰
            hyg_col = None
            for col in ["hyg_close", "hyg", "hyg_data"]:
                if col in macro_data.columns:
                    hyg_col = col
                    break
            
            # LQD (íˆ¬ìë“±ê¸‰ íšŒì‚¬ì±„ ETF) ê²€ìƒ‰
            lqd_col = None
            for col in ["lqd_close", "lqd", "lqd_data"]:
                if col in macro_data.columns:
                    lqd_col = col
                    break
                    
            # TLT (ì¥ê¸° êµ­ì±„ ETF) ê²€ìƒ‰
            tlt_col = None
            for col in ["tlt_close", "tlt", "tlt_data"]:
                if col in macro_data.columns:
                    tlt_col = col
                    break
            
            if hyg_col and tlt_col:
                hyg_data = pd.to_numeric(macro_data[hyg_col], errors="coerce").fillna(100.0)
                tlt_data = pd.to_numeric(macro_data[tlt_col], errors="coerce").fillna(120.0)
                
                # HYG-TLT ìŠ¤í”„ë ˆë“œ (ì‹ ìš© ìœ„í—˜ ì§€í‘œ)
                features["credit_spread"] = (hyg_data / tlt_data).pct_change(20).fillna(0)
                features["credit_stress"] = np.where(features["credit_spread"] < -0.05, 1, 0)
                logger.info("HYG-TLT ì‹ ìš© ìŠ¤í”„ë ˆë“œ ì§€í‘œ ì¶”ê°€")
            else:
                features["credit_spread"] = 0.0
                features["credit_stress"] = 0
                
            if lqd_col and tlt_col:
                lqd_data = pd.to_numeric(macro_data[lqd_col], errors="coerce").fillna(110.0)
                tlt_data = pd.to_numeric(macro_data[tlt_col], errors="coerce").fillna(120.0)
                
                # LQD-TLT ìŠ¤í”„ë ˆë“œ (íˆ¬ìë“±ê¸‰ ì‹ ìš© ìŠ¤í”„ë ˆë“œ)
                features["ig_credit_spread"] = (lqd_data / tlt_data).pct_change(20).fillna(0)
                logger.info("LQD-TLT íˆ¬ìë“±ê¸‰ ìŠ¤í”„ë ˆë“œ ì§€í‘œ ì¶”ê°€")
            else:
                features["ig_credit_spread"] = 0.0
                
        except Exception as e:
            logger.warning(f"ì‹ ìš© ìŠ¤í”„ë ˆë“œ ì§€í‘œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            features["credit_spread"] = 0.0
            features["credit_stress"] = 0
            features["ig_credit_spread"] = 0.0
    
    def _calculate_regime_persistence(self, features: pd.DataFrame) -> pd.Series:
        """ì²´ì œ ì§€ì†ì„± ì§€í‘œ ê³„ì‚°"""
        try:
            if "volatility_regime" not in features.columns:
                return pd.Series(0.5, index=features.index)
                
            vol_regime = features["volatility_regime"]
            
            # ë™ì¼ ì²´ì œ ì§€ì† ê¸°ê°„ ê³„ì‚°
            regime_changes = vol_regime != vol_regime.shift(1)
            regime_groups = regime_changes.cumsum()
            
            persistence = []
            for i, group in enumerate(regime_groups):
                if i == 0:
                    persistence.append(1)
                else:
                    # í˜„ì¬ ì²´ì œê°€ ì§€ì†ëœ ê¸°ê°„
                    same_regime_count = (regime_groups[:i+1] == group).sum()
                    # ìµœëŒ€ 20ì¼ë¡œ ì •ê·œí™”
                    normalized_persistence = min(same_regime_count / 20.0, 1.0)
                    persistence.append(normalized_persistence)
            
            return pd.Series(persistence, index=features.index)
            
        except Exception as e:
            logger.warning(f"ì²´ì œ ì§€ì†ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return pd.Series(0.5, index=features.index)
    
    def _calculate_market_stress_composite(self, features: pd.DataFrame) -> pd.Series:
        """ì‹œì¥ ìŠ¤íŠ¸ë ˆìŠ¤ ë³µí•© ì§€í‘œ ê³„ì‚°"""
        try:
            components = []
            weights = []
            
            # VIX ì»´í¬ë„ŒíŠ¸
            if "vix_level" in features.columns:
                vix_stress = np.clip(features["vix_level"] / 40.0, 0, 1)
                components.append(vix_stress)
                weights.append(0.3)
            
            # ì‹ ìš© ìŠ¤í”„ë ˆë“œ ì»´í¬ë„ŒíŠ¸
            if "credit_spread" in features.columns:
                credit_stress = np.clip(-features["credit_spread"] * 5, 0, 1)
                components.append(credit_stress)
                weights.append(0.25)
            
            # ìˆ˜ìµë¥  ê³¡ì„  ì»´í¬ë„ŒíŠ¸
            if "yield_spread" in features.columns:
                # ì—­ì „ëœ ìˆ˜ìµë¥  ê³¡ì„ ì€ ìŠ¤íŠ¸ë ˆìŠ¤ ì‹ í˜¸
                yield_stress = np.clip(-features["yield_spread"] + 2, 0, 1)
                components.append(yield_stress)
                weights.append(0.2)
            
            # ë‹¬ëŸ¬ ê°•ì„¸ ì»´í¬ë„ŒíŠ¸
            if "dollar_strength" in features.columns:
                dollar_stress = np.clip(abs(features["dollar_strength"]) * 2, 0, 1)
                components.append(dollar_stress)
                weights.append(0.15)
            
            # ëª¨ë©˜í…€ ì»´í¬ë„ŒíŠ¸  
            if "market_momentum" in features.columns:
                momentum_stress = np.clip(-features["market_momentum"] * 3, 0, 1)
                components.append(momentum_stress)
                weights.append(0.1)
            
            if components:
                # ê°€ì¤‘ í‰ê·  ê³„ì‚°
                weights = np.array(weights) / sum(weights)  # ì •ê·œí™”
                composite = sum(w * comp for w, comp in zip(weights, components))
                return composite.fillna(0.5)
            else:
                return pd.Series(0.5, index=features.index)
                
        except Exception as e:
            logger.warning(f"ì‹œì¥ ìŠ¤íŠ¸ë ˆìŠ¤ ë³µí•© ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return pd.Series(0.5, index=features.index)

    def _walk_forward_validation(self, features: pd.DataFrame, n_splits: int = 5) -> float:
        """
        ì›Œí¬í¬ì›Œë“œ ê²€ì¦ ìˆ˜í–‰
        
        Args:
            features: í”¼ì²˜ ë°ì´í„°
            n_splits: ê²€ì¦ ë¶„í•  ìˆ˜
            
        Returns:
            í‰ê·  ê²€ì¦ ì ìˆ˜
        """
        try:
            if len(features) < 100:
                logger.warning("ì›Œí¬í¬ì›Œë“œ ê²€ì¦ì„ ìœ„í•œ ë°ì´í„° ë¶€ì¡±")
                return 0.5
                
            scores = []
            min_train_size = max(50, len(features) // (n_splits + 1))
            
            for i in range(n_splits):
                # ë¶„í•  ì§€ì  ê³„ì‚°
                train_end = min_train_size + i * (len(features) - min_train_size) // n_splits
                test_start = train_end
                test_end = min(test_start + 20, len(features))  # 20ì¼ í…ŒìŠ¤íŠ¸ ìœˆë„ìš°
                
                if test_end <= test_start:
                    continue
                    
                # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
                train_features = features.iloc[:train_end]
                test_features = features.iloc[test_start:test_end]
                
                # ì„ì‹œ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
                temp_model = hmm.GaussianHMM(
                    n_components=self.n_states,
                    covariance_type=self.model.covariance_type,
                    n_iter=100,
                    random_state=42,
                )
                
                temp_scaler = StandardScaler()
                train_scaled = temp_scaler.fit_transform(train_features)
                
                try:
                    temp_model.fit(train_scaled)
                    
                    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
                    test_scaled = temp_scaler.transform(test_features)
                    predicted_states = temp_model.predict(test_scaled)
                    
                    # ì˜ˆì¸¡ ì¼ê´€ì„± ì ìˆ˜ (ì—°ì†ëœ ì˜ˆì¸¡ì˜ ì•ˆì •ì„±)
                    if len(predicted_states) > 1:
                        stability_score = 1 - (np.diff(predicted_states) != 0).mean()
                        scores.append(stability_score)
                        
                except Exception as e:
                    logger.warning(f"ì›Œí¬í¬ì›Œë“œ ê²€ì¦ {i+1}ë²ˆì§¸ ë¶„í•  ì‹¤íŒ¨: {e}")
                    continue
            
            if scores:
                avg_score = np.mean(scores)
                logger.info(f"ì›Œí¬í¬ì›Œë“œ ê²€ì¦ ì™„ë£Œ: {len(scores)}ê°œ ë¶„í• , í‰ê·  ì ìˆ˜: {avg_score:.3f}")
                return avg_score
            else:
                logger.warning("ì›Œí¬í¬ì›Œë“œ ê²€ì¦ ì‹¤íŒ¨")
                return 0.5
                
        except Exception as e:
            logger.error(f"ì›Œí¬í¬ì›Œë“œ ê²€ì¦ ì˜¤ë¥˜: {e}")
            return 0.5

    def fit(self, macro_data: pd.DataFrame) -> bool:
        """
        HMM ëª¨ë¸ í•™ìŠµ

        Args:
            macro_data: í•™ìŠµìš© ë§¤í¬ë¡œ ë°ì´í„°

        Returns:
            í•™ìŠµ ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info("HMM ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

            # í”¼ì²˜ ì¶”ì¶œ
            features = self.extract_macro_features(macro_data)

            if len(features) < 200:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ëŸ‰ (ê°œì„ )
                logger.warning(f"í•™ìŠµ ë°ì´í„° ë¶€ì¡±: {len(features)}ê°œ (ìµœì†Œ 200ê°œ í•„ìš”)")
                return False

            # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
            scaled_features = self.scaler.fit_transform(features)

            # HMM ëª¨ë¸ í•™ìŠµ
            self.model.fit(scaled_features)

            # í•™ìŠµëœ ìƒíƒœ í•´ì„
            self._interpret_states(scaled_features, features)

            # ì›Œí¬í¬ì›Œë“œ ê²€ì¦ ìˆ˜í–‰
            validation_score = self._walk_forward_validation(features)
            logger.info(f"ì›Œí¬í¬ì›Œë“œ ê²€ì¦ ì ìˆ˜: {validation_score:.3f}")

            self.is_fitted = True
            logger.info("HMM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

            return True

        except Exception as e:
            logger.error(f"HMM ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False

    def _interpret_states(
        self, scaled_features: np.ndarray, original_features: pd.DataFrame
    ):
        """
        í•™ìŠµëœ HMM ìƒíƒœë“¤ì„ í•´ì„í•˜ì—¬ BULLISH, BEARISH ë“±ìœ¼ë¡œ ë§¤í•‘
        """
        try:
            # ìƒíƒœ ì˜ˆì¸¡
            states = self.model.predict(scaled_features)

            # ê° ìƒíƒœë³„ íŠ¹ì„± ë¶„ì„
            state_characteristics = {}

            for state_idx in range(self.n_states):
                mask = states == state_idx
                if mask.sum() == 0:
                    continue

                state_data = original_features[mask]

                characteristics = {
                    "vix_mean": (
                        state_data["vix_level"].mean()
                        if "vix_level" in state_data.columns
                        else 20
                    ),
                    "volatility_regime": (
                        state_data["volatility_regime"].mean()
                        if "volatility_regime" in state_data.columns
                        else 0
                    ),
                    "market_momentum": (
                        state_data["market_momentum"].mean()
                        if "market_momentum" in state_data.columns
                        else 0
                    ),
                    "yield_spread": (
                        state_data["yield_spread"].mean()
                        if "yield_spread" in state_data.columns
                        else 1.5
                    ),
                    "frequency": mask.sum(),
                }

                state_characteristics[state_idx] = characteristics

            # ìƒíƒœ ë§¤í•‘ ê·œì¹™
            state_mapping = {}

            for state_idx, chars in state_characteristics.items():
                vix = chars["vix_mean"]
                momentum = chars["market_momentum"]
                vol_regime = chars["volatility_regime"]

                # ê°œì„ ëœ ìƒíƒœ ë¶„ë¥˜ ë¡œì§
                # 1ì°¨: ë³€ë™ì„± ê¸°ì¤€
                if vix > 28 or vol_regime > 0.6:
                    regime = "VOLATILE"
                # 2ì°¨: ëª¨ë©˜í…€ ê¸°ì¤€ (ë” ë³´ìˆ˜ì  ì„ê³„ê°’)
                elif momentum > 0.015:
                    regime = "BULLISH"
                elif momentum < -0.015:
                    regime = "BEARISH"
                # 3ì°¨: ë³µí•© ì§€í‘œ ê³ ë ¤
                else:
                    # ì‹ ìš© ìŠ¤í”„ë ˆë“œë‚˜ ê¸°íƒ€ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€í‘œ í™•ì¸
                    if hasattr(chars, 'credit_stress') and chars.get('credit_stress', 0) > 0.5:
                        regime = "VOLATILE"
                    else:
                        regime = "SIDEWAYS"

                state_mapping[state_idx] = regime

            self.state_mapping = state_mapping
            logger.info(f"ìƒíƒœ ë§¤í•‘: {state_mapping}")

        except Exception as e:
            logger.error(f"ìƒíƒœ í•´ì„ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë§¤í•‘
            self.state_mapping = {i: self.states[i] for i in range(self.n_states)}

    def predict_regime(self, macro_data: pd.DataFrame) -> Dict:
        """
        í˜„ì¬ ì‹œì¥ ì²´ì œ ì˜ˆì¸¡

        Args:
            macro_data: ì˜ˆì¸¡ìš© ë§¤í¬ë¡œ ë°ì´í„° (ìµœê·¼ ë°ì´í„°)

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.is_fitted:
            logger.error("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return self._get_default_prediction()

        try:
            # í”¼ì²˜ ì¶”ì¶œ
            features = self.extract_macro_features(macro_data)

            if len(features) == 0:
                return self._get_default_prediction()

            # ìµœê·¼ ë°ì´í„°ë§Œ ì‚¬ìš© (ë§ˆì§€ë§‰ 1ê°œ)
            recent_features = features.iloc[-1:].values
            scaled_features = self.scaler.transform(recent_features)

            # ìƒíƒœ ì˜ˆì¸¡
            predicted_state_idx = self.model.predict(scaled_features)[0]

            # ìƒíƒœ í™•ë¥  ê³„ì‚°
            log_probs = self.model.score_samples(scaled_features)[0]
            state_probs = self.model.predict_proba(scaled_features)[0]

            # ë§¤í•‘ëœ ì²´ì œëª…
            predicted_regime = self.state_mapping.get(predicted_state_idx, "SIDEWAYS")

            # ì‹ ë¢°ë„ ì¡°ì • (ê³¼ë„í•œ í™•ì‹  ë°©ì§€)
            raw_confidence = float(state_probs[predicted_state_idx])
            # ì‹ ë¢°ë„ë¥¼ 0.3~0.9 ë²”ìœ„ë¡œ ì œí•œí•˜ê³  ë¶ˆí™•ì‹¤ì„± ì¶”ê°€
            confidence = min(0.9, max(0.3, raw_confidence * 0.8 + 0.1))

            # ì²´ì œ ê°•ë„ ê³„ì‚°
            regime_strength = self._calculate_regime_strength(features.iloc[-1])

            # ì¶”ê°€ ë¶„ì„
            current_features = features.iloc[-1]

            result = {
                "regime": predicted_regime,
                "confidence": confidence,
                "regime_strength": regime_strength,
                "state_probabilities": {
                    self.state_mapping.get(i, f"State_{i}"): float(prob)
                    for i, prob in enumerate(state_probs)
                },
                "features": {
                    "vix_level": float(current_features.get("vix_level", 20)),
                    "yield_spread": float(current_features.get("yield_spread", 1.5)),
                    "market_momentum": float(
                        current_features.get("market_momentum", 0)
                    ),
                    "volatility_regime": float(
                        current_features.get("volatility_regime", 0)
                    ),
                },
                "timestamp": datetime.now().isoformat(),
                "model_info": {
                    "n_states": self.n_states,
                    "state_mapping": self.state_mapping,
                    "is_fitted": self.is_fitted,
                },
            }

            logger.info(
                f"ì˜ˆì¸¡ëœ ì‹œì¥ ì²´ì œ: {predicted_regime} (ì‹ ë¢°ë„: {confidence:.3f})"
            )

            return result

        except Exception as e:
            logger.error(f"ì‹œì¥ ì²´ì œ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return self._get_default_prediction()

    def _calculate_regime_strength(self, features: pd.Series) -> float:
        """
        ì²´ì œ ê°•ë„ ê³„ì‚° (0~1 ìŠ¤ì¼€ì¼)
        """
        try:
            vix = features.get("vix_level", 20)
            momentum = abs(features.get("market_momentum", 0))
            yield_spread = abs(features.get("yield_spread", 1.5))

            # ì •ê·œí™”ëœ ê°•ë„ ê³„ì‚°
            vix_strength = min(1.0, vix / 30)  # VIX 30ì„ ìµœëŒ€ë¡œ
            momentum_strength = min(1.0, momentum * 10)  # 10% ëª¨ë©˜í…€ì„ ìµœëŒ€ë¡œ
            yield_strength = min(1.0, yield_spread / 3)  # 3% ìŠ¤í”„ë ˆë“œë¥¼ ìµœëŒ€ë¡œ

            # ê°€ì¤‘ í‰ê· 
            strength = (
                vix_strength * 0.4 + momentum_strength * 0.4 + yield_strength * 0.2
            )

            return float(np.clip(strength, 0, 1))

        except Exception as e:
            logger.error(f"ì²´ì œ ê°•ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    def _get_default_prediction(self) -> Dict:
        """
        ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼ (ëª¨ë¸ ì‹¤íŒ¨ì‹œ)
        """
        return {
            "regime": "SIDEWAYS",
            "confidence": 0.25,  # ë‚®ì€ ì‹ ë¢°ë„
            "regime_strength": 0.5,
            "state_probabilities": {regime: 0.25 for regime in self.states},
            "features": {
                "vix_level": 20.0,
                "yield_spread": 1.5,
                "market_momentum": 0.0,
                "volatility_regime": 0,
            },
            "timestamp": datetime.now().isoformat(),
            "model_info": {
                "n_states": self.n_states,
                "state_mapping": {i: regime for i, regime in enumerate(self.states)},
                "is_fitted": False,
            },
        }

    def save_model(self, filepath: str) -> bool:
        """
        ëª¨ë¸ ì €ì¥
        """
        try:
            model_data = {
                "hmm_model": self.model,
                "scaler": self.scaler,
                "state_mapping": self.state_mapping,
                "feature_names": self.feature_names,
                "config": self.config,
                "is_fitted": self.is_fitted,
            }

            joblib.dump(model_data, filepath)
            logger.info(f"HMM ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")
            return True

        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def load_model(self, filepath: str) -> bool:
        """
        ëª¨ë¸ ë¡œë“œ
        """
        try:
            model_data = joblib.load(filepath)

            self.model = model_data["hmm_model"]
            self.scaler = model_data["scaler"]
            self.state_mapping = model_data["state_mapping"]
            self.feature_names = model_data["feature_names"]
            self.is_fitted = model_data["is_fitted"]

            logger.info(f"HMM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {filepath}")
            return True

        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False


class RegimeTransitionAnalyzer:
    """
    ì‹œì¥ ì²´ì œ ì „í™˜ ë¶„ì„ê¸°
    ì²´ì œ ë³€í™”ì˜ ì§€ì†ì„±ê³¼ ì „í™˜ í™•ë¥ ì„ ë¶„ì„
    """

    def __init__(self, config: Dict):
        self.config = config
        self.transition_history = []

    def analyze_transition_probability(self, regime_history: List[Dict]) -> Dict:
        """
        ì²´ì œ ì „í™˜ í™•ë¥  ë¶„ì„
        """
        try:
            if len(regime_history) < 10:
                return {"transition_probability": 0.5, "stability": "unknown"}

            regimes = [r["regime"] for r in regime_history]
            transitions = 0

            for i in range(1, len(regimes)):
                if regimes[i] != regimes[i - 1]:
                    transitions += 1

            transition_rate = transitions / (len(regimes) - 1)

            # ì•ˆì •ì„± í‰ê°€
            if transition_rate < 0.1:
                stability = "very_stable"
            elif transition_rate < 0.2:
                stability = "stable"
            elif transition_rate < 0.4:
                stability = "moderate"
            else:
                stability = "volatile"

            return {
                "transition_probability": transition_rate,
                "stability": stability,
                "recent_transitions": transitions,
                "analysis_period": len(regimes),
            }

        except Exception as e:
            logger.error(f"ì²´ì œ ì „í™˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"transition_probability": 0.5, "stability": "unknown"}


def main():
    """ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤"""
    import argparse
    import json
    import os
    import sys
    from pathlib import Path

    parser = argparse.ArgumentParser(description="HMM ì‹œì¥ ì²´ì œ ë¶„ë¥˜ê¸°")
    parser.add_argument("--train", action="store_true", help="ëª¨ë¸ í•™ìŠµ")
    parser.add_argument("--force", action="store_true", help="ê°•ì œ ì¬í•™ìŠµ")
    parser.add_argument(
        "--data-dir", type=str, default="data/macro", help="ë§¤í¬ë¡œ ë°ì´í„° ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--config", type=str, default="config/config_trader.json", help="ì„¤ì • íŒŒì¼"
    )
    parser.add_argument(
        "--model-dir", type=str, default="models/trader", help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument("--predict", action="store_true", help="í˜„ì¬ ì‹œì¥ ì²´ì œ ì˜ˆì¸¡")

    args = parser.parse_args()

    # ì„¤ì • íŒŒì¼ ë¡œë“œ
    try:
        with open(args.config, "r", encoding="utf-8") as f:
            config = json.load(f)
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # HMM ëª¨ë¸ ì´ˆê¸°í™”
    hmm = MarketRegimeHMM(config)

    # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
    model_dir = Path(args.model_dir)
    model_dir.mkdir(parents=True, exist_ok=True)
    model_path = model_dir / "hmm_regime_model.pkl"

    if args.train:
        print("ğŸ­ HMM ì‹œì¥ ì²´ì œ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘")

        # ê¸°ì¡´ ëª¨ë¸ í™•ì¸
        if not args.force and model_path.exists():
            try:
                if hmm.load_model(str(model_path)):
                    print("âœ… ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                    return
            except Exception as e:
                print(f"âš ï¸  ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        # ë§¤í¬ë¡œ ë°ì´í„° ë¡œë“œ (ê°œì„ ëœ ë²„ì „)
        print(f"ğŸ“Š ë§¤í¬ë¡œ ë°ì´í„° ë¡œë“œ: {args.data_dir}")
        macro_files = {
            "vix": f"{args.data_dir}/^vix_data.csv",
            "tnx": f"{args.data_dir}/^tnx_data.csv",
            "irx": f"{args.data_dir}/^irx_data.csv",
            "uup": f"{args.data_dir}/uup_data.csv",
            "spy": f"{args.data_dir}/spy_data.csv",
            # ì‹ ìš© ìŠ¤í”„ë ˆë“œ ë°ì´í„° ì¶”ê°€
            "hyg": f"{args.data_dir}/hyg_data.csv",
            "lqd": f"{args.data_dir}/lqd_data.csv", 
            "tlt": f"{args.data_dir}/tlt_data.csv",
        }

        macro_data = pd.DataFrame()
        for key, filepath in macro_files.items():
            if os.path.exists(filepath):
                df = pd.read_csv(filepath)
                if not df.empty and "close" in df.columns:
                    macro_data[key] = df["close"]
                elif not df.empty and "Close" in df.columns:
                    macro_data[key] = df["Close"]

        if macro_data.empty:
            print("âŒ ë§¤í¬ë¡œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"  í™•ì¸ ê²½ë¡œ: {args.data_dir}")
            sys.exit(1)

        print(f"âœ… ë§¤í¬ë¡œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(macro_data)}í–‰")

        # ëª¨ë¸ í•™ìŠµ
        if hmm.fit(macro_data):
            # ëª¨ë¸ ì €ì¥
            if hmm.save_model(str(model_path)):
                print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
            else:
                print("âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨")
                sys.exit(1)
        else:
            print("âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
            sys.exit(1)

    elif args.predict:
        print("ğŸ”® í˜„ì¬ ì‹œì¥ ì²´ì œ ì˜ˆì¸¡")

        # ëª¨ë¸ ë¡œë“œ
        if not model_path.exists():
            print("âŒ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € --train ì˜µì…˜ìœ¼ë¡œ í•™ìŠµí•˜ì„¸ìš”.")
            sys.exit(1)

        if not hmm.load_model(str(model_path)):
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            sys.exit(1)

        # ìµœê·¼ ë§¤í¬ë¡œ ë°ì´í„°ë¡œ ì˜ˆì¸¡ (ê°œì„ ëœ ë²„ì „)
        macro_files = {
            "vix": f"{args.data_dir}/^vix_data.csv",
            "tnx": f"{args.data_dir}/^tnx_data.csv",
            "irx": f"{args.data_dir}/^irx_data.csv",
            "uup": f"{args.data_dir}/uup_data.csv",
            "spy": f"{args.data_dir}/spy_data.csv",
            # ì‹ ìš© ìŠ¤í”„ë ˆë“œ ë°ì´í„° ì¶”ê°€
            "hyg": f"{args.data_dir}/hyg_data.csv",
            "lqd": f"{args.data_dir}/lqd_data.csv",
            "tlt": f"{args.data_dir}/tlt_data.csv",
        }

        macro_data = pd.DataFrame()
        for key, filepath in macro_files.items():
            if os.path.exists(filepath):
                df = pd.read_csv(filepath)
                if not df.empty and "close" in df.columns:
                    macro_data[key] = df["close"]
                elif not df.empty and "Close" in df.columns:
                    macro_data[key] = df["Close"]

        if macro_data.empty:
            print("âŒ ë§¤í¬ë¡œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)

        # ì˜ˆì¸¡ ì‹¤í–‰
        result = hmm.predict_regime(macro_data)
        print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼: {result['regime']} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
        print(f"ğŸ“ˆ ì²´ì œ ê°•ë„: {result['regime_strength']:.3f}")

        # ìƒíƒœë³„ í™•ë¥ 
        print("ğŸ“Š ìƒíƒœë³„ í™•ë¥ :")
        for state, prob in result["state_probabilities"].items():
            print(f"  - {state}: {prob:.3f}")

    else:
        print("ì‚¬ìš©ë²•:")
        print("  --train --data-dir data/macro    # ëª¨ë¸ í•™ìŠµ")
        print("  --predict --data-dir data/macro  # í˜„ì¬ ì²´ì œ ì˜ˆì¸¡")
        print("  --force                          # ê°•ì œ ì¬í•™ìŠµ")


if __name__ == "__main__":
    main()
