#!/usr/bin/env python3
"""
ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
src/actions í´ë”ì—ì„œ ì‹¤í–‰
"""

import sys
import os
import json
from datetime import datetime
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

from src.agent.market_sensor import MarketSensor
from src.agent.enhancements import LLMConfig


def run_enhanced_analysis(
    output_dir: str = "results/macro/enhanced",
    enable_llm_api: bool = False,
    llm_config: LLMConfig = None,
    verbose: bool = True
) -> Dict[str, Any]:
    """
    ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„ ì‹¤í–‰
    
    Args:
        output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        enable_llm_api: LLM API í™œì„±í™” ì—¬ë¶€
        llm_config: LLM ì„¤ì •
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if verbose:
        print("ğŸš€ ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„ ì‹œì‘")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # Market Sensor ì´ˆê¸°í™”
        sensor = MarketSensor(
            enable_llm_api=enable_llm_api,
            llm_config=llm_config
        )
        
        if verbose:
            print("âœ… Market Sensor ì´ˆê¸°í™” ì„±ê³µ")
        
        # ê³ ë„í™”ëœ ë¶„ì„ ìˆ˜í–‰
        if verbose:
            print("ğŸš€ ê³ ë„í™”ëœ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        
        analysis = sensor.get_enhanced_market_analysis(
            use_optimized_params=True,
            use_ml_model=True,
            enable_advanced_features=True
        )
        
        if verbose:
            print("âœ… ê³ ë„í™”ëœ ë¶„ì„ ì™„ë£Œ")
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"{output_dir}/analysis_results_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False, default=str)
        
        if verbose:
            print(f"âœ… ê²°ê³¼ ì €ì¥: {output_file}")
        
        # ìš”ì•½ ì¶œë ¥
        if verbose:
            print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
            print(f"í˜„ì¬ ì²´ì œ: {analysis.get('current_regime', 'N/A')}")
            
            if 'final_confidence' in analysis:
                final_conf = analysis['final_confidence'].get('final_confidence', 0.5)
                print(f"ìµœì¢… ì‹ ë¢°ë„: {final_conf:.3f}")
            
            if 'rlmf_analysis' in analysis:
                rlmf = analysis['rlmf_analysis']
                if 'statistical_arbitrage' in rlmf:
                    stat_arb = rlmf['statistical_arbitrage']
                    print(f"Statistical Arbitrage: {stat_arb.get('direction', 'N/A')} (ì‹ ë¢°ë„: {stat_arb.get('confidence', 0):.3f})")
            
            if 'regime_detection' in analysis:
                regime_det = analysis['regime_detection']
                if 'regime_shift_detection' in regime_det:
                    shift_det = regime_det['regime_shift_detection']
                    if shift_det.get('regime_shift_detected', False):
                        print("âš ï¸ ì‹œì¥ ì²´ì œ ì „í™˜ ê°ì§€ë¨!")
            
            if 'llm_api_insights' in analysis:
                print("ğŸ¤– LLM API ë¶„ì„ ì™„ë£Œ")
                api_stats = analysis['llm_api_insights'].get('api_stats', {})
                if api_stats:
                    print(f"API ì„±ê³µë¥ : {api_stats.get('success_rate', 0):.2%}")
            
            # LLM API í†µê³„ (í™œì„±í™”ëœ ê²½ìš°)
            if sensor.llm_api_system:
                stats = sensor.get_llm_api_stats()
                print(f"\nğŸ“ˆ LLM API í†µê³„:")
                print(f"ì´ í˜¸ì¶œ: {stats.get('total_calls', 0)}")
                print(f"ì„±ê³µë¥ : {stats.get('success_rate', 0):.2%}")
                print(f"í‰ê·  ì‘ë‹µì‹œê°„: {stats.get('avg_response_time', 0):.3f}ì´ˆ")
            
            print("ğŸ‰ ê³ ë„í™”ëœ ë¶„ì„ ì™„ë£Œ!")
        
        return analysis
        
    except Exception as e:
        if verbose:
            print(f"âŒ ê³ ë„í™”ëœ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±
    import argparse
    
    parser = argparse.ArgumentParser(description="ê³ ë„í™”ëœ ì‹œì¥ ë¶„ì„")
    parser.add_argument("--output", type=str, default="results/macro/enhanced", 
                       help="ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--enable-llm", action="store_true", 
                       help="LLM API í™œì„±í™”")
    parser.add_argument("--verbose", action="store_true", default=True,
                       help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    
    args = parser.parse_args()
    
    # LLM ì„¤ì • (í™œì„±í™”ëœ ê²½ìš°)
    llm_config = None
    if args.enable_llm:
        llm_config = LLMConfig(
            provider="hybrid",
            model_name="anthropic.claude-3-sonnet-20240229-v1:0",
            fallback_to_rules=True
        )
    
    # ë¶„ì„ ì‹¤í–‰
    result = run_enhanced_analysis(
        output_dir=args.output,
        enable_llm_api=args.enable_llm,
        llm_config=llm_config,
        verbose=args.verbose
    )
    
    return result


if __name__ == "__main__":
    main() 